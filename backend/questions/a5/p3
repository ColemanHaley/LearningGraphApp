3 . Analyzing NMT Systems ( 8 points ) ( a ) ( 2 points ) ( written ) The following table shows some of the forms of the Spanish word traducir , which means ‘ to translate ’ . 12 Infinitive traducir to translate Present traduzco I translate traduces you translate traduce he or she translates Subjunctive traduzca that I translate traduzcas that you translate Use vocab . json to find ( e.g . using grep ) which of these six forms are in the word-vocabulary , which consists of the 50,000 most frequent words in the training data for English and for Spanish . Superstrings don’t count ( e.g . having traducen in the vocabulary is not a hit for traduce ) . State which of these six forms occur , and which do not . Explain in one sentence why this is a bad thing for word-based NMT from Spanish to English . Then explain in detail ( approximately two sentences ) how our new character-aware NMT model may overcome this problem . ( b ) i . ( 0.5 points ) ( written ) In Assignments 1 and 2 , we investigated word embeddings created via algorithms such a Word2Vec , and found that for these embeddings , semantically similar words are close together in the embedding space . In this exercise , we’ll compare this with the word embeddings constructed using the CharCNN trained in our NMT system . Go to https://projector.tensorflow.org/ . The website by default shows data from Word2Vec . Look at the nearest neighbors of the following words with dataset Word2Vec All ( in cosine distance ) . • financial • neuron • Francisco • naturally • expectation For each word , report the single closest neighbor . For your convenience , for each example take a screenshot of all the nearest words ( so you can compare with the CharCNN embeddings ) . ii . ( 0.5 points ) ( written ) The TensorFlow embedding projector also allows you to upload your own data – you may find this useful in your projects ! Download the character-based word embeddings obtained from our implementation of the character-aware NMT model from this link . Navigate to https://projector.tensorflow . org / , select Load Data , and upload the files character-embeddings . txt ( the embeddings themselves ) and metadata . txt ( the words associated with the embeddings ) . 12You can check http://www.spanishdict.com/conjugate/traducir for a more complete table . CS 224n Assignment 5 [ updated ] Page 12 of 12 Now look at the nearest neighbors of the same words . Again , report the single closest neighbors with dataset Word2Vec All and take screenshots for yourself . iii . ( 3 points ) ( written ) Compare the closest neighbors found by the two methods : briefly describe what kind of similarity is modeled by Word2Vec , and what kind of similarity is modeled by the CharCNN . Explain in detail ( 2-3 sentences ) how the differences in the methodology of Word2Vec and a CharCNN explain the differences you have found . ( c ) ( 2 points ) ( written ) As in Assignment 4 , we’ll take a look at the outputs of the model that you have trained ! The test set translations your model generated in 2 ( e ) should be located in the outputs directory at : outputs / test outputs . txt . We also provided translations from a word-based model from our Assignment 4 model in the file outputs / test outputs a4 . txt . Find places where the word-based model produced < UNK > , and compare to what the character - based decoder did . Find one example where the character-based decoder produced an acceptable translation in place of < UNK > , and one example where the character-based decoder produced an incorrect translation in place of < UNK > . As in Assignment 4 , ‘ acceptable ’ and ‘ incorrect ’ doesn’t just mean ‘ matches or doesn’t match the reference translation ’ – use your own judgment ( and Google Translate , if necessary ) . For each of the two examples , you should : 1 . Write the source sentence in Spanish . The source sentences are in en es data / test.es . 2 . Write the reference English translation of the sentence . The reference translations are in en es data / test . en . 3 . Write the English translation generated by the model from Assignment 4 . These translations are in outputs / test outputs a4 . txt . Underline the < UNK > you are talking about . 4 . Write your character-based model’s English translation . These translations are in outputs / test outputs . txt . Underline the CharDecoder-generated word you are talking about . 5 . Indicate whether this is an acceptable or incorrect example . Give a brief possible explanation ( one sentence ) for why the character-based model performed this way . Submission Instructions You will submit this assignment on GradeScope as two submissions – one for Assignment 5 [ coding ] and another for Assignment 5 [ written ] : 1 . Verify that the following files exist at these specified paths within your assignment directory : • outputs / test outputs . txt • outputs / test outputs local q1 . txt • outputs / test outputs local q2 . txt 2 . Run the collect submission.sh script to produce your assignment5 . zip file . 3 . Upload your assignment5 . zip file to GradeScope to Assignment 5 [ coding ] . 4 . Check that the public autograder tests passed correctly . In particular , check that the BLEU scores calculated for parts 1 ( j ) , 2 ( d ) and 2 ( e ) match what you expect , because points will be awarded based on these autograder-computed numbers . 5 . Upload your written solutions to GradeScope to Assignment 5 [ written ] . Tag it properly !
