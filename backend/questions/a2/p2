Coding : Implementing word2vec ( 20 points ) In this part you will implement the word2vec model and train your own word vectors with stochastic gradient descent ( SGD ) . Before you begin , first run the following commands within the assignment directory in order to create the appropriate conda virtual environment . This guarantees that you have all the necessary packages to complete the assignment . Also note that you probably want to finish the previous math section before writing the code since you will be asked to implement the math functions in Python . You want to implement and test the following subsections in order since they are accumulative . conda env create - f env . yml conda activate a2 Once you are done with the assignment you can deactivate this environment by running : conda deactivate For each of the methods you need to implement , we included approximately how many lines of code our solution has in the code comments . These numbers are included to guide you . You don’t have to stick to them , you can write shorter or longer code as you wish . If you think your implementation is significantly longer than ours , it is a signal that there are some numpy methods you could utilize to make your code both shorter and faster . for loops in Python take a long time to complete when used over large arrays , so we expect you to utilize numpy methods . We will be checking the efficiency of your code . You will be able to see the results of the autograder when you submit your code to Gradescope . ( a ) ( 12 points ) We will start by implementing methods in word2vec.py . First , implement the sigmoid method , which takes in a vector and applies the sigmoid function to it . Then implement the softmax loss and gradient in the naiveSoftmaxLossAndGradient method , and negative sampling loss and gradient in the negSamplingLossAndGradient method . Finally , fill in the implementation for the skip-gram model in the skipgram method . When you are done , test your implementation by running python word2vec.py . ( b ) ( 4 points ) Complete the implementation for your SGD optimizer in the sgd method of sgd.py . Test your implementation by running python sgd.py . ( c ) ( 4 points ) Show time ! Now we are going to load some real data and train word vectors with everything you just implemented ! We are going to use the Stanford Sentiment Treebank ( SST ) dataset to train word vectors , and later apply them to a simple sentiment analysis task . You will need to fetch the datasets first . To do this , run sh get datasets.sh . There is no additional code to write for this part ; just run python run.py . Note : The training process may take a long time depending on the efficiency of your implementation and the compute power of your machine ( an efficient implementation takes one to two hours ) . Plan accordingly ! Page 3 of 4 CS 224n Assignment # 2 : word2vec ( 43 Points ) After 40,000 iterations , the script will finish and a visualization for your word vectors will appear . It will also be saved as word vectors . png in your project directory . Include the plot in your homework write up . Briefly explain in at most three sentences what you see in the plot . 3 Submission Instructions You shall submit this assignment on GradeScope as two submissions – one for “ Assignment 2 [ coding ] ” and another for ‘ Assignment 2 [ written ] ” : ( a ) Run the collect submission.sh script to produce your assignment2 . zip file . ( b ) Upload your assignment2 . zip file to GradeScope to “ Assignment 2 [ coding ] ” . ( c ) Upload your written solutions to GradeScope to “ Assignment 2 [ written ] ” .  
