{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from gensim import corpora, models\n",
    "import ground_truth\n",
    "from collections import defaultdict\n",
    "\n",
    "import spacy\n",
    "import math\n",
    "import pickle\n",
    "import pyLDAvis\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.ldamodel import LdaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\pvagdar1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\pvagdar1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "stopwords.words(\"english\").extend([\"one\", \"would\", \"said\", \"man\"])\n",
    "stoplist = stopwords.words(\"english\")\n",
    "nlp = spacy.load(\"en_core_web_sm\")  # use list made by NLTK ppls\n",
    "\n",
    "labels = [\"dependency_parsing.txt\", \"language_modelling.txt\", \"machine_translation.txt\", \"neural_nets.txt\", \"vector_semantics.txt\"]\n",
    "\n",
    "lmbda = 0.0001\n",
    "\n",
    "def process(docs):\n",
    "    processed_docs = []\n",
    "    print('hey')\n",
    "    # print(docs)\n",
    "    for doc in nlp.pipe(docs, n_threads=4, batch_size=100):\n",
    "        ents = doc.ents  # Named entities.\n",
    "        doc = [token.lemma_ for token in doc if token.is_alpha and not token.is_stop]\n",
    "        doc.extend([str(entity) for entity in ents if len(entity) > 1])\n",
    "        processed_docs.append(doc)\n",
    "\n",
    "    docs = processed_docs\n",
    "\n",
    "    # import string\n",
    "    #\n",
    "    # docs = [\n",
    "    #     [\n",
    "    #         w\n",
    "    #         for w in d.translate(str.maketrans(\"\", \"\", string.punctuation)).split()\n",
    "    #         if w not in stoplist\n",
    "    #     ]\n",
    "    #     for d in docs\n",
    "    # ]\n",
    "\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    docs = [[lemmatizer.lemmatize(w) for w in d] for d in docs]\n",
    "    return docs\n",
    "\n",
    "\n",
    "def build_model():\n",
    "\n",
    "    # class GutenbergCorpusBOW(object):\n",
    "    #     def __iter__(self):\n",
    "    #         for document in os.listdir('Gutenberg/txt'):\n",
    "    #             splitdoc = []\n",
    "    #             for line in open('Gutenberg/txt/' + document):\n",
    "    #                 splitdoc.extend(line.lower().split())\n",
    "    #             yield dictionary.doc2bow(splitdoc)\n",
    "    #     def __len__(self):\n",
    "    #         return len(os.listdir('Gutenberg/txt'))\n",
    "\n",
    "    docs = []\n",
    "    for file in os.listdir(\"resources/\"):\n",
    "        with open(\"resources/\" + file, encoding='utf8') as doc:\n",
    "            try:\n",
    "                txt = doc.read()\n",
    "            except:\n",
    "                continue\n",
    "        docs.append(txt)\n",
    "    docs = process(docs)\n",
    "    dictionary = Dictionary(docs)\n",
    "\n",
    "    # Remove rare and common tokens.\n",
    "    # Filter out words that occur too frequently or too rarely.\n",
    "    max_freq = 0.5\n",
    "    min_wordcount = 2\n",
    "    dictionary.filter_extremes(no_below=min_wordcount, no_above=max_freq)\n",
    "    # print(dictionary)\n",
    "    # _ = dictionary[0]  # This sort of \"initializes\" dictionary.id2token.\n",
    "\n",
    "    corpus = [dictionary.doc2bow(doc) for doc in docs]\n",
    "    models = []\n",
    "    for i in range(10):\n",
    "        lda = LdaModel(corpus, num_topics=5,id2word = dictionary)\n",
    "        models.append(lda)\n",
    "    print(\"yo\")\n",
    "    with open(\"topic_models.pkl\", \"wb\") as mfile:\n",
    "        print(\"hey!\")\n",
    "        pickle.dump((models, dictionary,corpus), mfile)\n",
    "\n",
    "\n",
    "    # annotated questions\n",
    "    # for assignment, questions in ground_truth.items():\n",
    "    #     if assignment = \"a2\": # hold out assignment 2\n",
    "    #         continue\n",
    "    #     for q, labels in question.items():\n",
    "    #         for label in labels:\n",
    "    #             if label is not in p_class:\n",
    "    #                 p_class[label] = {}\n",
    "    #                 p_label[label] = 1\n",
    "    #             else:\n",
    "    #                 p_label[label] += 1\n",
    "    #             if assignment not in observations[label]:\n",
    "    #                 observations[label][assignment] = {}\n",
    "    #             observations[label][assignment][q] = 1\n",
    "    #             with open(\"../questions/\"+assignment+\"/\"+q + \".txt\") as q_file:\n",
    "    #                 q_txt = q_file.read()\n",
    "    #                 q_txt = process([q_txt])\n",
    "    #                 for i, lda in enumerate(models):\n",
    "    #                     if i not in p_class[label]:\n",
    "    #                         p_class[label][i] = [[],[],[],[],[]]\n",
    "    #                     theta = lda[dictionary.doc2bow(q_txt[0])]\n",
    "    #                     for j, feature in enumerate(theta):\n",
    "    #                         p_class[label][i][j].append(feature)\n",
    "\n",
    "    # topics labelled\n",
    "def predict(txt, models, dictionary, p_class, p_label):\n",
    "    Z = sum([val for _, val in p_label.items()])\n",
    "    txt = process([txt])\n",
    "    results = {label: 0 for label in labels}\n",
    "    for label in labels:\n",
    "        for i, lda in enumerate(models):\n",
    "            theta = lda[dictionary.doc2bow(txt[0])]\n",
    "            for j, feature in theta:\n",
    "                results[label] = feature * ((sum(p_class[label][i][j]) + lmbda) / (p_label[label]+10*lmbda)) * (p_label[label]/Z)\n",
    "    norm = sum(results.values())\n",
    "    results = {label: val/norm for label, val in results.items()}\n",
    "    return results\n",
    "\n",
    "def bayes_EM(models, dictionary):\n",
    "    p_class = {}\n",
    "    labels = [\"dependency_parsing.txt\", \"language_modelling.txt\", \"machine_translation.txt\", \"neural_nets.txt\", \"vector_semantics.txt\"]\n",
    "    p_label = {}\n",
    "    observations = {label: {} for label in labels}\n",
    "    for label in labels:\n",
    "        with open(\"topics/\"+label, encoding='utf8') as doc:\n",
    "            try:\n",
    "                txt = doc.read()\n",
    "            except:\n",
    "                continue\n",
    "            if label not in p_class:\n",
    "                p_class[label] = {}\n",
    "                p_label[label] = 1\n",
    "            else:\n",
    "                p_label[label] += 1\n",
    "            if \"topics\" not in observations[label]:\n",
    "                observations[label][\"topics\"] = {}\n",
    "            observations[label][\"topics\"][label] = 1\n",
    "            txt = process([txt])\n",
    "            for i, lda in enumerate(models):\n",
    "                print(i)\n",
    "                if i not in p_class[label]:\n",
    "                    p_class[label][i] = [[],[],[],[],[]]\n",
    "                theta = lda[dictionary.doc2bow(txt[0])]\n",
    "                for j, feature in theta:\n",
    "                        p_class[label][i][j].append(feature)\n",
    "    lmbda = 0.0001\n",
    "\n",
    "    Z = sum([val for _, val in p_label.items()])\n",
    "    for label, ms in p_class.items():\n",
    "        for i, topics in enumerate(ms):\n",
    "            for j in range(5):\n",
    "                p_class[label][i][j] = [((sum(p_class[label][i][j]) + lmbda) / (p_label[label]+(10*lmbda))) * (p_label[label]/Z) / 2]\n",
    "\n",
    "    # expectation maximization\n",
    "    epochs = 10\n",
    "    for label in labels:\n",
    "        observations[label][\"resources\"] = {}\n",
    "    for e in range(epochs):\n",
    "        i = -1\n",
    "        # expectation\n",
    "        print(\"expectation\")\n",
    "        Z = sum([val for _, val in p_label.items()])\n",
    "        for file in os.listdir(\"resources/\"):\n",
    "            with open(\"resources/\" + file) as doc:\n",
    "                try:\n",
    "                    txt = doc.read()\n",
    "                    i += 1\n",
    "                except:\n",
    "                    continue\n",
    "                results = predict(txt, models, dictionary, p_class, p_label)\n",
    "                for label in labels:\n",
    "                    observations[label][\"resources\"][file] = results[label]\n",
    "        # maximization\n",
    "        # print(observations)\n",
    "        print(\"maximization\")\n",
    "        for file in os.listdir(\"resources/\"):\n",
    "            with open(\"resources/\" + file) as doc:\n",
    "                try:\n",
    "                    txt = doc.read()\n",
    "                except:\n",
    "                    continue\n",
    "                txt = process([txt])\n",
    "                for label in labels:\n",
    "                    if label not in p_class:\n",
    "                        p_class[label] = {}\n",
    "                        p_label[label] = observations[label][\"resources\"][file]\n",
    "                    else:\n",
    "                        p_label[label] += observations[label][\"resources\"][file]\n",
    "                    for i, lda in enumerate(models):\n",
    "                        if i not in p_class[label]:\n",
    "                            p_class[label][i] = [[],[],[],[],[]]\n",
    "                        theta = lda[dictionary.doc2bow(txt[0])]\n",
    "                        for j, feature in theta:\n",
    "                            p_class[label][i][j].append(feature*observations[label][\"resources\"][file])\n",
    "        #print(observations)\n",
    "    with open(\"classifier.pkl\", \"wb\") as mfile:\n",
    "        pickle.dump((p_class, p_label), mfile)\n",
    "\n",
    "\n",
    "def evaluate_bayes():\n",
    "    try:\n",
    "        with open(\"topic_models.pkl\", \"rb\") as f:\n",
    "            models, dictionary = pickle.load(f)\n",
    "    except:\n",
    "        print('heyo!')\n",
    "        build_model()\n",
    "        with open(\"topic_models.pkl\", \"rb\") as f:\n",
    "            models, dictionary = pickle.load(f)\n",
    "    try:\n",
    "        with open(\"classifier.pkl\", \"rb\") as f:\n",
    "            p_class, p_label = pickle.load(f)\n",
    "    except:\n",
    "        bayes_EM(models, dictionary)\n",
    "        with open(\"classifier.pkl\", \"rb\") as f:\n",
    "            p_class, p_label = pickle.load(f)\n",
    "    tp = defaultdict(int)\n",
    "    fp = defaultdict(int)\n",
    "    tn = defaultdict(int)\n",
    "    fn = defaultdict(int)\n",
    "    for assignment, questions in ground_truth.get_groundTruth().items():\n",
    "        for question, ground in questions.items():\n",
    "            with open('questions/' + assignment + \"/\" + question) as f:\n",
    "                try:\n",
    "                    txt = f.read()\n",
    "                except:\n",
    "                    continue\n",
    "                results = predict(txt, models, dictionary, p_class, p_label)\n",
    "                tops = sorted(results, key=results.get, reverse=True)[:len(ground)]\n",
    "                for label in labels:\n",
    "                    if label in tops and label in ground:\n",
    "                        tp[label] += 1\n",
    "                    elif label in tops and label not in ground:\n",
    "                        fp[label] += 1\n",
    "                    elif label in ground and label not in tops:\n",
    "                        fn[label] += 1\n",
    "                    else:\n",
    "                        tn[label] += 1\n",
    "\n",
    "    precision_dict = defaultdict(int)\n",
    "    recall_dict = defaultdict(int)\n",
    "    f1_dict = defaultdict(int)\n",
    "    for label in labels:\n",
    "        if tp[label] == 0:\n",
    "            print(label)\n",
    "            continue\n",
    "        precision_dict[label] = tp[label] / (fp[label]+tp[label])\n",
    "        recall_dict[label] = tp[label] / (fn[label]+tp[label])\n",
    "        f1_dict[label] = 2 * (precision_dict[label] * recall_dict[label]) / (precision_dict[label] + recall_dict[label])\n",
    "\n",
    "    macro_precision = sum(precision_dict.values()) / 5\n",
    "    macro_recall = sum(recall_dict.values()) / 5\n",
    "    macro_f1 = sum(f1_dict.values()) / 5\n",
    "    micro_precision = sum(tp.values()) / (sum(tp.values()) + sum(fp.values()))\n",
    "    micro_recall = sum(tp.values()) / (sum(tp.values()) + sum(fn.values()))\n",
    "    micro_f1 = 2 * (micro_precision * micro_recall) / (micro_recall + micro_precision)\n",
    "\n",
    "    print(\"### PER-CLASS METRICS ###\")\n",
    "    print(\"PRECIS  RECALL  F1    \")\n",
    "    for label in labels:\n",
    "        print(f\"{precision_dict[label]:6.4f}  {recall_dict[label]:6.4f}  {f1_dict[label]:6.4f}  {label.upper()}\")\n",
    "\n",
    "    print()\n",
    "    print(\"### AVERAGED METRICS ###\")\n",
    "    print()\n",
    "    print(\"MICRO AVERAGED\")\n",
    "    print(\"PRECIS  RECALL  F1    \")\n",
    "    print(f\"{micro_precision:6.4f}  {micro_recall:6.4f}  {micro_f1:6.4f}\")\n",
    "    print()\n",
    "    print(\"MACRO AVERAGED\")\n",
    "    print(\"PRECIS  RECALL  F1    \")\n",
    "    print(f\"{macro_precision:6.4f}  {macro_recall:6.4f}  {macro_f1:6.4f}\")\n",
    "\n",
    "#def evaluate_baseline():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heyo!\n",
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yo\n",
      "hey!\n",
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n",
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n",
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n",
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvagdar1\\.conda\\envs\\nlpenv\\lib\\runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open(\"topic_models.pkl\", \"rb\") as f:\n",
    "        models, dictionary, corpus = pickle.load(f)\n",
    "except:\n",
    "    print('heyo!')\n",
    "    build_model()\n",
    "    with open(\"topic_models.pkl\", \"rb\") as f:\n",
    "        models, dictionary, corpus = pickle.load(f)\n",
    "try:\n",
    "    with open(\"classifier.pkl\", \"rb\") as f:\n",
    "        p_class, p_label = pickle.load(f)\n",
    "except:\n",
    "    bayes_EM(models, dictionary)\n",
    "tp = defaultdict(int)\n",
    "fp = defaultdict(int)\n",
    "tn = defaultdict(int)\n",
    "fn = defaultdict(int)\n",
    "for assignment, questions in ground_truth.get_groundTruth().items():\n",
    "    for question, ground in questions.items():\n",
    "        with open('questions/' + assignment + \"/\" + question, encoding='utf8') as f:\n",
    "            try:\n",
    "                txt1 = f.read()\n",
    "            except:\n",
    "                continue\n",
    "            txt1 = process([txt1])\n",
    "            results = {}\n",
    "            for file in os.listdir(\"topics/\"):\n",
    "                with open(\"topics/\" + file, encoding='utf8') as doc2:\n",
    "                    txt = doc2.read()\n",
    "                    # print(\"hey\")\n",
    "                    txt = process([txt])\n",
    "                    # print(txt)\n",
    "                    # print(\"ho\")\n",
    "                    kl = 0\n",
    "                    for lda in models:\n",
    "                        p = lda[dictionary.doc2bow(txt1[0])]\n",
    "                        # print(p)\n",
    "                        q = lda[dictionary.doc2bow(txt[0])]\n",
    "                        # print(q)\n",
    "                        for y, w1 in p:\n",
    "                            for x, w0 in q:\n",
    "                                if x == y:\n",
    "                                    kl += w0 * w1\n",
    "                    results[file] = kl\n",
    "            tops = sorted(results, key=results.get, reverse=True)[:len(ground)]\n",
    "            for label in labels:\n",
    "                if label in tops and label in ground:\n",
    "                    tp[label] += 1\n",
    "                elif label in tops and label not in ground:\n",
    "                    fp[label] += 1\n",
    "                elif label in ground and label not in tops:\n",
    "                    fn[label] += 1\n",
    "                else:\n",
    "                    tn[label] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.006*\"NP\" + 0.004*\"sense\" + 0.003*\"flight\" + 0.003*\"grammar\" + 0.003*\"head\" + 0.003*\"bigram\" + 0.003*\"z\" + 0.003*\"Pr\" + 0.003*\"span\" + 0.002*\"transition\"'), (1, '0.010*\"NP\" + 0.005*\"z\" + 0.005*\"grammar\" + 0.005*\"VP\" + 0.003*\"head\" + 0.003*\"discourse\" + 0.003*\"ym\" + 0.003*\"logistic\" + 0.003*\"flight\" + 0.003*\"regression\"'), (2, '0.007*\"z\" + 0.007*\"NP\" + 0.004*\"grammar\" + 0.003*\"head\" + 0.003*\"dialogue\" + 0.003*\"VP\" + 0.003*\"discourse\" + 0.003*\"flight\" + 0.002*\"parsing\" + 0.002*\"PP\"'), (3, '0.007*\"sense\" + 0.005*\"NP\" + 0.004*\"z\" + 0.004*\"discourse\" + 0.004*\"grammar\" + 0.003*\"coreference\" + 0.003*\"VP\" + 0.002*\"span\" + 0.002*\"ym\" + 0.002*\"transition\"'), (4, '0.006*\"discourse\" + 0.005*\"z\" + 0.003*\"NP\" + 0.003*\"dialogue\" + 0.003*\"user\" + 0.003*\"similarity\" + 0.003*\"grammar\" + 0.003*\"target\" + 0.002*\"sense\" + 0.002*\"frequency\"')]\n",
      "[(0, '0.007*\"discourse\" + 0.003*\"NP\" + 0.003*\"coherence\" + 0.003*\"dialogue\" + 0.003*\"sense\" + 0.003*\"span\" + 0.003*\"grammar\" + 0.003*\"transition\" + 0.002*\"flight\" + 0.002*\"user\"'), (1, '0.015*\"NP\" + 0.006*\"z\" + 0.006*\"grammar\" + 0.005*\"VP\" + 0.004*\"flight\" + 0.003*\"PP\" + 0.003*\"sense\" + 0.003*\"constituent\" + 0.003*\"head\" + 0.003*\"terminal\"'), (2, '0.006*\"sense\" + 0.004*\"ym\" + 0.004*\"NP\" + 0.003*\"grammar\" + 0.002*\"VP\" + 0.002*\"discourse\" + 0.002*\"bigram\" + 0.002*\"wn\" + 0.002*\"transition\" + 0.002*\"H\"'), (3, '0.005*\"grammar\" + 0.004*\"NP\" + 0.004*\"bigram\" + 0.003*\"head\" + 0.003*\"sense\" + 0.003*\"z\" + 0.003*\"VP\" + 0.003*\"similarity\" + 0.002*\"\" + 0.002*\"free\"'), (4, '0.011*\"z\" + 0.004*\"discourse\" + 0.004*\"coreference\" + 0.004*\"NP\" + 0.003*\"head\" + 0.003*\"span\" + 0.003*\"October 15 , 2018\" + 0.003*\"cluster\" + 0.003*\"NC\" + 0.003*\"CC\"')]\n",
      "[(0, '0.007*\"z\" + 0.007*\"sense\" + 0.006*\"NP\" + 0.005*\"discourse\" + 0.004*\"coreference\" + 0.004*\"grammar\" + 0.003*\"head\" + 0.003*\"span\" + 0.003*\"cluster\" + 0.003*\"bigram\"'), (1, '0.005*\"NP\" + 0.004*\"discourse\" + 0.004*\"grammar\" + 0.003*\"dialogue\" + 0.003*\"regression\" + 0.003*\"logistic\" + 0.003*\"flight\" + 0.003*\"user\" + 0.002*\"head\" + 0.002*\"constituent\"'), (2, '0.008*\"NP\" + 0.006*\"z\" + 0.004*\"grammar\" + 0.004*\"ym\" + 0.003*\"sense\" + 0.003*\"flight\" + 0.003*\"VP\" + 0.003*\"head\" + 0.003*\"production\" + 0.003*\"free\"'), (3, '0.006*\"NP\" + 0.006*\"z\" + 0.005*\"grammar\" + 0.004*\"discourse\" + 0.004*\"VP\" + 0.003*\"target\" + 0.003*\"bigram\" + 0.003*\"ym\" + 0.003*\"\" + 0.003*\"flight\"'), (4, '0.004*\"NP\" + 0.003*\"z\" + 0.003*\"ym\" + 0.003*\"transition\" + 0.003*\"grammar\" + 0.003*\"sense\" + 0.002*\"head\" + 0.002*\"ti\" + 0.002*\"sentiment\" + 0.002*\"logistic\"')]\n",
      "[(0, '0.007*\"discourse\" + 0.006*\"z\" + 0.003*\"wm\" + 0.003*\"bigram\" + 0.003*\"vocabulary\" + 0.003*\"sentiment\" + 0.003*\"span\" + 0.003*\"lexicon\" + 0.002*\"sense\" + 0.002*\"Eisenstein\"'), (1, '0.005*\"sense\" + 0.005*\"z\" + 0.003*\"dialogue\" + 0.003*\"NP\" + 0.003*\"coreference\" + 0.003*\"discourse\" + 0.003*\"head\" + 0.002*\"span\" + 0.002*\"target\" + 0.002*\"frequency\"'), (2, '0.009*\"NP\" + 0.007*\"grammar\" + 0.007*\"sense\" + 0.005*\"VP\" + 0.005*\"z\" + 0.004*\"head\" + 0.004*\"parsing\" + 0.003*\"flight\" + 0.003*\"transition\" + 0.003*\"constituent\"'), (3, '0.006*\"z\" + 0.005*\"NP\" + 0.004*\"ym\" + 0.004*\"discourse\" + 0.004*\"grammar\" + 0.003*\"user\" + 0.003*\"Jacob\" + 0.003*\"dialogue\" + 0.003*\"transition\" + 0.003*\"Eisenstein\"'), (4, '0.010*\"NP\" + 0.004*\"grammar\" + 0.004*\"flight\" + 0.004*\"VP\" + 0.003*\"coreference\" + 0.003*\"span\" + 0.003*\"z\" + 0.003*\"head\" + 0.003*\"PP\" + 0.003*\"Pr\"')]\n",
      "[(0, '0.004*\"NP\" + 0.004*\"discourse\" + 0.004*\"z\" + 0.004*\"sense\" + 0.004*\"ym\" + 0.003*\"target\" + 0.003*\"grammar\" + 0.003*\"span\" + 0.003*\"Eisenstein\" + 0.002*\"similarity\"'), (1, '0.004*\"z\" + 0.004*\"discourse\" + 0.004*\"NP\" + 0.003*\"coreference\" + 0.003*\"head\" + 0.003*\"span\" + 0.002*\"sense\" + 0.002*\"sentiment\" + 0.002*\"cluster\" + 0.002*\"grammar\"'), (2, '0.007*\"NP\" + 0.007*\"sense\" + 0.004*\"grammar\" + 0.003*\"z\" + 0.003*\"head\" + 0.003*\"production\" + 0.003*\"VP\" + 0.003*\"user\" + 0.003*\"dialogue\" + 0.003*\"regression\"'), (3, '0.010*\"z\" + 0.009*\"NP\" + 0.006*\"discourse\" + 0.004*\"grammar\" + 0.004*\"coreference\" + 0.003*\"VP\" + 0.003*\"flight\" + 0.003*\"transition\" + 0.003*\"head\" + 0.003*\"PP\"'), (4, '0.005*\"NP\" + 0.005*\"grammar\" + 0.004*\"VP\" + 0.004*\"z\" + 0.003*\"ym\" + 0.003*\"head\" + 0.003*\"flight\" + 0.003*\"bigram\" + 0.003*\"transition\" + 0.002*\"frequency\"')]\n",
      "[(0, '0.009*\"z\" + 0.006*\"NP\" + 0.004*\"coreference\" + 0.004*\"grammar\" + 0.003*\"VP\" + 0.002*\"u\" + 0.002*\"span\" + 0.002*\"bigram\" + 0.002*\"discourse\" + 0.002*\"sense\"'), (1, '0.006*\"NP\" + 0.005*\"discourse\" + 0.004*\"z\" + 0.003*\"grammar\" + 0.003*\"span\" + 0.003*\"head\" + 0.003*\"transition\" + 0.003*\"similarity\" + 0.003*\"sense\" + 0.003*\"flight\"'), (2, '0.007*\"NP\" + 0.006*\"discourse\" + 0.005*\"z\" + 0.004*\"VP\" + 0.003*\"grammar\" + 0.003*\"dialogue\" + 0.003*\"coreference\" + 0.003*\"head\" + 0.003*\"user\" + 0.003*\"flight\"'), (3, '0.006*\"ym\" + 0.006*\"NP\" + 0.004*\"grammar\" + 0.003*\"z\" + 0.003*\"sense\" + 0.003*\"CC\" + 0.003*\"dialogue\" + 0.003*\"October 15 , 2018\" + 0.003*\"contract\" + 0.002*\"transition\"'), (4, '0.007*\"NP\" + 0.007*\"sense\" + 0.004*\"grammar\" + 0.004*\"z\" + 0.003*\"flight\" + 0.003*\"head\" + 0.003*\"VP\" + 0.003*\"discourse\" + 0.003*\"parsing\" + 0.003*\"regression\"')]\n",
      "[(0, '0.008*\"NP\" + 0.007*\"z\" + 0.005*\"grammar\" + 0.004*\"VP\" + 0.003*\"span\" + 0.003*\"license\" + 0.003*\"head\" + 0.003*\"Pr\" + 0.003*\"PP\" + 0.003*\"free\"'), (1, '0.008*\"sense\" + 0.008*\"discourse\" + 0.005*\"NP\" + 0.004*\"z\" + 0.004*\"grammar\" + 0.003*\"flight\" + 0.003*\"head\" + 0.003*\"transition\" + 0.003*\"span\" + 0.002*\"coreference\"'), (2, '0.011*\"NP\" + 0.005*\"z\" + 0.004*\"grammar\" + 0.004*\"discourse\" + 0.004*\"VP\" + 0.004*\"coreference\" + 0.002*\"\" + 0.002*\"constituent\" + 0.002*\"pronoun\" + 0.002*\"parsing\"'), (3, '0.005*\"z\" + 0.005*\"NP\" + 0.004*\"grammar\" + 0.003*\"head\" + 0.003*\"discourse\" + 0.003*\"parsing\" + 0.003*\"frequency\" + 0.003*\"VP\" + 0.003*\"flight\" + 0.002*\"transition\"'), (4, '0.004*\"ym\" + 0.004*\"dialogue\" + 0.003*\"NP\" + 0.003*\"regression\" + 0.003*\"sentiment\" + 0.003*\"user\" + 0.003*\"sense\" + 0.003*\"encoder\" + 0.003*\"z\" + 0.003*\"decoder\"')]\n",
      "[(0, '0.007*\"z\" + 0.004*\"NP\" + 0.004*\"ym\" + 0.004*\"head\" + 0.003*\"VP\" + 0.003*\"coreference\" + 0.003*\"sense\" + 0.003*\"span\" + 0.003*\"grammar\" + 0.003*\"transition\"'), (1, '0.005*\"sense\" + 0.005*\"NP\" + 0.005*\"z\" + 0.004*\"grammar\" + 0.004*\"discourse\" + 0.003*\"VP\" + 0.002*\"category\" + 0.002*\"regression\" + 0.002*\"wm\" + 0.002*\"transition\"'), (2, '0.007*\"NP\" + 0.004*\"z\" + 0.004*\"grammar\" + 0.003*\"sense\" + 0.003*\"regression\" + 0.003*\"flight\" + 0.003*\"logistic\" + 0.003*\"bigram\" + 0.003*\"head\" + 0.002*\"transition\"'), (3, '0.006*\"NP\" + 0.005*\"discourse\" + 0.004*\"grammar\" + 0.004*\"z\" + 0.003*\"dialogue\" + 0.003*\"\" + 0.003*\"VP\" + 0.003*\"span\" + 0.002*\"head\" + 0.002*\"user\"'), (4, '0.008*\"NP\" + 0.005*\"discourse\" + 0.005*\"z\" + 0.004*\"sense\" + 0.003*\"grammar\" + 0.003*\"flight\" + 0.003*\"VP\" + 0.003*\"head\" + 0.002*\"parsing\" + 0.002*\"terminal\"')]\n",
      "[(0, '0.008*\"NP\" + 0.007*\"z\" + 0.005*\"VP\" + 0.005*\"grammar\" + 0.004*\"flight\" + 0.003*\"head\" + 0.003*\"PP\" + 0.003*\"wm\" + 0.003*\"parsing\" + 0.003*\"constituent\"'), (1, '0.008*\"sense\" + 0.007*\"discourse\" + 0.003*\"z\" + 0.003*\"NP\" + 0.003*\"transition\" + 0.002*\"span\" + 0.002*\"coreference\" + 0.002*\"RNN\" + 0.002*\"grammar\" + 0.002*\"R\"'), (2, '0.004*\"coreference\" + 0.004*\"discourse\" + 0.003*\"span\" + 0.003*\"NP\" + 0.003*\"antecedent\" + 0.003*\"bigram\" + 0.003*\"head\" + 0.003*\"grammar\" + 0.002*\"cluster\" + 0.002*\"pronoun\"'), (3, '0.008*\"NP\" + 0.005*\"z\" + 0.004*\"dialogue\" + 0.004*\"grammar\" + 0.004*\"user\" + 0.003*\"discourse\" + 0.003*\"VP\" + 0.003*\"q\" + 0.003*\"span\" + 0.003*\"\"'), (4, '0.007*\"NP\" + 0.006*\"z\" + 0.004*\"grammar\" + 0.004*\"discourse\" + 0.004*\"sense\" + 0.003*\"VP\" + 0.003*\"head\" + 0.003*\"ym\" + 0.002*\"sentiment\" + 0.002*\"span\"')]\n",
      "[(0, '0.010*\"NP\" + 0.005*\"sense\" + 0.005*\"grammar\" + 0.004*\"z\" + 0.004*\"flight\" + 0.004*\"VP\" + 0.003*\"head\" + 0.003*\"PP\" + 0.003*\"ym\" + 0.003*\"transition\"'), (1, '0.005*\"z\" + 0.005*\"RNN\" + 0.003*\"NP\" + 0.003*\"sense\" + 0.003*\"grammar\" + 0.002*\"head\" + 0.002*\"similarity\" + 0.002*\"transition\" + 0.002*\"hidden\" + 0.002*\"coreference\"'), (2, '0.008*\"discourse\" + 0.006*\"z\" + 0.005*\"NP\" + 0.003*\"grammar\" + 0.003*\"regression\" + 0.003*\"VP\" + 0.003*\"span\" + 0.003*\"logistic\" + 0.003*\"head\" + 0.003*\"parsing\"'), (3, '0.007*\"NP\" + 0.006*\"z\" + 0.004*\"grammar\" + 0.003*\"discourse\" + 0.003*\"VP\" + 0.003*\"Pr\" + 0.003*\"sense\" + 0.003*\"flight\" + 0.002*\"\" + 0.002*\"sentiment\"'), (4, '0.004*\"NP\" + 0.003*\"z\" + 0.003*\"sense\" + 0.003*\"coreference\" + 0.003*\"bigram\" + 0.003*\"grammar\" + 0.002*\"user\" + 0.002*\"head\" + 0.002*\"span\" + 0.002*\"vocabulary\"')]\n"
     ]
    }
   ],
   "source": [
    "for lda in models:\n",
    "    print(lda.show_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el4961629528131995607735033329\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el4961629528131995607735033329_data = {\"mdsDat\": {\"x\": [-0.0014091609723939184, 0.011968138912581075, -0.013178884113620259, 0.011047560008448408, -0.008427653835015347], \"y\": [-0.002872828125108009, -0.008285151890794115, -0.0052638428546340444, 0.008427914389290959, 0.00799390848124521], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [25.433799743652344, 24.555795669555664, 20.608285903930664, 19.039573669433594, 10.362545013427734]}, \"tinfo\": {\"Term\": [\"ym\", \"sense\", \"logistic\", \"Pr\", \"ti\", \"regression\", \"transition\", \"RNN\", \"tagging\", \"encoder\", \"Viterbi\", \"Ym\", \"sentiment\", \"coreference\", \"hidden\", \"z\", \"forward\", \"wm\", \"dialogue\", \"predicate\", \"production\", \"frame\", \"softmax\", \"target\", \"user\", \"head\", \"decoder\", \"cat\", \"eat\", \"NP\", \"week\", \"pajama\", \"scene\", \"twist\", \"idf\", \"Romeo\", \"spam\", \"wordtoword\", \"le\", \"nonparametric\", \"Bojanowski\", \"useless\", \"differentially\", \"cm\", \"Earley\", \"ongchoi\", \"atacado\", \"EM\", \"pivot\", \"attentional\", \"BAYES\", \"fun\", \"\\u03a6\", \"commission\", \"pwt\", \"elephant\", \"vn\", \"SVD\", \"hub\", \"Temporal\", \"target\", \"AB\", \"\\u03c6\", \"cell\", \"coffee\", \"frontier\", \"\\u00b5\", \"film\", \"\\u03b1\", \"mutual\", \"MACHINE\", \"bigram\", \"wm\", \"ym\", \"statistical\", \"terminal\", \"maximization\", \"chunk\", \"VP\", \"unlabeled\", \"encoder\", \"PMI\", \"grammar\", \"Nominal\", \"CC\", \"z\", \"hm\", \"coherence\", \"similarity\", \"alignment\", \"NP\", \"u\", \"entropy\", \"Bayes\", \"discourse\", \"vocabulary\", \"intuition\", \"ND\", \"column\", \"flight\", \"\\u03bb\", \"frequency\", \"license\", \"H\", \"production\", \"PP\", \"\\u03c8\", \"transition\", \"Jacob\", \"contract\", \"span\", \"parsing\", \"constituent\", \"head\", \"Lesk\", \"bass\", \"superordinate\", \"biguation\", \"WORDNET\", \"SemCor\", \"sense\", \"RESOLUTION\", \"blood\", \"Taboada\", \"antonym\", \"thesaurus\", \"concordance\", \"wn\", \"semcor\", \"Maas\", \"politician\", \"stopword\", \"musical\", \"polysemy\", \"\\u03ba\", \"lean\", \"erence\", \"confess\", \"unfortunate\", \"Pilehvar , M\", \"Mention\", \"Lucia\", \"ponzetto\", \"jet\", \"coreference\", \"tail\", \"edit\", \"WordNet\", \"anaphor\", \"anaphoric\", \"Heafield\", \"pronoun\", \"OntoNotes\", \"policy\", \"cluster\", \"synset\", \"Lee\", \"zk\", \"z\", \"Abigail\", \"discourse\", \"antecedent\", \"chinese\", \"annotation\", \"span\", \"bigram\", \"user\", \"smooth\", \"clustering\", \"head\", \"resolution\", \"NP\", \"q\", \"perplexity\", \"disambiguation\", \"frequency\", \"sentiment\", \"lexicon\", \"grammar\", \"eat\", \"parsing\", \"Eisenstein\", \"VP\", \"dialogue\", \"H\", \"Jacob Eisenstein\", \"October 15 , 2018\", \"Jacob\", \"contract\", \"R\", \"PP\", \"CC\", \"TH\", \"flip\", \"Reno\", \"matcher\", \"HH\", \"coin\", \"SEQUENCE\", \"Pr\", \"Hamming\", \"pcfg\", \"PCFG\", \"1 4\", \"splitting\", \"pX\", \"Ym\", \"can\", \"cream\", \"affinity\", \"ct\", \"RNNs\", \"rence\", \"sack\", \"Schabes\", \"Rn\", \"sbi\", \"pr\", \"th\", \"ht\", \"RECURRENT\", \"Memory\", \"RNN\", \"ym\", \"lexicalized\", \"yn\", \"VBD\", \"production\", \"recurrence\", \"attachment\", \"sm\", \"dump\", \"vm\", \"free\", \"parser\", \"NP\", \"fish\", \"\\u03c8\", \"flight\", \"wm\", \"max\", \"terminal\", \"backward\", \"z\", \"forward\", \"head\", \"NC\", \"stack\", \"activation\", \"VP\", \"contract\", \"PP\", \"grammar\", \"hidden\", \"sense\", \"parsing\", \"draft\", \"Eisenstein\", \"October 15 , 2018\", \"edge\", \"transition\", \"constituent\", \"license\", \"discourse\", \"span\", \"LCE\", \"Boyang\", \"doc\", \"Manhattan\", \"dw\", \"lasso\", \"Pietra\", \"maxent\", \"Banarescu\", \"Regression\", \"confound\", \"shrinkage\", \"Labov\", \"ezi\", \"multiclass\", \"REGRESSION\", \"lossloss\", \"PROPN\", \"compromise\", \"log\\u03c3\", \"derivativechain\", \"PropBank\", \"transparently\", \"collar\", \"abysmal\", \"Poirot\", \"whichgenerativemodel\", \"Affair\", \"intercept\", \"Della\", \"xb\", \"\\u03c3w\", \"slope\", \"VerbNet\", \"Das\", \"perfectly\", \"BiLSTM\", \"regression\", \"logistic\", \"Logistic\", \"Serves\", \"batch\", \"dialogue\", \"restaurant\", \"crossentropy\", \"\\u03c3\", \"agent\", \"user\", \"conversation\", \"teach\", \"softmax\", \"bias\", \"predicate\", \"response\", \"slot\", \"category\", \"movie\", \"sigmoid\", \"utterance\", \"edge\", \"constituent\", \"rank\", \"sentiment\", \"flight\", \"discourse\", \"lexicon\", \"grammar\", \"path\", \"NP\", \"coreference\", \"span\", \"head\", \"transition\", \"PP\", \"eat\", \"VP\", \"u\", \"H\", \"R\", \"parser\", \"parsing\", \"z\", \"Eisenstein\", \"sense\", \"Jacob\", \"PAST\", \"adverb\", \"turkish\", \"Gimpel\", \"Janet\", \"toe\", \"exceedingly\", \"at least 1\", \"octopus\", \"shuffle\", \"Section 7\", \"advise\", \"xavi\", \"Success\", \"vt\", \"kenization\", \"Tokenization\", \"flag\", \"NOUN\", \"SGD\", \"YES\", \"Choice\", \"transliterate\", \"Section 6.4\", \"PTB\", \"Japanese\", \"execution\", \"ti\", \"SV\", \"Rdin\", \"selectional\", \"auxiliary\", \"switch\", \"neuron\", \"MD\", \"lookup\", \"preference\", \"Viterbi\", \"tagging\", \"MEMM\", \"theme\", \"decode\", \"VB\", \"HMM\", \"UD\", \"ym\", \"prefix\", \"encoder\", \"morphological\", \"attribute\", \"alignment\", \"hidden\", \"transition\", \"tagger\", \"frame\", \"decoder\", \"cat\", \"forward\", \"adjective\", \"tagset\", \"rnn\", \"derivative\", \"sentiment\", \"logistic\", \"eat\", \"draft\", \"predicate\", \"Jacob\", \"observation\", \"similarity\", \"R\", \"cell\", \"head\", \"NP\", \"target\", \"regression\", \"Eisenstein\", \"z\", \"sense\", \"span\", \"grammar\", \"H\", \"CC\", \"parsing\", \"license\", \"VP\"], \"Freq\": [229.0, 436.0, 218.0, 152.0, 137.0, 224.0, 264.0, 170.0, 126.0, 142.0, 99.0, 76.0, 218.0, 273.0, 152.0, 644.0, 149.0, 199.0, 246.0, 154.0, 220.0, 169.0, 121.0, 236.0, 211.0, 330.0, 157.0, 127.0, 174.0, 784.0, 17.350486755371094, 5.294646263122559, 5.5625152587890625, 3.527879238128662, 22.340452194213867, 7.369568347930908, 15.342310905456543, 5.142741680145264, 15.633477210998535, 2.192847967147827, 2.567051649093628, 5.575153350830078, 1.238317847251892, 11.155733108520508, 4.643036365509033, 5.352182865142822, 2.0711278915405273, 16.499391555786133, 4.99358606338501, 5.215860366821289, 8.086893081665039, 8.133026123046875, 4.1100287437438965, 1.2003934383392334, 4.3685622215271, 2.848389148712158, 2.7932584285736084, 7.632012367248535, 7.296561241149902, 2.4137308597564697, 97.75149536132812, 8.443131446838379, 70.59532928466797, 57.26401901245117, 13.06922435760498, 12.864133834838867, 36.83236312866211, 9.43022346496582, 83.15068817138672, 20.425460815429688, 17.344562530517578, 89.71923065185547, 73.5361099243164, 83.20433807373047, 40.99229049682617, 79.13618469238281, 19.517240524291992, 17.850526809692383, 118.81888580322266, 23.492345809936523, 49.843441009521484, 19.067718505859375, 146.96131896972656, 28.473865509033203, 76.41826629638672, 180.81097412109375, 30.800003051757812, 50.5278205871582, 67.01365661621094, 32.77968978881836, 202.74822998046875, 63.036842346191406, 45.90296936035156, 51.42728805541992, 124.85446166992188, 62.48015213012695, 38.169090270996094, 62.57183074951172, 41.28853225708008, 80.77610778808594, 38.45675277709961, 57.72920227050781, 61.996788024902344, 58.886592864990234, 59.14087677001953, 62.0863151550293, 55.01646423339844, 62.27048873901367, 57.521026611328125, 57.062015533447266, 61.070980072021484, 57.26042175292969, 56.39945983886719, 56.81022644042969, 10.65200424194336, 10.435885429382324, 3.996583938598633, 2.3715157508850098, 8.559541702270508, 6.699545860290527, 220.1878204345703, 7.598620891571045, 3.247781991958618, 2.780963659286499, 9.924715042114258, 9.919179916381836, 2.7254793643951416, 57.357383728027344, 1.779908299446106, 1.341574788093567, 3.5357143878936768, 1.762171983718872, 2.1638023853302, 4.385942459106445, 6.488015174865723, 1.7250797748565674, 4.367518901824951, 1.7523959875106812, 1.6971460580825806, 2.142895460128784, 10.385598182678223, 3.0154237747192383, 2.141207695007324, 2.147686004638672, 122.79873657226562, 10.70413875579834, 26.374313354492188, 46.84136962890625, 21.84465217590332, 13.57641315460205, 7.326303958892822, 75.48540496826172, 12.265904426574707, 19.370025634765625, 80.71133422851562, 19.993616104125977, 28.825035095214844, 14.391608238220215, 221.50469970703125, 33.58163833618164, 156.93798828125, 57.06990432739258, 27.004745483398438, 46.324974060058594, 94.36177062988281, 80.02616882324219, 69.60860443115234, 47.69109344482422, 34.22956085205078, 98.42359161376953, 55.2587776184082, 191.13931274414062, 55.28293991088867, 33.62882614135742, 31.97048568725586, 59.49244689941406, 63.24229431152344, 54.281394958496094, 111.10917663574219, 50.20004653930664, 62.944671630859375, 61.35091781616211, 77.5554428100586, 61.03852844238281, 56.07781219482422, 53.687923431396484, 55.4205322265625, 56.15699768066406, 55.327274322509766, 52.14514923095703, 54.414615631103516, 53.99102783203125, 9.155515670776367, 10.379656791687012, 5.1883111000061035, 3.6280903816223145, 8.086783409118652, 8.989066123962402, 4.003131866455078, 72.2779769897461, 2.1877076625823975, 15.541298866271973, 15.9352445602417, 5.143856048583984, 3.3846797943115234, 5.048072338104248, 33.79267501831055, 2.058725595474243, 2.044121503829956, 2.4800682067871094, 3.2049741744995117, 6.759535312652588, 2.421875238418579, 14.960860252380371, 2.8016772270202637, 2.797001600265503, 2.3741698265075684, 10.031028747558594, 6.831155300140381, 17.86560821533203, 5.533034324645996, 2.7997825145721436, 70.89302062988281, 94.28565216064453, 21.05647850036621, 21.07918930053711, 45.3118896484375, 79.59075164794922, 29.308687210083008, 22.95977783203125, 21.267398834228516, 24.360923767089844, 12.794677734375, 73.25546264648438, 67.1529312133789, 219.53843688964844, 34.6425895690918, 63.212364196777344, 88.54618835449219, 61.702083587646484, 47.08168411254883, 66.55892944335938, 32.98392868041992, 145.4399871826172, 45.65787887573242, 84.55060577392578, 57.822654724121094, 44.84510803222656, 39.004249572753906, 86.74205017089844, 57.382965087890625, 60.68000030517578, 96.61053466796875, 43.972591400146484, 88.54789733886719, 60.29035949707031, 55.352256774902344, 58.716041564941406, 53.70237350463867, 46.67551040649414, 58.99121856689453, 53.8255615234375, 51.46681213378906, 58.39582443237305, 52.2187614440918, 13.1304349899292, 16.868877410888672, 14.954081535339355, 2.0113577842712402, 3.5879907608032227, 2.3974177837371826, 1.9633723497390747, 1.9466030597686768, 2.7167322635650635, 5.8760600090026855, 2.3043272495269775, 1.157679796218872, 1.8974744081497192, 3.8200318813323975, 5.592145919799805, 7.201732158660889, 1.1218929290771484, 1.4653120040893555, 1.1060773134231567, 4.121356964111328, 1.1019890308380127, 20.766767501831055, 1.100416660308838, 1.8304719924926758, 1.0892564058303833, 1.0911433696746826, 1.0907831192016602, 1.0943416357040405, 1.4580923318862915, 1.8094923496246338, 17.815570831298828, 8.20749568939209, 14.512519836425781, 6.031494617462158, 3.520695209503174, 8.346034049987793, 3.218668222427368, 79.7758560180664, 77.07789611816406, 5.2691192626953125, 6.572338104248047, 14.905267715454102, 81.021484375, 39.781681060791016, 10.543553352355957, 52.917659759521484, 27.213607788085938, 65.3814926147461, 30.148733139038086, 10.12238597869873, 37.10808181762695, 55.01884078979492, 45.45969009399414, 26.505327224731445, 33.759830474853516, 49.861175537109375, 20.29956817626953, 32.90398025512695, 29.015522003173828, 45.35780715942383, 58.621795654296875, 33.20204162597656, 54.71475601196289, 69.74439239501953, 93.39542388916016, 43.81926727294922, 90.28472137451172, 45.24612808227539, 119.7520751953125, 57.62260055541992, 57.37582015991211, 58.83546829223633, 51.33134841918945, 48.29597091674805, 40.05654525756836, 56.2429084777832, 42.00773620605469, 43.318565368652344, 40.50949478149414, 40.55220031738281, 42.94053268432617, 56.603118896484375, 41.92537307739258, 45.95719909667969, 40.92427444458008, 1.2198556661605835, 10.758310317993164, 1.104554533958435, 0.6488834619522095, 5.9827494621276855, 1.2579153776168823, 0.8470539450645447, 1.2511848211288452, 0.826036810874939, 0.8290413022041321, 1.2443677186965942, 1.0244128704071045, 0.8174163103103638, 0.6128115057945251, 3.6797406673431396, 0.6114737391471863, 1.3949888944625854, 0.7940837740898132, 3.3905107975006104, 3.1407546997070312, 1.1843575239181519, 0.5996487140655518, 0.5905182361602783, 0.591041088104248, 3.1718480587005615, 2.550264835357666, 1.9451926946640015, 30.49411392211914, 1.1818745136260986, 1.7406491041183472, 10.382193565368652, 8.02060317993164, 4.222252368927002, 7.634246826171875, 11.423365592956543, 3.4239065647125244, 8.461368560791016, 19.906766891479492, 24.743549346923828, 5.100447177886963, 11.935474395751953, 15.759114265441895, 10.280200958251953, 8.953682899475098, 4.923937797546387, 38.86655044555664, 10.785117149353027, 24.520769119262695, 11.531512260437012, 10.259119033813477, 15.409461975097656, 23.766801834106445, 37.985530853271484, 12.657382011413574, 25.03337287902832, 23.457538604736328, 19.61188507080078, 22.121919631958008, 16.795808792114258, 11.383195877075195, 10.401087760925293, 17.666040420532227, 27.885385513305664, 27.58565902709961, 22.833778381347656, 26.201980590820312, 20.438739776611328, 26.208168029785156, 16.588254928588867, 24.10382080078125, 23.714073181152344, 18.866792678833008, 31.38551902770996, 51.771671295166016, 24.881866455078125, 24.126062393188477, 24.605714797973633, 40.197410583496094, 33.094329833984375, 26.986560821533203, 33.887168884277344, 23.158916473388672, 23.980852127075195, 23.243440628051758, 22.522146224975586, 25.203676223754883], \"Total\": [229.0, 436.0, 218.0, 152.0, 137.0, 224.0, 264.0, 170.0, 126.0, 142.0, 99.0, 76.0, 218.0, 273.0, 152.0, 644.0, 149.0, 199.0, 246.0, 154.0, 220.0, 169.0, 121.0, 236.0, 211.0, 330.0, 157.0, 127.0, 174.0, 784.0, 32.408233642578125, 10.741043090820312, 11.65858268737793, 7.710156440734863, 48.828556060791016, 16.137977600097656, 33.837398529052734, 11.36730670928955, 34.57669448852539, 4.88021183013916, 5.771233081817627, 12.647393226623535, 2.8485758304595947, 25.748950958251953, 10.746240615844727, 12.40286636352539, 4.804551601409912, 38.45685958862305, 11.729838371276855, 12.256564140319824, 19.06688117980957, 19.177288055419922, 9.709287643432617, 2.8358778953552246, 10.347101211547852, 6.748493194580078, 6.622010707855225, 18.104522705078125, 17.316709518432617, 5.732544898986816, 236.57589721679688, 20.094810485839844, 172.11131286621094, 141.13064575195312, 31.620622634887695, 31.216859817504883, 92.59645080566406, 22.788806915283203, 219.01800537109375, 51.01981735229492, 42.98280334472656, 245.9561004638672, 199.60049438476562, 229.48373413085938, 108.11564636230469, 220.80743408203125, 49.37236785888672, 45.2780876159668, 364.56298828125, 61.848331451416016, 142.80551147460938, 49.2996826171875, 478.8529357910156, 77.15319061279297, 235.8215789794922, 644.55615234375, 84.39422607421875, 149.10121154785156, 206.74014282226562, 91.00574493408203, 784.94970703125, 197.60794067382812, 136.07333374023438, 155.99609375, 454.5158386230469, 201.79989624023438, 110.21932983398438, 205.07835388183594, 122.89189147949219, 301.01220703125, 113.4358901977539, 199.75637817382812, 222.23582458496094, 215.01390075683594, 220.1855926513672, 243.77774047851562, 203.5803680419922, 264.2082824707031, 226.653076171875, 223.32373046875, 292.013916015625, 246.67942810058594, 234.7505645751953, 330.00543212890625, 17.094148635864258, 17.82813262939453, 7.494030475616455, 4.665812969207764, 16.864107131958008, 13.241945266723633, 436.4736633300781, 15.383540153503418, 6.613047122955322, 5.71968936920166, 20.459304809570312, 20.475324630737305, 5.645869255065918, 118.93128967285156, 3.748783826828003, 2.8347465991973877, 7.569385528564453, 3.780261278152466, 4.6588592529296875, 9.497613906860352, 14.067066192626953, 3.7453174591064453, 9.50782299041748, 3.815458059310913, 3.6976394653320312, 4.692543029785156, 22.76346778869629, 6.61566686630249, 4.698047161102295, 4.738034725189209, 273.478271484375, 23.699920654296875, 59.103580474853516, 106.4449462890625, 49.43536376953125, 30.61626434326172, 16.342426300048828, 179.10433959960938, 27.72447967529297, 44.67008972167969, 198.32058715820312, 47.50471878051758, 70.51927185058594, 33.97080612182617, 644.55615234375, 84.80549621582031, 454.5158386230469, 157.5108642578125, 69.6236572265625, 128.05746459960938, 292.013916015625, 245.9561004638672, 211.81768798828125, 137.4835205078125, 93.35176086425781, 330.00543212890625, 165.41964721679688, 784.94970703125, 170.58360290527344, 92.58549499511719, 87.67024230957031, 199.75637817382812, 218.6076202392578, 178.14892578125, 478.8529357910156, 174.720947265625, 246.67942810058594, 239.9150848388672, 364.56298828125, 246.19378662109375, 215.01390075683594, 202.93101501464844, 216.44046020507812, 226.653076171875, 223.32373046875, 202.02655029296875, 243.77774047851562, 235.8215789794922, 17.59402084350586, 20.62126922607422, 10.438974380493164, 7.497193813323975, 16.865251541137695, 18.886734008789062, 8.453720092773438, 152.84536743164062, 4.664720058441162, 33.75376510620117, 35.14718246459961, 11.441475868225098, 7.534327507019043, 11.258234977722168, 76.20927429199219, 4.663595199584961, 4.663203716278076, 5.69126033782959, 7.382736682891846, 15.73044490814209, 5.660105228424072, 35.1644287109375, 6.625240325927734, 6.616681098937988, 5.6329779624938965, 23.812366485595703, 16.229955673217773, 42.53365707397461, 13.174234390258789, 6.680773735046387, 170.50245666503906, 229.48373413085938, 51.272926330566406, 52.07345199584961, 115.97395324707031, 220.1855926513672, 76.92593383789062, 59.968589782714844, 55.43742370605469, 64.86686706542969, 32.45573806762695, 222.5261688232422, 203.1525115966797, 784.94970703125, 100.13239288330078, 203.5803680419922, 301.01220703125, 199.60049438476562, 147.4258575439453, 220.80743408203125, 98.94523620605469, 644.55615234375, 149.13534545898438, 330.00543212890625, 205.82211303710938, 147.74514770507812, 123.12932586669922, 364.56298828125, 223.32373046875, 243.77774047851562, 478.8529357910156, 152.98060607910156, 436.4736633300781, 246.67942810058594, 218.79420471191406, 239.9150848388672, 216.44046020507812, 170.9436798095703, 264.2082824707031, 234.7505645751953, 222.23582458496094, 454.5158386230469, 292.013916015625, 27.80328369140625, 37.19700241088867, 33.39021301269531, 4.494752407073975, 8.055672645568848, 5.397993087768555, 4.53580904006958, 4.507220268249512, 6.299811363220215, 13.679364204406738, 5.381938457489014, 2.721564531326294, 4.4907732009887695, 9.092327117919922, 13.37803840637207, 17.260665893554688, 2.693540334701538, 3.5473783016204834, 2.691269874572754, 10.036556243896484, 2.7024435997009277, 51.002601623535156, 2.719649076461792, 4.526695251464844, 2.6942524909973145, 2.7076070308685303, 2.706721305847168, 2.7263290882110596, 3.6502442359924316, 4.5324578285217285, 44.91667556762695, 20.697607040405273, 37.54005813598633, 15.372834205627441, 8.928624153137207, 21.725688934326172, 8.163290023803711, 224.61383056640625, 218.4238739013672, 13.612582206726074, 17.152101516723633, 40.773338317871094, 246.19378662109375, 116.06478881835938, 28.46736717224121, 159.81297302246094, 78.925537109375, 211.81768798828125, 94.90666198730469, 28.103504180908203, 121.27215576171875, 190.6949920654297, 154.10833740234375, 86.52938842773438, 114.93475341796875, 180.88795471191406, 64.07353973388672, 113.50770568847656, 99.44180297851562, 170.9436798095703, 234.7505645751953, 117.26639556884766, 218.6076202392578, 301.01220703125, 454.5158386230469, 178.14892578125, 478.8529357910156, 187.12232971191406, 784.94970703125, 273.478271484375, 292.013916015625, 330.00543212890625, 264.2082824707031, 243.77774047851562, 174.720947265625, 364.56298828125, 197.60794067382812, 215.01390075683594, 202.02655029296875, 203.1525115966797, 246.67942810058594, 644.55615234375, 239.9150848388672, 436.4736633300781, 226.653076171875, 4.306884288787842, 41.71502685546875, 4.372900485992432, 2.624011993408203, 24.497055053710938, 5.226786136627197, 3.5293703079223633, 5.214847564697266, 3.4527740478515625, 3.504964590072632, 5.2627854347229, 4.365706920623779, 3.523383617401123, 2.641779899597168, 15.872050285339355, 2.6381986141204834, 6.147141456604004, 3.5091774463653564, 14.998750686645508, 13.905983924865723, 5.267721652984619, 2.669659376144409, 2.6296610832214355, 2.6364810466766357, 14.197379112243652, 11.51251220703125, 8.782591819763184, 137.9917755126953, 5.3484697341918945, 7.978039741516113, 47.693763732910156, 37.387237548828125, 19.5063419342041, 35.90644836425781, 54.73686599731445, 15.864082336425781, 40.793678283691406, 99.93798828125, 126.89454650878906, 24.169965744018555, 59.48198318481445, 80.3174819946289, 51.90593338012695, 45.126869201660156, 23.750717163085938, 229.48373413085938, 56.332725524902344, 142.80551147460938, 61.866661071777344, 56.05750274658203, 91.00574493408203, 152.98060607910156, 264.2082824707031, 74.02999114990234, 169.08892822265625, 157.38829040527344, 127.9128646850586, 149.13534545898438, 106.241943359375, 65.97613525390625, 59.20296096801758, 118.55229187011719, 218.6076202392578, 218.4238739013672, 174.720947265625, 218.79420471191406, 154.10833740234375, 226.653076171875, 115.23294830322266, 206.74014282226562, 202.02655029296875, 141.13064575195312, 330.00543212890625, 784.94970703125, 236.57589721679688, 224.61383056640625, 239.9150848388672, 644.55615234375, 436.4736633300781, 292.013916015625, 478.8529357910156, 215.01390075683594, 235.8215789794922, 246.67942810058594, 222.23582458496094, 364.56298828125], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -7.521100044250488, -8.708100318908691, -8.658699989318848, -9.114100456237793, -7.268400192260742, -8.377400398254395, -7.644100189208984, -8.737199783325195, -7.62529993057251, -9.589599609375, -9.432000160217285, -8.656399726867676, -10.16100025177002, -7.962800025939941, -8.839400291442871, -8.69729995727539, -9.646699905395508, -7.571400165557861, -8.766599655151367, -8.723099708557129, -8.284500122070312, -8.278800010681152, -8.961299896240234, -10.192099571228027, -8.900300025939941, -9.32800006866455, -9.347599983215332, -8.342399597167969, -8.387399673461914, -9.493599891662598, -5.792300224304199, -8.241399765014648, -6.117800235748291, -6.327099800109863, -7.804500102996826, -7.820300102233887, -6.768400192260742, -8.130800247192383, -5.954100131988525, -7.357999801635742, -7.521500110626221, -5.8780999183654785, -6.077000141143799, -5.953499794006348, -6.661399841308594, -6.003600120544434, -7.403500080108643, -7.492700099945068, -5.5971999168396, -7.218100070953369, -6.46589994430542, -7.426799774169922, -5.3846001625061035, -7.0258002281188965, -6.03849983215332, -5.177299976348877, -6.947199821472168, -6.452199935913086, -6.169899940490723, -6.885000228881836, -5.06279993057251, -6.230999946594238, -6.5482001304626465, -6.434599876403809, -5.547599792480469, -6.2399001121521, -6.732699871063232, -6.238399982452393, -6.654200077056885, -5.983099937438965, -6.725200176239014, -6.318999767303467, -6.247700214385986, -6.299200057983398, -6.2947998046875, -6.246200084686279, -6.367099761962891, -6.243299961090088, -6.3225998878479, -6.330599784851074, -6.262700080871582, -6.327199935913086, -6.342299938201904, -6.335000038146973, -7.973899841308594, -7.9944000244140625, -8.95419979095459, -9.476099967956543, -8.19260025024414, -8.437600135803223, -4.945199966430664, -8.311699867248535, -9.161700248718262, -9.316800117492676, -8.044599533081055, -8.04520034790039, -9.336999893188477, -6.290299892425537, -9.763099670410156, -10.04580020904541, -9.076700210571289, -9.773099899291992, -9.56779956817627, -8.861200332641602, -8.46969985961914, -9.794400215148926, -8.865400314331055, -9.778599739074707, -9.810700416564941, -9.577500343322754, -7.999199867248535, -9.235899925231934, -9.578300476074219, -9.575200080871582, -5.529099941253662, -7.968999862670898, -7.067200183868408, -6.4928998947143555, -7.25570011138916, -7.731299877166748, -8.348199844360352, -6.015699863433838, -7.832799911499023, -7.375899791717529, -5.948800086975098, -7.344200134277344, -6.978400230407715, -7.672999858856201, -4.939199924468994, -6.825699806213379, -5.28380012512207, -6.295400142669678, -7.043600082397461, -6.504000186920166, -5.792500019073486, -5.957300186157227, -6.096700191497803, -6.474899768829346, -6.80649995803833, -5.750400066375732, -6.327600002288818, -5.086599826812744, -6.327199935913086, -6.82420015335083, -6.874800205230713, -6.253799915313721, -6.192699909210205, -6.3454999923706055, -5.6290998458862305, -6.423600196838379, -6.197400093078613, -6.2230000495910645, -5.98859977722168, -6.228099822998047, -6.312900066375732, -6.356400012969971, -6.324699878692627, -6.311500072479248, -6.326399803161621, -6.3856000900268555, -6.3429999351501465, -6.350800037384033, -7.949999809265137, -7.82450008392334, -8.517999649047852, -8.875699996948242, -8.07409954071045, -7.968400001525879, -8.777299880981445, -5.883900165557861, -9.381500244140625, -7.420899868011475, -7.3958001136779785, -8.526599884033203, -8.945099830627441, -8.54539966583252, -6.644100189208984, -9.442299842834473, -9.449399948120117, -9.256099700927734, -8.999699592590332, -8.253399848937988, -9.279800415039062, -7.458899974822998, -9.134200096130371, -9.1358003616333, -9.299699783325195, -7.858699798583984, -8.242899894714355, -7.281499862670898, -8.45359992980957, -9.13479995727539, -5.903200149536133, -5.618000030517578, -7.117199897766113, -7.116099834442139, -6.350800037384033, -5.787499904632568, -6.786499977111816, -7.030600070953369, -7.1072001457214355, -6.971399784088135, -7.615300178527832, -5.8703999519348145, -5.957399845123291, -4.772900104522705, -6.61929988861084, -6.017899990081787, -5.6809000968933105, -6.042099952697754, -6.3125, -5.966300010681152, -6.668399810791016, -5.184599876403809, -6.343200206756592, -5.7270002365112305, -6.10699987411499, -6.361199855804443, -6.500699996948242, -5.701399803161621, -6.11460018157959, -6.058800220489502, -5.593699932098389, -6.380799770355225, -5.680799961090088, -6.065199851989746, -6.150700092315674, -6.091700077056885, -6.1809000968933105, -6.321199893951416, -6.086999893188477, -6.178599834442139, -6.223400115966797, -6.097099781036377, -6.208899974822998, -7.510300159454346, -7.259699821472168, -7.380199909210205, -9.38640022277832, -8.807600021362305, -9.210800170898438, -9.410499572753906, -9.419099807739258, -9.085800170898438, -8.314299583435059, -9.250399589538574, -9.938799858093262, -9.444700241088867, -8.74489974975586, -8.363800048828125, -8.110899925231934, -9.970199584960938, -9.703100204467773, -9.984399795532227, -8.668999671936035, -9.988100051879883, -7.051799774169922, -9.989500045776367, -9.480600357055664, -9.999699592590332, -9.998000144958496, -9.998299598693848, -9.995100021362305, -9.708100318908691, -9.492199897766113, -7.205100059509277, -7.980199813842773, -7.410200119018555, -8.288200378417969, -8.826499938964844, -7.963399887084961, -8.916199684143066, -5.705999851226807, -5.7403998374938965, -8.423299789428711, -8.202300071716309, -7.383500099182129, -5.690499782562256, -6.401800155639648, -7.729700088500977, -6.116499900817871, -6.781499862670898, -5.90500020980835, -6.679100036621094, -7.770500183105469, -6.471399784088135, -6.077499866485596, -6.268400192260742, -6.8078999519348145, -6.565899848937988, -6.176000118255615, -7.0746002197265625, -6.591599941253662, -6.717400074005127, -6.270599842071533, -6.014100074768066, -6.582600116729736, -6.083099842071533, -5.840400218963623, -5.548399925231934, -6.305099964141846, -5.582200050354004, -6.273099899291992, -5.299799919128418, -6.031300067901611, -6.035600185394287, -6.010499954223633, -6.146900177001953, -6.207900047302246, -6.394899845123291, -6.055500030517578, -6.347400188446045, -6.3165998458862305, -6.383699893951416, -6.382599830627441, -6.325399875640869, -6.049099922180176, -6.349299907684326, -6.257500171661377, -6.373499870300293, -9.27810001373291, -7.101200103759766, -9.377400398254395, -9.90939998626709, -7.688000202178955, -9.247400283813477, -9.642900466918945, -9.252799987792969, -9.668000221252441, -9.664400100708008, -9.258299827575684, -9.452799797058105, -9.678500175476074, -9.96660041809082, -8.173999786376953, -9.968799591064453, -9.144000053405762, -9.70740032196045, -8.255900382995605, -8.33240032196045, -9.307700157165527, -9.988300323486328, -10.003600120544434, -10.002799987792969, -8.322600364685059, -8.54069995880127, -8.81149959564209, -6.059299945831299, -9.309800148010254, -8.922599792480469, -7.1367998123168945, -7.394899845123291, -8.036499977111816, -7.444200038909912, -7.041200160980225, -8.246100425720215, -7.341400146484375, -6.485799789428711, -6.2683000564575195, -7.847599983215332, -6.997399806976318, -6.7195000648498535, -7.146699905395508, -7.284800052642822, -7.882800102233887, -5.816699981689453, -7.098700046539307, -6.277400016784668, -7.031799793243408, -7.14870023727417, -6.7418999671936035, -6.308599948883057, -5.839700222015381, -6.938600063323975, -6.256700038909912, -6.321700096130371, -6.500699996948242, -6.380300045013428, -6.655799865722656, -7.0447001457214355, -7.135000228881836, -6.605199813842773, -6.148799896240234, -6.159599781036377, -6.348599910736084, -6.210999965667725, -6.459499835968018, -6.2108001708984375, -6.6682000160217285, -6.29449987411499, -6.310800075531006, -6.5395002365112305, -6.0304999351501465, -5.53000020980835, -6.262700080871582, -6.293600082397461, -6.273900032043457, -5.783100128173828, -5.977499961853027, -6.18149995803833, -5.953800201416016, -6.334499835968018, -6.299600124359131, -6.330900192260742, -6.362400054931641, -6.249899864196777], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.7443000078201294, 0.6617000102996826, 0.6291000247001648, 0.5871999859809875, 0.5871999859809875, 0.5853000283241272, 0.5781000256538391, 0.5759000182151794, 0.5752999782562256, 0.569100022315979, 0.5590000152587891, 0.550000011920929, 0.5360000133514404, 0.5327000021934509, 0.5299000144004822, 0.5286999940872192, 0.5275999903678894, 0.5228999853134155, 0.5151000022888184, 0.5146999955177307, 0.5113999843597412, 0.5113000273704529, 0.5094000101089478, 0.5094000101089478, 0.5067999958992004, 0.5065000057220459, 0.5059000253677368, 0.505299985408783, 0.504800021648407, 0.5041000247001648, 0.4853000044822693, 0.5019999742507935, 0.4778999984264374, 0.46709999442100525, 0.4855000078678131, 0.48260000348091125, 0.4472000002861023, 0.48669999837875366, 0.40059998631477356, 0.4537000060081482, 0.46160000562667847, 0.36059999465942383, 0.37049999833106995, 0.3546000123023987, 0.3993000090122223, 0.34299999475479126, 0.4410000145435333, 0.4383000135421753, 0.24799999594688416, 0.4011000096797943, 0.3165000081062317, 0.41920000314712524, 0.18790000677108765, 0.37229999899864197, 0.24220000207424164, 0.09799999743700027, 0.3610999882221222, 0.28700000047683716, 0.24250000715255737, 0.3479999899864197, 0.015399999916553497, 0.226500004529953, 0.2824000120162964, 0.25940001010894775, 0.07699999958276749, 0.19670000672340393, 0.3086000084877014, 0.18199999630451202, 0.2784000039100647, 0.053599998354911804, 0.2874000072479248, 0.12780000269412994, 0.09239999949932098, 0.07400000095367432, 0.054499998688697815, 0.00139999995008111, 0.06069999933242798, -0.07620000094175339, -0.002199999988079071, 0.004600000102072954, -0.195700004696846, -0.09139999747276306, -0.05700000002980232, -0.3903000056743622, 0.9312000274658203, 0.8687000274658203, 0.775600016117096, 0.7275000214576721, 0.7261000275611877, 0.7228999733924866, 0.7200000286102295, 0.6988999843597412, 0.6930999755859375, 0.6830999851226807, 0.6808000206947327, 0.6794999837875366, 0.6758999824523926, 0.675000011920929, 0.6593999862670898, 0.6560999751091003, 0.6430000066757202, 0.640999972820282, 0.6373000144958496, 0.631600022315979, 0.630299985408783, 0.6290000081062317, 0.6262999773025513, 0.6261000037193298, 0.6255000233650208, 0.6204000115394592, 0.6194999814033508, 0.6184999942779541, 0.618399977684021, 0.6129999756813049, 0.6035000085830688, 0.6093999743461609, 0.5972999930381775, 0.5834000110626221, 0.5874999761581421, 0.5910000205039978, 0.6018999814987183, 0.5401999950408936, 0.588699996471405, 0.5685999989509583, 0.5052000284194946, 0.5388000011444092, 0.5095999836921692, 0.5454000234603882, 0.3361000120639801, 0.47780001163482666, 0.3407999873161316, 0.3889999985694885, 0.4571000039577484, 0.3874000012874603, 0.27459999918937683, 0.28139999508857727, 0.2913999855518341, 0.34549999237060547, 0.4009000062942505, 0.19439999759197235, 0.3077999949455261, -0.00839999970048666, 0.2775000035762787, 0.39149999618530273, 0.3955000042915344, 0.19300000369548798, 0.1639000028371811, 0.21580000221729279, -0.056699998676776886, 0.15700000524520874, 0.03840000182390213, 0.04050000011920929, -0.14350000023841858, 0.009600000455975533, 0.06030000001192093, 0.07450000196695328, 0.04190000146627426, 0.008999999612569809, 0.008899999782443047, 0.04989999905228615, -0.09539999812841415, -0.07000000029802322, 0.9262999892234802, 0.8930000066757202, 0.880299985408783, 0.8536999821662903, 0.8445000052452087, 0.8370000123977661, 0.8319000005722046, 0.8306000232696533, 0.8223000168800354, 0.8039000034332275, 0.7885000109672546, 0.7799999713897705, 0.7792999744415283, 0.777400016784668, 0.7662000060081482, 0.7617999911308289, 0.7547000050544739, 0.7487999796867371, 0.7450000047683716, 0.7347999811172485, 0.7305999994277954, 0.7249000072479248, 0.7188000082969666, 0.7184000015258789, 0.715499997138977, 0.7149999737739563, 0.7141000032424927, 0.7121000289916992, 0.7120000123977661, 0.7098000049591064, 0.7019000053405762, 0.6899999976158142, 0.6894999742507935, 0.6751000285148621, 0.6396999955177307, 0.5619000196456909, 0.6144999861717224, 0.6194000244140625, 0.621399998664856, 0.6000999808311462, 0.6485999822616577, 0.4684000015258789, 0.4724999964237213, 0.305400013923645, 0.5181000232696533, 0.4099000096321106, 0.35589998960494995, 0.40549999475479126, 0.43799999356269836, 0.38029998540878296, 0.48089998960494995, 0.09070000052452087, 0.39579999446868896, 0.21770000457763672, 0.30979999899864197, 0.3871999979019165, 0.42989999055862427, 0.1437000036239624, 0.22059999406337738, 0.18880000710487366, -0.021199999377131462, 0.3327000141143799, -0.015699999406933784, 0.17059999704360962, 0.20509999990463257, 0.17190000414848328, 0.18559999763965607, 0.28139999508857727, 0.08009999990463257, 0.10670000314712524, 0.11670000106096268, -0.4724999964237213, -0.14190000295639038, 0.9083999991416931, 0.867900013923645, 0.855400025844574, 0.8546000123023987, 0.8499000072479248, 0.847000002861023, 0.8213000297546387, 0.819100022315979, 0.8176000118255615, 0.8136000037193298, 0.8104000091552734, 0.8039000034332275, 0.7971000075340271, 0.7914999723434448, 0.7864000201225281, 0.784500002861023, 0.782800018787384, 0.7745000123977661, 0.7695000171661377, 0.7685999870300293, 0.7616000175476074, 0.7601000070571899, 0.7537999749183655, 0.7531999945640564, 0.753000020980835, 0.7498000264167786, 0.7498000264167786, 0.7458000183105469, 0.7409999966621399, 0.7404000163078308, 0.7339000105857849, 0.7336999773979187, 0.708299994468689, 0.7229999899864197, 0.7279999852180481, 0.7019000053405762, 0.7279999852180481, 0.6234999895095825, 0.6169999837875366, 0.7095000147819519, 0.699400007724762, 0.6523000001907349, 0.5472000241279602, 0.5878999829292297, 0.6654000282287598, 0.5533999800682068, 0.5939000248908997, 0.4832000136375427, 0.511900007724762, 0.637499988079071, 0.47440001368522644, 0.4156999886035919, 0.43779999017715454, 0.4754999876022339, 0.4336000084877014, 0.3700000047683716, 0.5091999769210815, 0.4203999936580658, 0.4268999993801117, 0.3319000005722046, 0.2712000012397766, 0.3968000113964081, 0.273499995470047, 0.19629999995231628, 0.0763000026345253, 0.25609999895095825, -0.009800000116229057, 0.23899999260902405, -0.2214999943971634, 0.10130000114440918, 0.03150000050663948, -0.065700002014637, 0.02019999921321869, 0.03970000147819519, 0.1858000010251999, -0.21040000021457672, 0.11020000278949738, 0.05649999901652336, 0.05180000141263008, 0.04729999974370003, -0.08959999680519104, -0.7738000154495239, -0.08569999784231186, -0.5924000144004822, -0.05299999937415123, 1.0054999589920044, 0.9118000268936157, 0.890999972820282, 0.8697999715805054, 0.8572999835014343, 0.8425999879837036, 0.839900016784668, 0.8396000266075134, 0.8367000222206116, 0.8252999782562256, 0.8248999714851379, 0.817300021648407, 0.805899977684021, 0.8058000206947327, 0.8052999973297119, 0.8050000071525574, 0.7839000225067139, 0.781000018119812, 0.7799999713897705, 0.7791000008583069, 0.7746000289916992, 0.7735999822616577, 0.7734000086784363, 0.7717000246047974, 0.7681999802589417, 0.7597000002861023, 0.7595999836921692, 0.7573000192642212, 0.7573000192642212, 0.7444999814033508, 0.7422999739646912, 0.7276999950408936, 0.7365999817848206, 0.7186999917030334, 0.7001000046730042, 0.7336999773979187, 0.6940000057220459, 0.6535000205039978, 0.6322000026702881, 0.7111999988555908, 0.6607999801635742, 0.6384000182151794, 0.6478000283241272, 0.6496000289916992, 0.6934999823570251, 0.49129998683929443, 0.6139000058174133, 0.5049999952316284, 0.5871000289916992, 0.5687999725341797, 0.4909999966621399, 0.4050000011920929, 0.32739999890327454, 0.5006999969482422, 0.35679998993873596, 0.36340001225471497, 0.3917999863624573, 0.3587000072002411, 0.42239999771118164, 0.5098000168800354, 0.527899980545044, 0.36329999566078186, 0.2078000009059906, 0.19779999554157257, 0.23199999332427979, 0.14470000565052032, 0.2467000037431717, 0.1096000000834465, 0.3287000060081482, 0.11789999902248383, 0.12460000067949295, 0.2547000050544739, -0.08579999953508377, -0.45179998874664307, 0.014800000004470348, 0.03590000048279762, -0.010300000198185444, -0.5077999830245972, -0.3124000132083893, -0.1145000010728836, -0.3813999891281128, 0.038600001484155655, -0.018799999728798866, -0.09510000050067902, -0.022299999371170998, -0.40470001101493835]}, \"token.table\": {\"Topic\": [1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 4, 1, 2, 3, 4, 5, 1, 2, 4, 1, 2, 3, 4, 2, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 4, 1, 2, 3, 4, 1, 2, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 4, 1, 2, 3, 4, 5, 1, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 2, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 4, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 4, 5, 1, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5], \"Freq\": [0.08740130811929703, 0.3496052324771881, 0.43700656294822693, 0.08740130811929703, 0.08740130811929703, 0.3981127440929413, 0.29858455061912537, 0.04976409301161766, 0.09952818602323532, 0.09952818602323532, 0.18866701424121857, 0.4009174108505249, 0.17687532305717468, 0.165083646774292, 0.082541823387146, 0.36679357290267944, 0.36679357290267944, 0.41957569122314453, 0.26223480701446533, 0.10489392280578613, 0.10489392280578613, 0.10489392280578613, 0.15873491764068604, 0.31746983528137207, 0.15873491764068604, 0.4762047231197357, 0.15873491764068604, 0.32693126797676086, 0.2692375183105469, 0.12179791927337646, 0.17308126389980316, 0.1025666743516922, 0.12249962985515594, 0.2449992597103119, 0.12249962985515594, 0.36749887466430664, 0.12249962985515594, 0.5198196172714233, 0.17327319085597992, 0.17327319085597992, 0.17327319085597992, 0.17327319085597992, 0.10753554850816727, 0.29572275280952454, 0.0806516632437706, 0.45702606439590454, 0.05376777425408363, 0.3222775459289551, 0.2289866805076599, 0.18658173084259033, 0.15689827501773834, 0.10177185386419296, 0.37457960844039917, 0.37457960844039917, 0.37457960844039917, 0.11199934035539627, 0.22399868071079254, 0.11199934035539627, 0.4479973614215851, 0.11199934035539627, 0.22063083946704865, 0.22063083946704865, 0.22063083946704865, 0.4412616789340973, 0.41605061292648315, 0.20802530646324158, 0.23402847349643707, 0.07800948619842529, 0.052006326615810394, 0.4652789831161499, 0.18611159920692444, 0.18611159920692444, 0.09305579960346222, 0.09305579960346222, 0.22091148793697357, 0.25425663590431213, 0.2459203451871872, 0.17506194114685059, 0.10420353710651398, 0.381095826625824, 0.381095826625824, 0.27440086007118225, 0.26044827699661255, 0.15812930464744568, 0.19998706877231598, 0.10696982592344284, 0.059293512254953384, 0.2964675724506378, 0.4743480980396271, 0.059293512254953384, 0.11858702450990677, 0.2880766987800598, 0.26591697335243225, 0.11079873144626617, 0.13295848667621613, 0.1994377225637436, 0.21437513828277588, 0.42875027656555176, 0.21437513828277588, 0.24476169049739838, 0.42833298444747925, 0.061190422624349594, 0.18357127904891968, 0.061190422624349594, 0.2558977007865906, 0.24707363545894623, 0.20295333862304688, 0.1808931976556778, 0.11471275985240936, 0.23160579800605774, 0.26610028743743896, 0.21682244539260864, 0.17740018665790558, 0.10841122269630432, 0.2041061669588089, 0.24492740631103516, 0.12246370315551758, 0.16328492760658264, 0.24492740631103516, 0.17372402548789978, 0.17372402548789978, 0.17372402548789978, 0.17372402548789978, 0.26058605313301086, 0.14386789500713348, 0.17983487248420715, 0.14386789500713348, 0.4675706624984741, 0.07193394750356674, 0.2226787954568863, 0.2226787954568863, 0.4453575909137726, 0.1985272914171219, 0.41123509407043457, 0.1701662540435791, 0.1559857279062271, 0.05672208219766617, 0.058499548584222794, 0.6434950232505798, 0.17549864947795868, 0.058499548584222794, 0.058499548584222794, 0.14692290127277374, 0.22038434445858002, 0.14692290127277374, 0.36730724573135376, 0.07346145063638687, 0.15115633606910706, 0.45346903800964355, 0.15115633606910706, 0.15115633606910706, 0.15115633606910706, 0.39550700783729553, 0.1628558337688446, 0.1628558337688446, 0.11632559448480606, 0.13959071040153503, 0.2923075556755066, 0.21923066675662994, 0.12788456678390503, 0.1461537778377533, 0.20096145570278168, 0.2896156311035156, 0.20686830580234528, 0.1654946506023407, 0.1654946506023407, 0.20686830580234528, 0.35276520252227783, 0.35276520252227783, 0.22248166799545288, 0.22248166799545288, 0.22248166799545288, 0.44496333599090576, 0.14968326687812805, 0.14968326687812805, 0.44904977083206177, 0.14968326687812805, 0.13179011642932892, 0.43930038809776306, 0.17572015523910522, 0.17572015523910522, 0.043930038809776306, 0.2137768417596817, 0.252645343542099, 0.28179672360420227, 0.16033262014389038, 0.09231272339820862, 0.3071996569633484, 0.23893307149410248, 0.16579028964042664, 0.18041884899139404, 0.1072760671377182, 0.20001666247844696, 0.20001666247844696, 0.20001666247844696, 0.20001666247844696, 0.20001666247844696, 0.25861528515815735, 0.24332769215106964, 0.2802727222442627, 0.15287603437900543, 0.06624628603458405, 0.3629143536090851, 0.19441840052604675, 0.2851469814777374, 0.09072858840227127, 0.06480613350868225, 0.23101040720939636, 0.2541114389896393, 0.24949124455451965, 0.16632749140262604, 0.09702437371015549, 0.14427682757377625, 0.43283048272132874, 0.21641524136066437, 0.1803460419178009, 0.03606920689344406, 0.23218640685081482, 0.23218640685081482, 0.23218640685081482, 0.23218640685081482, 0.23218640685081482, 0.1707106977701187, 0.1707106977701187, 0.4552285373210907, 0.11380713433027267, 0.08535534888505936, 0.3853980302810669, 0.1622728556394577, 0.2636933922767639, 0.12170463800430298, 0.08113642781972885, 0.254330039024353, 0.22151325643062592, 0.2502279281616211, 0.19690066576004028, 0.0738377496600151, 0.2818983197212219, 0.2818983197212219, 0.2113066017627716, 0.2817421555519104, 0.1408710777759552, 0.1408710777759552, 0.2113066017627716, 0.22046783566474915, 0.22046783566474915, 0.4409356713294983, 0.21310406923294067, 0.42620813846588135, 0.21310406923294067, 0.21310406923294067, 0.3693298101425171, 0.3693298101425171, 0.10468096286058426, 0.2747875154018402, 0.47106432914733887, 0.06542559713125229, 0.08505327999591827, 0.13724790513515472, 0.1568547487258911, 0.1764615923166275, 0.411743700504303, 0.13724790513515472, 0.21284331381320953, 0.25739189982414246, 0.21284331381320953, 0.2029436230659485, 0.11879626661539078, 0.22771722078323364, 0.15181148052215576, 0.4554344415664673, 0.15181148052215576, 0.07590574026107788, 0.2317407727241516, 0.2317407727241516, 0.1158703863620758, 0.4055463373661041, 0.0579351931810379, 0.13000908493995667, 0.5200363397598267, 0.26001816987991333, 0.13000908493995667, 0.06500454246997833, 0.14662545919418335, 0.1759505420923233, 0.4164162874221802, 0.1583554893732071, 0.10557032376527786, 0.19071297347545624, 0.12714198231697083, 0.4449969530105591, 0.12714198231697083, 0.12714198231697083, 0.2506881356239319, 0.12534406781196594, 0.2506881356239319, 0.12534406781196594, 0.2506881356239319, 0.21930843591690063, 0.21930843591690063, 0.07310280948877335, 0.43861687183380127, 0.07310280948877335, 0.09579484909772873, 0.19158969819545746, 0.47897425293922424, 0.09579484909772873, 0.09579484909772873, 0.15113316476345062, 0.15113316476345062, 0.45339950919151306, 0.15113316476345062, 0.15113316476345062, 0.4337594211101532, 0.12393126636743546, 0.18589690327644348, 0.12393126636743546, 0.12393126636743546, 0.23658223450183868, 0.11829111725091934, 0.47316446900367737, 0.11829111725091934, 0.11829111725091934, 0.14382298290729523, 0.07191149145364761, 0.28764596581459045, 0.21573446691036224, 0.21573446691036224, 0.37393873929977417, 0.18696936964988708, 0.18696936964988708, 0.18696936964988708, 0.18696936964988708, 0.4418785274028778, 0.16570444405078888, 0.16570444405078888, 0.11046963185071945, 0.11046963185071945, 0.15093791484832764, 0.15093791484832764, 0.4528137743473053, 0.15093791484832764, 0.15093791484832764, 0.37929344177246094, 0.37929344177246094, 0.37929344177246094, 0.37929344177246094, 0.19001345336437225, 0.19001345336437225, 0.19001345336437225, 0.19001345336437225, 0.19001345336437225, 0.07551760226488113, 0.5286232233047485, 0.226552814245224, 0.07551760226488113, 0.07551760226488113, 0.233207568526268, 0.1749056875705719, 0.116603784263134, 0.4081132709980011, 0.116603784263134, 0.37853267788887024, 0.37853267788887024, 0.37853267788887024, 0.05683749169111252, 0.17051246762275696, 0.5115374326705933, 0.11367498338222504, 0.11367498338222504, 0.17483466863632202, 0.5245040059089661, 0.17483466863632202, 0.17483466863632202, 0.348885178565979, 0.1744425892829895, 0.1744425892829895, 0.1744425892829895, 0.1744425892829895, 0.16267724335193634, 0.3253544867038727, 0.16267724335193634, 0.16267724335193634, 0.16267724335193634, 0.16841596364974976, 0.16841596364974976, 0.25262394547462463, 0.2105199545621872, 0.2105199545621872, 0.23118744790554047, 0.23118744790554047, 0.15412496030330658, 0.17339058220386505, 0.19265620410442352, 0.1465846449136734, 0.21556565165519714, 0.3880181610584259, 0.17245250940322876, 0.06898100674152374, 0.3264182209968567, 0.21395479142665863, 0.2386418879032135, 0.15360857546329498, 0.06857525557279587, 0.13009962439537048, 0.26019924879074097, 0.13009962439537048, 0.39029887318611145, 0.06504981219768524, 0.29017993807792664, 0.12007445842027664, 0.29017993807792664, 0.1000620499253273, 0.2001240998506546, 0.11859507113695145, 0.5336778163909912, 0.17789261043071747, 0.11859507113695145, 0.05929753556847572, 0.10333980619907379, 0.4415428042411804, 0.22546866536140442, 0.15031243860721588, 0.08455075323581696, 0.18983538448810577, 0.18983538448810577, 0.18983538448810577, 0.18983538448810577, 0.18983538448810577, 0.30180054903030396, 0.052487049251794815, 0.446139931678772, 0.052487049251794815, 0.14433938264846802, 0.37116044759750366, 0.12994466722011566, 0.2030385583639145, 0.31674015522003174, 0.2192816287279129, 0.12182313203811646, 0.24472443759441376, 0.25413691997528076, 0.19766204059123993, 0.1411871761083603, 0.1600121259689331, 0.19177740812301636, 0.23972177505493164, 0.14383305609226227, 0.1678052395582199, 0.2636939585208893, 0.22905798256397247, 0.22905798256397247, 0.22905798256397247, 0.22905798256397247, 0.22905798256397247, 0.17570801079273224, 0.17570801079273224, 0.3514160215854645, 0.17570801079273224, 0.17738237977027893, 0.2027227282524109, 0.17738237977027893, 0.3420946002006531, 0.10136136412620544, 0.3626144826412201, 0.1538364440202713, 0.17581307888031006, 0.14284811913967133, 0.16482475399971008, 0.12137060612440109, 0.44502556324005127, 0.22251278162002563, 0.18205590546131134, 0.0404568687081337, 0.19597427546977997, 0.45727330446243286, 0.19597427546977997, 0.13064950704574585, 0.06532475352287292, 0.23426982760429382, 0.3592137396335602, 0.1952248513698578, 0.1327528953552246, 0.07808994501829147, 0.1396729052066803, 0.36187979578971863, 0.22855566442012787, 0.2031605839729309, 0.06983645260334015, 0.09775502979755402, 0.4887751638889313, 0.19551005959510803, 0.09775502979755402, 0.09775502979755402, 0.19176015257835388, 0.19176015257835388, 0.19176015257835388, 0.19176015257835388, 0.4162719249725342, 0.2081359624862671, 0.2081359624862671, 0.2081359624862671, 0.18342936038970947, 0.200104758143425, 0.38353410363197327, 0.13340316712856293, 0.1000523790717125, 0.4079446792602539, 0.16317786276340485, 0.16317786276340485, 0.08158893138170242, 0.16317786276340485, 0.26758238673210144, 0.23190473020076752, 0.16054943203926086, 0.16054943203926086, 0.17838825285434723, 0.18722966313362122, 0.2942180335521698, 0.18722966313362122, 0.13373547792434692, 0.21397675573825836, 0.20213201642036438, 0.20213201642036438, 0.33351781964302063, 0.12127920985221863, 0.14149241149425507, 0.05609112232923508, 0.560911238193512, 0.16827337443828583, 0.05609112232923508, 0.11218224465847015, 0.17168082296848297, 0.22073248028755188, 0.14715498685836792, 0.3678874671459198, 0.09810332208871841, 0.20451506972312927, 0.18353916704654694, 0.21500302851200104, 0.2884186804294586, 0.10487952083349228, 0.36591896414756775, 0.32526129484176636, 0.10164415836334229, 0.14230181276798248, 0.06505225598812103, 0.2143249213695526, 0.4286498427391052, 0.2143249213695526, 0.2143249213695526, 0.15121622383594513, 0.4536486566066742, 0.15121622383594513, 0.15121622383594513, 0.15121622383594513, 0.21442684531211853, 0.42885369062423706, 0.21442684531211853, 0.18762773275375366, 0.20326337218284607, 0.21108119189739227, 0.24235248565673828, 0.15635643899440765, 0.1990182250738144, 0.2377162128686905, 0.1990182250738144, 0.2764142155647278, 0.08845254778862, 0.40388110280036926, 0.18422646820545197, 0.16296955943107605, 0.12045576423406601, 0.13462702929973602, 0.21544401347637177, 0.3877992331981659, 0.10054054111242294, 0.21544401347637177, 0.07181467115879059, 0.3975432813167572, 0.1987716406583786, 0.1987716406583786, 0.11042869091033936, 0.08834295719861984, 0.21682065725326538, 0.4084296226501465, 0.18152427673339844, 0.14118553698062897, 0.050423409789800644, 0.22495558857917786, 0.3642137944698334, 0.23566775023937225, 0.11783387511968613, 0.053560853004455566, 0.42720186710357666, 0.11650960147380829, 0.23301920294761658, 0.15534614026546478, 0.11650960147380829, 0.4111241102218628, 0.1897495836019516, 0.1581246554851532, 0.1264997273683548, 0.0948747918009758, 0.3420495390892029, 0.28168785572052, 0.08718910068273544, 0.22803302109241486, 0.06706853955984116, 0.05294721573591232, 0.31768330931663513, 0.4765249490737915, 0.05294721573591232, 0.10589443147182465, 0.22091171145439148, 0.22091171145439148, 0.22091171145439148, 0.44182342290878296, 0.33362656831741333, 0.26852869987487793, 0.20343083143234253, 0.10578403621912003, 0.08137233555316925, 0.3526245057582855, 0.371571809053421, 0.371571809053421, 0.177120640873909, 0.5313619375228882, 0.177120640873909, 0.177120640873909, 0.262091726064682, 0.524183452129364, 0.262091726064682, 0.18580666184425354, 0.18580666184425354, 0.18580666184425354, 0.3716133236885071, 0.18580666184425354, 0.2385510802268982, 0.2002125084400177, 0.23003140091896057, 0.25133058428764343, 0.07667712867259979, 0.25523486733436584, 0.24627923965454102, 0.25523486733436584, 0.15224535763263702, 0.08507828414440155, 0.2318066954612732, 0.22127002477645874, 0.14751335978507996, 0.31610003113746643, 0.08429334312677383, 0.14626391232013702, 0.4497615098953247, 0.15357710421085358, 0.2120826691389084, 0.036565978080034256, 0.2144448459148407, 0.4288896918296814, 0.2144448459148407, 0.2458955943584442, 0.17563970386981964, 0.10538382083177567, 0.38640734553337097, 0.07025588303804398, 0.13545112311840057, 0.13545112311840057, 0.4063533842563629, 0.13545112311840057, 0.13545112311840057, 0.2739129662513733, 0.14940707385540009, 0.22411061823368073, 0.14940707385540009, 0.19920943677425385, 0.2922707796096802, 0.17790396511554718, 0.22237995266914368, 0.15884281694889069, 0.1461353898048401, 0.2277476042509079, 0.19400721788406372, 0.17713701725006104, 0.2446177899837494, 0.1518317312002182, 0.37003546953201294, 0.37003546953201294, 0.2234012484550476, 0.24777229130268097, 0.12997891008853912, 0.32900911569595337, 0.06905129551887512, 0.3510526120662689, 0.3510526120662689, 0.1596893072128296, 0.36500412225723267, 0.1939084380865097, 0.14828293025493622, 0.12547016143798828, 0.2750179171562195, 0.34542250633239746, 0.1276083141565323, 0.2046133279800415, 0.04620300978422165, 0.17969337105751038, 0.17969337105751038, 0.11979558318853378, 0.44923344254493713, 0.08984668552875519, 0.246807262301445, 0.23309575021266937, 0.25137776136398315, 0.15082666277885437, 0.11883313208818436, 0.13874571025371552, 0.27749142050743103, 0.3699885904788971, 0.10791333764791489, 0.09249714761972427, 0.12413612753152847, 0.12413612753152847, 0.12413612753152847, 0.4965445101261139, 0.12413612753152847, 0.17170237004756927, 0.2861706018447876, 0.17742577195167542, 0.22893649339675903, 0.13163848221302032, 0.1696465164422989, 0.19304603338241577, 0.27494436502456665, 0.2632445991039276, 0.09944795817136765, 0.11843614280223846, 0.43990567326545715, 0.13535559177398682, 0.15227504074573517, 0.15227504074573517, 0.4445436894893646, 0.1481812298297882, 0.2963624596595764, 0.1481812298297882, 0.1481812298297882, 0.3501265347003937, 0.13304808735847473, 0.14005061984062195, 0.2030733972787857, 0.17506326735019684, 0.33805301785469055, 0.27191221714019775, 0.0955367237329483, 0.1984224170446396, 0.10288570076227188, 0.2103530913591385, 0.420706182718277, 0.2103530913591385, 0.10517654567956924, 0.10517654567956924, 0.28333666920661926, 0.28333666920661926, 0.28333666920661926, 0.28333666920661926, 0.22772321105003357, 0.22772321105003357, 0.11386160552501678, 0.22772321105003357, 0.22772321105003357, 0.21996569633483887, 0.21996569633483887, 0.10998284816741943, 0.43993139266967773, 0.10998284816741943, 0.39493072032928467, 0.21940596401691437, 0.13164357841014862, 0.1755247712135315, 0.08776238560676575, 0.3095901310443878, 0.12982811033725739, 0.3495372235774994, 0.08988100290298462, 0.11984133720397949, 0.2849670648574829, 0.2849670648574829, 0.2849670648574829, 0.2849670648574829, 0.2849670648574829, 0.2690920829772949, 0.1661062240600586, 0.2956690788269043, 0.23254871368408203, 0.03986549377441406, 0.04849362000823021, 0.29096171259880066, 0.4849362075328827, 0.09698724001646042, 0.09698724001646042, 0.2011595517396927, 0.1810435950756073, 0.30844464898109436, 0.1609276384115219, 0.14751701056957245, 0.20699167251586914, 0.20699167251586914, 0.23656190931797028, 0.20699167251586914, 0.14785119891166687, 0.25165578722953796, 0.19323569536209106, 0.32805129885673523, 0.13481560349464417, 0.08987706899642944, 0.2903536856174469, 0.2953597903251648, 0.19023172557353973, 0.15518903732299805, 0.07008536905050278, 0.4164416193962097, 0.09610191732645035, 0.12813588976860046, 0.1922038346529007, 0.16016985476016998, 0.41716012358665466, 0.26072508096694946, 0.10429003089666367, 0.10429003089666367, 0.10429003089666367, 0.3069835901260376, 0.23180393874645233, 0.20256741344928741, 0.18794915080070496, 0.0710030123591423, 0.1727244257926941, 0.2969647943973541, 0.2575715184211731, 0.17878493666648865, 0.09393784403800964, 0.2353239506483078, 0.16995617747306824, 0.28761816024780273, 0.15034586191177368, 0.1568826287984848, 0.36732369661331177, 0.09479321539402008, 0.2962287962436676, 0.1777372807264328, 0.07109490782022476, 0.14106476306915283, 0.1880863457918167, 0.4231942594051361, 0.1175539642572403, 0.1175539642572403, 0.40423384308815, 0.17324307560920715, 0.17324307560920715, 0.11549538373947144, 0.05774769186973572, 0.4505560100078583, 0.16383855044841766, 0.16383855044841766, 0.10239909589290619, 0.10239909589290619, 0.27395427227020264, 0.27395427227020264, 0.27395427227020264, 0.27395427227020264, 0.34476712346076965, 0.23589329421520233, 0.13609227538108826, 0.19052919745445251, 0.09980100393295288, 0.21105797588825226, 0.4221159517765045, 0.21105797588825226, 0.21105797588825226, 0.3790465295314789, 0.3790465295314789, 0.1852540373802185, 0.1852540373802185, 0.1852540373802185, 0.370508074760437, 0.4627394378185272, 0.1735272854566574, 0.1735272854566574, 0.0867636427283287, 0.1156848594546318, 0.5340000987052917, 0.2670000493526459, 0.15602776408195496, 0.17553123831748962, 0.40957286953926086, 0.17553123831748962, 0.09751734882593155, 0.18523827195167542, 0.30311718583106995, 0.14594531059265137, 0.2469843626022339, 0.11787890642881393, 0.278982937335968, 0.2114870548248291, 0.22948595881462097, 0.17548926174640656, 0.10349366813898087, 0.20144318044185638, 0.15566064417362213, 0.16481715440750122, 0.3525255620479584, 0.12819111347198486, 0.1992715448141098, 0.1992715448141098, 0.0996357724070549, 0.3985430896282196, 0.0996357724070549, 0.18910643458366394, 0.18910643458366394, 0.25214192271232605, 0.18910643458366394, 0.18910643458366394, 0.37125858664512634, 0.13338324427604675, 0.13338324427604675, 0.533532977104187, 0.13338324427604675, 0.13338324427604675, 0.2509736120700836, 0.18992598354816437, 0.3188043236732483, 0.10852912813425064, 0.12887834012508392, 0.22186623513698578, 0.22186623513698578, 0.22186623513698578, 0.44373247027397156, 0.40508487820625305, 0.18228819966316223, 0.2430509328842163, 0.10127121955156326, 0.08101698011159897, 0.27478450536727905, 0.22629311680793762, 0.19396553933620453, 0.11314655840396881, 0.19396553933620453, 0.24971306324005127, 0.18728479743003845, 0.14046360552310944, 0.3121413290500641, 0.10924946516752243, 0.14949874579906464, 0.14949874579906464, 0.14949874579906464, 0.4484962522983551, 0.14949874579906464, 0.21464481949806213, 0.42928963899612427, 0.21464481949806213, 0.21464481949806213, 0.3920045495033264, 0.13720159232616425, 0.15680181980133057, 0.1960022747516632, 0.0980011373758316, 0.19495105743408203, 0.11140060424804688, 0.22280120849609375, 0.25065135955810547, 0.22280120849609375, 0.40981826186180115, 0.20490913093090057, 0.20490913093090057, 0.2776983678340912, 0.22562991082668304, 0.1388491839170456, 0.2082737684249878, 0.14752724766731262, 0.2896221876144409, 0.2896221876144409, 0.2896221876144409, 0.2896221876144409, 0.2896221876144409, 0.4031326174736023, 0.16125304996967316, 0.16125304996967316, 0.08062652498483658, 0.08062652498483658, 0.17764773964881897, 0.17764773964881897, 0.4441193640232086, 0.08882386982440948, 0.08882386982440948, 0.46550413966178894, 0.18620166182518005, 0.18620166182518005, 0.09310083091259003, 0.09310083091259003, 0.19689640402793884, 0.18705159425735474, 0.3298014998435974, 0.2018188238143921, 0.08860338479280472, 0.23106913268566132, 0.2553921937942505, 0.2432306557893753, 0.17431530356407166, 0.09323842078447342, 0.256516695022583, 0.22979620099067688, 0.17635522782802582, 0.24048438668251038, 0.09084966033697128, 0.20738427340984344, 0.17775794863700867, 0.47402119636535645, 0.08887897431850433, 0.059252649545669556, 0.18411384522914886, 0.18411384522914886, 0.13808538019657135, 0.36822769045829773, 0.09205692261457443, 0.2808215320110321, 0.3672281503677368, 0.0972074493765831, 0.21601656079292297, 0.043203312903642654, 0.42626333236694336, 0.25575798749923706, 0.25575798749923706, 0.08525266498327255, 0.08525266498327255, 0.13431806862354279, 0.42534053325653076, 0.20147709548473358, 0.15670441091060638, 0.044772688299417496, 0.13211111724376678, 0.5284444689750671, 0.13211111724376678, 0.13211111724376678, 0.10528960078954697, 0.42115840315818787, 0.21057920157909393, 0.10528960078954697, 0.10528960078954697, 0.21285440027713776, 0.4257088005542755, 0.21285440027713776, 0.21285440027713776, 0.20997492969036102, 0.20997492969036102, 0.41994985938072205, 0.08398997038602829, 0.08398997038602829, 0.18169036507606506, 0.2530687153339386, 0.14275671541690826, 0.2920023798942566, 0.12977883219718933, 0.17159521579742432, 0.19610881805419922, 0.24513602256774902, 0.17159521579742432, 0.19610881805419922, 0.2307717204093933, 0.17751671373844147, 0.19526837766170502, 0.19526837766170502, 0.19526837766170502, 0.2679557800292969, 0.15895681083202362, 0.36332985758781433, 0.12716545164585114, 0.08629084378480911, 0.1619167923927307, 0.4187503159046173, 0.17308346927165985, 0.19541682302951813, 0.050250038504600525, 0.386581689119339, 0.09664542227983475, 0.09664542227983475, 0.1932908445596695, 0.09664542227983475, 0.28138694167137146, 0.3224225342273712, 0.17000462114810944, 0.11138233542442322, 0.11138233542442322, 0.1876070350408554, 0.2984657287597656, 0.16202424466609955, 0.2814105451107025, 0.06822073459625244, 0.32498791813850403, 0.0909966230392456, 0.37698599696159363, 0.0909966230392456, 0.11699565500020981, 0.20034384727478027, 0.18698759377002716, 0.15137091279029846, 0.3561668395996094, 0.10685005784034729, 0.17667515575885773, 0.17667515575885773, 0.35335031151771545, 0.17667515575885773, 0.17667515575885773, 0.2055378556251526, 0.33248770236968994, 0.2055378556251526, 0.2055378556251526, 0.048361849039793015, 0.23113533854484558, 0.23113533854484558, 0.1617947369813919, 0.3120327293872833, 0.06934060156345367, 0.2240128070116043, 0.24124456942081451, 0.11200640350580215, 0.34463509917259216, 0.07754289358854294, 0.16891047358512878, 0.16891047358512878, 0.3040388524532318, 0.18580152094364166, 0.16891047358512878, 0.1421891450881958, 0.19906480610370636, 0.4265674352645874, 0.17062696814537048, 0.05687565729022026, 0.17752599716186523, 0.17752599716186523, 0.35505199432373047, 0.17752599716186523, 0.17752599716186523, 0.5146422982215881, 0.25732114911079407, 0.08577372133731842, 0.08577372133731842, 0.08577372133731842, 0.18870390951633453, 0.10483551025390625, 0.31450653076171875, 0.18870390951633453, 0.2096710205078125, 0.5335063338279724, 0.2667531669139862, 0.11226335912942886, 0.5040395855903625, 0.20390692353248596, 0.10539009422063828, 0.07560593634843826, 0.21042267978191376, 0.28818756341934204, 0.12350896000862122, 0.25159233808517456, 0.12808336317539215, 0.3674357235431671, 0.3674357235431671, 0.2853095829486847, 0.2853095829486847, 0.2853095829486847, 0.22024936974048615, 0.18500946462154388, 0.19381943345069885, 0.2907291650772095, 0.10571969300508499, 0.3240783214569092, 0.2273385226726532, 0.22250154614448547, 0.10641378164291382, 0.11608775705099106, 0.1331910490989685, 0.266382098197937, 0.1331910490989685, 0.3995731770992279, 0.0532764233648777, 0.3045206069946289, 0.20011353492736816, 0.13050882518291473, 0.2958199977874756, 0.07830529659986496, 0.2886137068271637, 0.14430685341358185, 0.3788054883480072, 0.0901917815208435, 0.0901917815208435, 0.2836703658103943, 0.3491327464580536, 0.1018303856253624, 0.2182079702615738, 0.0509151928126812, 0.1731642335653305, 0.14842648804187775, 0.23088563978672028, 0.30509889125823975, 0.1401805728673935, 0.44329649209976196, 0.2364247888326645, 0.08865930140018463, 0.14776550233364105, 0.05910619720816612, 0.20889414846897125, 0.32190245389938354, 0.1780737042427063, 0.19519618153572083, 0.09246134757995605, 0.13272584974765778, 0.26545169949531555, 0.39817753434181213, 0.13272584974765778, 0.13272584974765778, 0.19628393650054932, 0.17597870528697968, 0.3045785427093506, 0.2301260083913803, 0.09475776553153992, 0.3792235553264618, 0.24048322439193726, 0.1479896754026413, 0.12024161219596863, 0.11099226027727127, 0.2645319700241089, 0.5290639400482178, 0.2645319700241089, 0.2645319700241089, 0.1334395408630371, 0.5337581634521484, 0.1334395408630371, 0.1334395408630371, 0.1334395408630371, 0.2563268840312958, 0.20506151020526886, 0.15379613637924194, 0.20506151020526886, 0.20506151020526886, 0.12630324065685272, 0.421010822057724, 0.23155593872070312, 0.12630324065685272, 0.105252705514431, 0.32419294118881226, 0.20262058079242706, 0.14858843386173248, 0.14858843386173248, 0.17560450732707977, 0.2915807068347931, 0.1497306227684021, 0.2364167720079422, 0.126088947057724, 0.1970139890909195, 0.212197944521904, 0.25766894221305847, 0.18188394606113434, 0.1667269468307495, 0.1667269468307495, 0.16877692937850952, 0.4641365706920624, 0.16877692937850952, 0.12658269703388214, 0.08438846468925476, 0.4142433702945709, 0.21557563543319702, 0.17330589890480042, 0.09299341589212418, 0.10567433387041092, 0.14233100414276123, 0.28466200828552246, 0.10674825310707092, 0.3558275103569031, 0.10674825310707092, 0.35777780413627625, 0.14945149421691895, 0.30343180894851685, 0.1086919903755188, 0.0815189927816391, 0.18484339118003845, 0.24645784497261047, 0.4313012361526489, 0.12322892248630524, 0.06161446124315262, 0.1849299520254135, 0.16811813414096832, 0.2521772086620331, 0.2017417550086975, 0.2017417550086975, 0.09767854958772659, 0.48839274048805237, 0.1465178281068802, 0.1465178281068802, 0.09767854958772659, 0.30436596274375916, 0.22465106844902039, 0.1304425597190857, 0.12319574505090714, 0.21740426123142242, 0.19132216274738312, 0.19132216274738312, 0.19132216274738312, 0.19132216274738312, 0.19132216274738312, 0.23466335237026215, 0.2043842077255249, 0.22330866754055023, 0.193029522895813, 0.14382591843605042, 0.3802771270275116, 0.3802771270275116, 0.3802771270275116, 0.3676944971084595, 0.3676944971084595, 0.22868117690086365, 0.22868117690086365, 0.22868117690086365, 0.22868117690086365, 0.22868117690086365, 0.5187962055206299, 0.25939810276031494, 0.12969905138015747, 0.12969905138015747, 0.12969905138015747, 0.3188130855560303, 0.16699734330177307, 0.19736048579216003, 0.2125420719385147, 0.10121050477027893, 0.5408856272697449, 0.27044281363487244, 0.3718774616718292, 0.17785443365573883, 0.2425287812948227, 0.12934868037700653, 0.06467434018850327, 0.47440606355667114, 0.15813535451889038, 0.23720303177833557, 0.15813535451889038, 0.07906767725944519, 0.19356268644332886, 0.3304728865623474, 0.10858394205570221, 0.30686765909194946, 0.06137353181838989, 0.2514033317565918, 0.24134719371795654, 0.12067359685897827, 0.2916278541088104, 0.10056132823228836, 0.40054550766944885, 0.030811192467808723, 0.40054550766944885, 0.06162238493561745, 0.1232447698712349, 0.4530346095561981, 0.15101154148578644, 0.15101154148578644, 0.15101154148578644, 0.15101154148578644, 0.3072350323200226, 0.2229931801557541, 0.20317156612873077, 0.16352832317352295, 0.09910807758569717, 0.18901149928569794, 0.3150191605091095, 0.12600766122341156, 0.12600766122341156, 0.2520153224468231, 0.5245580673217773, 0.15428178012371063, 0.1234254240989685, 0.09256906807422638, 0.06171271204948425, 0.3694506585597992, 0.3694506585597992, 0.3707405626773834, 0.11523017287254333, 0.3106204867362976, 0.11523017287254333, 0.09018013626337051, 0.2606547176837921, 0.47926831245422363, 0.06726572662591934, 0.15134789049625397, 0.03363286331295967, 0.43985792994499207, 0.17594316601753235, 0.17594316601753235, 0.08797158300876617, 0.08797158300876617, 0.2838180959224701, 0.2838180959224701, 0.2838180959224701, 0.2838180959224701, 0.2838180959224701, 0.2226344645023346, 0.15584412217140198, 0.1113172322511673, 0.4007420241832733, 0.1113172322511673, 0.36168140172958374, 0.021788036450743675, 0.40961509943008423, 0.03486085683107376, 0.16994668543338776, 0.26885101199150085, 0.0960182175040245, 0.4032765030860901, 0.0960182175040245, 0.1536291539669037, 0.28081339597702026, 0.3444230556488037, 0.22496101260185242, 0.08843294531106949, 0.062058206647634506, 0.11774816364049911, 0.4121185541152954, 0.26493337750434875, 0.11774816364049911, 0.08831112086772919, 0.3995833396911621, 0.15119369328022003, 0.2699887454509735, 0.10799550265073776, 0.0647972971200943, 0.4119766652584076, 0.2059883326292038, 0.2059883326292038, 0.1029941663146019, 0.1029941663146019, 0.37896427512168884, 0.2008967250585556, 0.20546256005764008, 0.14154087007045746, 0.06848751753568649, 0.1421760618686676, 0.4265281558036804, 0.1421760618686676, 0.2132640779018402, 0.0710880309343338, 0.3349909782409668, 0.25565099716186523, 0.12341772764921188, 0.1939421445131302, 0.08815552294254303, 0.225263312458992, 0.1939767450094223, 0.1626901775598526, 0.3316376507282257, 0.087602399289608, 0.24157382547855377, 0.14494429528713226, 0.09662953019142151, 0.38651812076568604, 0.09662953019142151, 0.41252371668815613, 0.24402812123298645, 0.18011599779129028, 0.0929630920290947, 0.07553251087665558, 0.27016356587409973, 0.14244988560676575, 0.3094601035118103, 0.18665847182273865, 0.0884171724319458], \"Term\": [\"1 4\", \"1 4\", \"1 4\", \"1 4\", \"1 4\", \"AB\", \"AB\", \"AB\", \"AB\", \"AB\", \"Abigail\", \"Abigail\", \"Abigail\", \"Abigail\", \"Abigail\", \"Affair\", \"Affair\", \"BAYES\", \"BAYES\", \"BAYES\", \"BAYES\", \"BAYES\", \"Banarescu\", \"Banarescu\", \"Banarescu\", \"Banarescu\", \"Banarescu\", \"Bayes\", \"Bayes\", \"Bayes\", \"Bayes\", \"Bayes\", \"BiLSTM\", \"BiLSTM\", \"BiLSTM\", \"BiLSTM\", \"BiLSTM\", \"Bojanowski\", \"Bojanowski\", \"Bojanowski\", \"Bojanowski\", \"Bojanowski\", \"Boyang\", \"Boyang\", \"Boyang\", \"Boyang\", \"Boyang\", \"CC\", \"CC\", \"CC\", \"CC\", \"CC\", \"Choice\", \"Choice\", \"Choice\", \"Das\", \"Das\", \"Das\", \"Das\", \"Das\", \"Della\", \"Della\", \"Della\", \"Della\", \"EM\", \"EM\", \"EM\", \"EM\", \"EM\", \"Earley\", \"Earley\", \"Earley\", \"Earley\", \"Earley\", \"Eisenstein\", \"Eisenstein\", \"Eisenstein\", \"Eisenstein\", \"Eisenstein\", \"Gimpel\", \"Gimpel\", \"H\", \"H\", \"H\", \"H\", \"H\", \"HH\", \"HH\", \"HH\", \"HH\", \"HH\", \"HMM\", \"HMM\", \"HMM\", \"HMM\", \"HMM\", \"Hamming\", \"Hamming\", \"Hamming\", \"Heafield\", \"Heafield\", \"Heafield\", \"Heafield\", \"Heafield\", \"Jacob\", \"Jacob\", \"Jacob\", \"Jacob\", \"Jacob\", \"Jacob Eisenstein\", \"Jacob Eisenstein\", \"Jacob Eisenstein\", \"Jacob Eisenstein\", \"Jacob Eisenstein\", \"Janet\", \"Janet\", \"Janet\", \"Janet\", \"Janet\", \"Japanese\", \"Japanese\", \"Japanese\", \"Japanese\", \"Japanese\", \"LCE\", \"LCE\", \"LCE\", \"LCE\", \"LCE\", \"Labov\", \"Labov\", \"Labov\", \"Lee\", \"Lee\", \"Lee\", \"Lee\", \"Lee\", \"Lesk\", \"Lesk\", \"Lesk\", \"Lesk\", \"Lesk\", \"Logistic\", \"Logistic\", \"Logistic\", \"Logistic\", \"Logistic\", \"Lucia\", \"Lucia\", \"Lucia\", \"Lucia\", \"Lucia\", \"MACHINE\", \"MACHINE\", \"MACHINE\", \"MACHINE\", \"MACHINE\", \"MD\", \"MD\", \"MD\", \"MD\", \"MD\", \"MEMM\", \"MEMM\", \"MEMM\", \"MEMM\", \"MEMM\", \"Maas\", \"Maas\", \"Manhattan\", \"Manhattan\", \"Manhattan\", \"Manhattan\", \"Memory\", \"Memory\", \"Memory\", \"Memory\", \"Mention\", \"Mention\", \"Mention\", \"Mention\", \"Mention\", \"NC\", \"NC\", \"NC\", \"NC\", \"NC\", \"ND\", \"ND\", \"ND\", \"ND\", \"ND\", \"NOUN\", \"NOUN\", \"NOUN\", \"NOUN\", \"NOUN\", \"NP\", \"NP\", \"NP\", \"NP\", \"NP\", \"Nominal\", \"Nominal\", \"Nominal\", \"Nominal\", \"Nominal\", \"October 15 , 2018\", \"October 15 , 2018\", \"October 15 , 2018\", \"October 15 , 2018\", \"October 15 , 2018\", \"OntoNotes\", \"OntoNotes\", \"OntoNotes\", \"OntoNotes\", \"OntoNotes\", \"PAST\", \"PAST\", \"PAST\", \"PAST\", \"PAST\", \"PCFG\", \"PCFG\", \"PCFG\", \"PCFG\", \"PCFG\", \"PMI\", \"PMI\", \"PMI\", \"PMI\", \"PMI\", \"PP\", \"PP\", \"PP\", \"PP\", \"PP\", \"PROPN\", \"PROPN\", \"PTB\", \"PTB\", \"PTB\", \"PTB\", \"PTB\", \"Pietra\", \"Pietra\", \"Pietra\", \"Pilehvar , M\", \"Pilehvar , M\", \"Pilehvar , M\", \"Pilehvar , M\", \"Poirot\", \"Poirot\", \"Pr\", \"Pr\", \"Pr\", \"Pr\", \"Pr\", \"PropBank\", \"PropBank\", \"PropBank\", \"PropBank\", \"PropBank\", \"R\", \"R\", \"R\", \"R\", \"R\", \"RECURRENT\", \"RECURRENT\", \"RECURRENT\", \"RECURRENT\", \"RECURRENT\", \"REGRESSION\", \"REGRESSION\", \"REGRESSION\", \"REGRESSION\", \"REGRESSION\", \"RESOLUTION\", \"RESOLUTION\", \"RESOLUTION\", \"RESOLUTION\", \"RESOLUTION\", \"RNN\", \"RNN\", \"RNN\", \"RNN\", \"RNN\", \"RNNs\", \"RNNs\", \"RNNs\", \"RNNs\", \"RNNs\", \"Rdin\", \"Rdin\", \"Rdin\", \"Rdin\", \"Rdin\", \"Regression\", \"Regression\", \"Regression\", \"Regression\", \"Regression\", \"Reno\", \"Reno\", \"Reno\", \"Reno\", \"Reno\", \"Rn\", \"Rn\", \"Rn\", \"Rn\", \"Rn\", \"Romeo\", \"Romeo\", \"Romeo\", \"Romeo\", \"Romeo\", \"SEQUENCE\", \"SEQUENCE\", \"SEQUENCE\", \"SEQUENCE\", \"SEQUENCE\", \"SGD\", \"SGD\", \"SGD\", \"SGD\", \"SGD\", \"SV\", \"SV\", \"SV\", \"SV\", \"SV\", \"SVD\", \"SVD\", \"SVD\", \"SVD\", \"SVD\", \"Schabes\", \"Schabes\", \"Schabes\", \"Schabes\", \"Schabes\", \"Section 6.4\", \"Section 6.4\", \"Section 6.4\", \"Section 6.4\", \"Section 7\", \"Section 7\", \"Section 7\", \"Section 7\", \"Section 7\", \"SemCor\", \"SemCor\", \"SemCor\", \"SemCor\", \"SemCor\", \"Serves\", \"Serves\", \"Serves\", \"Serves\", \"Serves\", \"Success\", \"Success\", \"Success\", \"TH\", \"TH\", \"TH\", \"TH\", \"TH\", \"Taboada\", \"Taboada\", \"Taboada\", \"Taboada\", \"Temporal\", \"Temporal\", \"Temporal\", \"Temporal\", \"Temporal\", \"Tokenization\", \"Tokenization\", \"Tokenization\", \"Tokenization\", \"Tokenization\", \"UD\", \"UD\", \"UD\", \"UD\", \"UD\", \"VB\", \"VB\", \"VB\", \"VB\", \"VB\", \"VBD\", \"VBD\", \"VBD\", \"VBD\", \"VBD\", \"VP\", \"VP\", \"VP\", \"VP\", \"VP\", \"VerbNet\", \"VerbNet\", \"VerbNet\", \"VerbNet\", \"VerbNet\", \"Viterbi\", \"Viterbi\", \"Viterbi\", \"Viterbi\", \"Viterbi\", \"WORDNET\", \"WORDNET\", \"WORDNET\", \"WORDNET\", \"WORDNET\", \"WordNet\", \"WordNet\", \"WordNet\", \"WordNet\", \"WordNet\", \"YES\", \"YES\", \"YES\", \"YES\", \"YES\", \"Ym\", \"Ym\", \"Ym\", \"Ym\", \"Ym\", \"abysmal\", \"activation\", \"activation\", \"activation\", \"activation\", \"activation\", \"adjective\", \"adjective\", \"adjective\", \"adjective\", \"adjective\", \"adverb\", \"adverb\", \"adverb\", \"adverb\", \"adverb\", \"advise\", \"advise\", \"advise\", \"advise\", \"advise\", \"affinity\", \"affinity\", \"affinity\", \"affinity\", \"agent\", \"agent\", \"agent\", \"agent\", \"agent\", \"alignment\", \"alignment\", \"alignment\", \"alignment\", \"alignment\", \"anaphor\", \"anaphor\", \"anaphor\", \"anaphor\", \"anaphor\", \"anaphoric\", \"anaphoric\", \"anaphoric\", \"anaphoric\", \"anaphoric\", \"annotation\", \"annotation\", \"annotation\", \"annotation\", \"annotation\", \"antecedent\", \"antecedent\", \"antecedent\", \"antecedent\", \"antecedent\", \"antonym\", \"antonym\", \"antonym\", \"antonym\", \"antonym\", \"at least 1\", \"at least 1\", \"at least 1\", \"at least 1\", \"atacado\", \"atacado\", \"atacado\", \"atacado\", \"attachment\", \"attachment\", \"attachment\", \"attachment\", \"attachment\", \"attentional\", \"attentional\", \"attentional\", \"attentional\", \"attentional\", \"attribute\", \"attribute\", \"attribute\", \"attribute\", \"attribute\", \"auxiliary\", \"auxiliary\", \"auxiliary\", \"auxiliary\", \"auxiliary\", \"backward\", \"backward\", \"backward\", \"backward\", \"backward\", \"bass\", \"bass\", \"bass\", \"bass\", \"bass\", \"batch\", \"batch\", \"batch\", \"batch\", \"batch\", \"bias\", \"bias\", \"bias\", \"bias\", \"bias\", \"bigram\", \"bigram\", \"bigram\", \"bigram\", \"bigram\", \"biguation\", \"biguation\", \"biguation\", \"biguation\", \"blood\", \"blood\", \"blood\", \"blood\", \"blood\", \"can\", \"can\", \"can\", \"cat\", \"cat\", \"cat\", \"cat\", \"cat\", \"category\", \"category\", \"category\", \"category\", \"category\", \"cell\", \"cell\", \"cell\", \"cell\", \"cell\", \"chinese\", \"chinese\", \"chinese\", \"chinese\", \"chinese\", \"chunk\", \"chunk\", \"chunk\", \"chunk\", \"chunk\", \"cluster\", \"cluster\", \"cluster\", \"cluster\", \"cluster\", \"clustering\", \"clustering\", \"clustering\", \"clustering\", \"clustering\", \"cm\", \"cm\", \"cm\", \"cm\", \"cm\", \"coffee\", \"coffee\", \"coffee\", \"coffee\", \"coffee\", \"coherence\", \"coherence\", \"coherence\", \"coherence\", \"coherence\", \"coin\", \"coin\", \"coin\", \"coin\", \"coin\", \"collar\", \"collar\", \"collar\", \"collar\", \"column\", \"column\", \"column\", \"column\", \"column\", \"commission\", \"compromise\", \"compromise\", \"concordance\", \"concordance\", \"concordance\", \"concordance\", \"confess\", \"confess\", \"confess\", \"confound\", \"confound\", \"confound\", \"confound\", \"confound\", \"constituent\", \"constituent\", \"constituent\", \"constituent\", \"constituent\", \"contract\", \"contract\", \"contract\", \"contract\", \"contract\", \"conversation\", \"conversation\", \"conversation\", \"conversation\", \"conversation\", \"coreference\", \"coreference\", \"coreference\", \"coreference\", \"coreference\", \"cream\", \"cream\", \"cream\", \"crossentropy\", \"crossentropy\", \"crossentropy\", \"crossentropy\", \"crossentropy\", \"ct\", \"ct\", \"ct\", \"ct\", \"ct\", \"decode\", \"decode\", \"decode\", \"decode\", \"decode\", \"decoder\", \"decoder\", \"decoder\", \"decoder\", \"decoder\", \"derivative\", \"derivative\", \"derivative\", \"derivative\", \"derivative\", \"derivativechain\", \"derivativechain\", \"dialogue\", \"dialogue\", \"dialogue\", \"dialogue\", \"dialogue\", \"differentially\", \"differentially\", \"disambiguation\", \"disambiguation\", \"disambiguation\", \"disambiguation\", \"disambiguation\", \"discourse\", \"discourse\", \"discourse\", \"discourse\", \"discourse\", \"doc\", \"doc\", \"doc\", \"doc\", \"doc\", \"draft\", \"draft\", \"draft\", \"draft\", \"draft\", \"dump\", \"dump\", \"dump\", \"dump\", \"dump\", \"dw\", \"dw\", \"dw\", \"dw\", \"dw\", \"eat\", \"eat\", \"eat\", \"eat\", \"eat\", \"edge\", \"edge\", \"edge\", \"edge\", \"edge\", \"edit\", \"edit\", \"edit\", \"edit\", \"edit\", \"elephant\", \"elephant\", \"elephant\", \"elephant\", \"elephant\", \"encoder\", \"encoder\", \"encoder\", \"encoder\", \"encoder\", \"entropy\", \"entropy\", \"entropy\", \"entropy\", \"entropy\", \"erence\", \"erence\", \"erence\", \"erence\", \"erence\", \"exceedingly\", \"exceedingly\", \"exceedingly\", \"exceedingly\", \"execution\", \"execution\", \"execution\", \"execution\", \"execution\", \"ezi\", \"ezi\", \"ezi\", \"ezi\", \"ezi\", \"film\", \"film\", \"film\", \"film\", \"film\", \"fish\", \"fish\", \"fish\", \"fish\", \"fish\", \"flag\", \"flag\", \"flag\", \"flag\", \"flag\", \"flight\", \"flight\", \"flight\", \"flight\", \"flight\", \"flip\", \"flip\", \"flip\", \"flip\", \"flip\", \"forward\", \"forward\", \"forward\", \"forward\", \"forward\", \"frame\", \"frame\", \"frame\", \"frame\", \"frame\", \"free\", \"free\", \"free\", \"free\", \"free\", \"frequency\", \"frequency\", \"frequency\", \"frequency\", \"frequency\", \"frontier\", \"frontier\", \"frontier\", \"frontier\", \"frontier\", \"fun\", \"fun\", \"fun\", \"fun\", \"fun\", \"grammar\", \"grammar\", \"grammar\", \"grammar\", \"grammar\", \"head\", \"head\", \"head\", \"head\", \"head\", \"hidden\", \"hidden\", \"hidden\", \"hidden\", \"hidden\", \"hm\", \"hm\", \"hm\", \"hm\", \"hm\", \"ht\", \"ht\", \"ht\", \"ht\", \"ht\", \"hub\", \"hub\", \"hub\", \"hub\", \"hub\", \"idf\", \"idf\", \"idf\", \"idf\", \"idf\", \"intercept\", \"intercept\", \"intercept\", \"intercept\", \"intuition\", \"intuition\", \"intuition\", \"intuition\", \"intuition\", \"jet\", \"jet\", \"jet\", \"jet\", \"kenization\", \"kenization\", \"lasso\", \"lasso\", \"lasso\", \"lasso\", \"le\", \"le\", \"le\", \"le\", \"le\", \"lean\", \"lean\", \"lexicalized\", \"lexicalized\", \"lexicalized\", \"lexicalized\", \"lexicalized\", \"lexicon\", \"lexicon\", \"lexicon\", \"lexicon\", \"lexicon\", \"license\", \"license\", \"license\", \"license\", \"license\", \"logistic\", \"logistic\", \"logistic\", \"logistic\", \"logistic\", \"log\\u03c3\", \"log\\u03c3\", \"log\\u03c3\", \"log\\u03c3\", \"log\\u03c3\", \"lookup\", \"lookup\", \"lookup\", \"lookup\", \"lookup\", \"lossloss\", \"matcher\", \"matcher\", \"matcher\", \"matcher\", \"matcher\", \"max\", \"max\", \"max\", \"max\", \"max\", \"maxent\", \"maxent\", \"maxent\", \"maxent\", \"maximization\", \"maximization\", \"maximization\", \"maximization\", \"maximization\", \"morphological\", \"morphological\", \"morphological\", \"morphological\", \"morphological\", \"movie\", \"movie\", \"movie\", \"movie\", \"movie\", \"multiclass\", \"multiclass\", \"multiclass\", \"multiclass\", \"multiclass\", \"musical\", \"musical\", \"musical\", \"musical\", \"mutual\", \"mutual\", \"mutual\", \"mutual\", \"mutual\", \"neuron\", \"neuron\", \"neuron\", \"neuron\", \"neuron\", \"nonparametric\", \"nonparametric\", \"nonparametric\", \"observation\", \"observation\", \"observation\", \"observation\", \"observation\", \"octopus\", \"octopus\", \"octopus\", \"octopus\", \"octopus\", \"ongchoi\", \"ongchoi\", \"ongchoi\", \"ongchoi\", \"ongchoi\", \"pX\", \"pX\", \"pX\", \"pX\", \"pX\", \"pajama\", \"pajama\", \"pajama\", \"pajama\", \"pajama\", \"parser\", \"parser\", \"parser\", \"parser\", \"parser\", \"parsing\", \"parsing\", \"parsing\", \"parsing\", \"parsing\", \"path\", \"path\", \"path\", \"path\", \"path\", \"pcfg\", \"pcfg\", \"pcfg\", \"pcfg\", \"pcfg\", \"perfectly\", \"perfectly\", \"perfectly\", \"perfectly\", \"perfectly\", \"perplexity\", \"perplexity\", \"perplexity\", \"perplexity\", \"perplexity\", \"pivot\", \"pivot\", \"pivot\", \"pivot\", \"pivot\", \"policy\", \"policy\", \"policy\", \"policy\", \"policy\", \"politician\", \"politician\", \"politician\", \"politician\", \"polysemy\", \"polysemy\", \"polysemy\", \"polysemy\", \"polysemy\", \"ponzetto\", \"ponzetto\", \"ponzetto\", \"ponzetto\", \"pr\", \"pr\", \"pr\", \"pr\", \"pr\", \"predicate\", \"predicate\", \"predicate\", \"predicate\", \"predicate\", \"preference\", \"preference\", \"preference\", \"preference\", \"preference\", \"prefix\", \"prefix\", \"prefix\", \"prefix\", \"prefix\", \"production\", \"production\", \"production\", \"production\", \"production\", \"pronoun\", \"pronoun\", \"pronoun\", \"pronoun\", \"pronoun\", \"pwt\", \"pwt\", \"pwt\", \"pwt\", \"pwt\", \"q\", \"q\", \"q\", \"q\", \"q\", \"rank\", \"rank\", \"rank\", \"rank\", \"rank\", \"recurrence\", \"recurrence\", \"recurrence\", \"recurrence\", \"recurrence\", \"regression\", \"regression\", \"regression\", \"regression\", \"regression\", \"rence\", \"rence\", \"rence\", \"rence\", \"rence\", \"resolution\", \"resolution\", \"resolution\", \"resolution\", \"resolution\", \"response\", \"response\", \"response\", \"response\", \"response\", \"restaurant\", \"restaurant\", \"restaurant\", \"restaurant\", \"restaurant\", \"rnn\", \"rnn\", \"rnn\", \"rnn\", \"rnn\", \"sack\", \"sack\", \"sack\", \"sack\", \"sack\", \"sbi\", \"sbi\", \"sbi\", \"sbi\", \"sbi\", \"scene\", \"scene\", \"scene\", \"scene\", \"scene\", \"selectional\", \"selectional\", \"selectional\", \"selectional\", \"selectional\", \"semcor\", \"semcor\", \"sense\", \"sense\", \"sense\", \"sense\", \"sense\", \"sentiment\", \"sentiment\", \"sentiment\", \"sentiment\", \"sentiment\", \"shrinkage\", \"shrinkage\", \"shuffle\", \"shuffle\", \"shuffle\", \"sigmoid\", \"sigmoid\", \"sigmoid\", \"sigmoid\", \"sigmoid\", \"similarity\", \"similarity\", \"similarity\", \"similarity\", \"similarity\", \"slope\", \"slope\", \"slope\", \"slope\", \"slope\", \"slot\", \"slot\", \"slot\", \"slot\", \"slot\", \"sm\", \"sm\", \"sm\", \"sm\", \"sm\", \"smooth\", \"smooth\", \"smooth\", \"smooth\", \"smooth\", \"softmax\", \"softmax\", \"softmax\", \"softmax\", \"softmax\", \"spam\", \"spam\", \"spam\", \"spam\", \"spam\", \"span\", \"span\", \"span\", \"span\", \"span\", \"splitting\", \"splitting\", \"splitting\", \"splitting\", \"splitting\", \"stack\", \"stack\", \"stack\", \"stack\", \"stack\", \"statistical\", \"statistical\", \"statistical\", \"statistical\", \"statistical\", \"stopword\", \"stopword\", \"stopword\", \"stopword\", \"superordinate\", \"superordinate\", \"superordinate\", \"superordinate\", \"superordinate\", \"switch\", \"switch\", \"switch\", \"switch\", \"switch\", \"synset\", \"synset\", \"synset\", \"synset\", \"synset\", \"tagger\", \"tagger\", \"tagger\", \"tagger\", \"tagger\", \"tagging\", \"tagging\", \"tagging\", \"tagging\", \"tagging\", \"tagset\", \"tagset\", \"tagset\", \"tagset\", \"tagset\", \"tail\", \"tail\", \"tail\", \"tail\", \"tail\", \"target\", \"target\", \"target\", \"target\", \"target\", \"teach\", \"teach\", \"teach\", \"teach\", \"teach\", \"terminal\", \"terminal\", \"terminal\", \"terminal\", \"terminal\", \"th\", \"th\", \"th\", \"th\", \"th\", \"theme\", \"theme\", \"theme\", \"theme\", \"theme\", \"thesaurus\", \"thesaurus\", \"thesaurus\", \"thesaurus\", \"thesaurus\", \"ti\", \"ti\", \"ti\", \"ti\", \"ti\", \"toe\", \"toe\", \"toe\", \"toe\", \"toe\", \"transition\", \"transition\", \"transition\", \"transition\", \"transition\", \"transliterate\", \"transliterate\", \"transliterate\", \"transparently\", \"transparently\", \"turkish\", \"turkish\", \"turkish\", \"turkish\", \"turkish\", \"twist\", \"twist\", \"twist\", \"twist\", \"twist\", \"u\", \"u\", \"u\", \"u\", \"u\", \"unfortunate\", \"unfortunate\", \"unlabeled\", \"unlabeled\", \"unlabeled\", \"unlabeled\", \"unlabeled\", \"useless\", \"useless\", \"useless\", \"useless\", \"useless\", \"user\", \"user\", \"user\", \"user\", \"user\", \"utterance\", \"utterance\", \"utterance\", \"utterance\", \"utterance\", \"vm\", \"vm\", \"vm\", \"vm\", \"vm\", \"vn\", \"vn\", \"vn\", \"vn\", \"vn\", \"vocabulary\", \"vocabulary\", \"vocabulary\", \"vocabulary\", \"vocabulary\", \"vt\", \"vt\", \"vt\", \"vt\", \"vt\", \"week\", \"week\", \"week\", \"week\", \"week\", \"whichgenerativemodel\", \"whichgenerativemodel\", \"wm\", \"wm\", \"wm\", \"wm\", \"wm\", \"wn\", \"wn\", \"wn\", \"wn\", \"wn\", \"wordtoword\", \"wordtoword\", \"wordtoword\", \"wordtoword\", \"wordtoword\", \"xavi\", \"xavi\", \"xavi\", \"xavi\", \"xavi\", \"xb\", \"xb\", \"xb\", \"xb\", \"xb\", \"ym\", \"ym\", \"ym\", \"ym\", \"ym\", \"yn\", \"yn\", \"yn\", \"yn\", \"yn\", \"z\", \"z\", \"z\", \"z\", \"z\", \"zk\", \"zk\", \"zk\", \"zk\", \"zk\", \"\\u00b5\", \"\\u00b5\", \"\\u00b5\", \"\\u00b5\", \"\\u00b5\", \"\\u03a6\", \"\\u03a6\", \"\\u03a6\", \"\\u03a6\", \"\\u03a6\", \"\\u03b1\", \"\\u03b1\", \"\\u03b1\", \"\\u03b1\", \"\\u03b1\", \"\\u03ba\", \"\\u03ba\", \"\\u03ba\", \"\\u03ba\", \"\\u03ba\", \"\\u03bb\", \"\\u03bb\", \"\\u03bb\", \"\\u03bb\", \"\\u03bb\", \"\\u03c3\", \"\\u03c3\", \"\\u03c3\", \"\\u03c3\", \"\\u03c3\", \"\\u03c3w\", \"\\u03c3w\", \"\\u03c3w\", \"\\u03c3w\", \"\\u03c3w\", \"\\u03c6\", \"\\u03c6\", \"\\u03c6\", \"\\u03c6\", \"\\u03c6\", \"\\u03c8\", \"\\u03c8\", \"\\u03c8\", \"\\u03c8\", \"\\u03c8\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [4, 1, 3, 2, 5]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el4961629528131995607735033329\", ldavis_el4961629528131995607735033329_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el4961629528131995607735033329\", ldavis_el4961629528131995607735033329_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el4961629528131995607735033329\", ldavis_el4961629528131995607735033329_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "3     -0.001409 -0.002873       1        1  25.433800\n",
       "0      0.011968 -0.008285       2        1  24.555796\n",
       "2     -0.013179 -0.005264       3        1  20.608286\n",
       "1      0.011048  0.008428       4        1  19.039574\n",
       "4     -0.008428  0.007994       5        1  10.362545, topic_info=          Term        Freq       Total Category  logprob  loglift\n",
       "407         ym  229.000000  229.000000  Default  30.0000  30.0000\n",
       "342      sense  436.000000  436.000000  Default  29.0000  29.0000\n",
       "2548  logistic  218.000000  218.000000  Default  28.0000  28.0000\n",
       "1912        Pr  152.000000  152.000000  Default  27.0000  27.0000\n",
       "2225        ti  137.000000  137.000000  Default  26.0000  26.0000\n",
       "...        ...         ...         ...      ...      ...      ...\n",
       "47           H   23.158916  215.013901   Topic5  -6.3345   0.0386\n",
       "460         CC   23.980852  235.821579   Topic5  -6.2996  -0.0188\n",
       "1241   parsing   23.243441  246.679428   Topic5  -6.3309  -0.0951\n",
       "5652   license   22.522146  222.235825   Topic5  -6.3624  -0.0223\n",
       "797         VP   25.203676  364.562988   Topic5  -6.2499  -0.4047\n",
       "\n",
       "[436 rows x 6 columns], token_table=      Topic      Freq Term\n",
       "term                      \n",
       "6669      1  0.087401  1 4\n",
       "6669      2  0.349605  1 4\n",
       "6669      3  0.437007  1 4\n",
       "6669      4  0.087401  1 4\n",
       "6669      5  0.087401  1 4\n",
       "...     ...       ...  ...\n",
       "8169      1  0.270164    \n",
       "8169      2  0.142450    \n",
       "8169      3  0.309460    \n",
       "8169      4  0.186658    \n",
       "8169      5  0.088417    \n",
       "\n",
       "[1470 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[4, 1, 3, 2, 5])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyLDAvis.gensim\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(models[2],corpus,dictionary)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_dict = defaultdict(int)\n",
    "recall_dict = defaultdict(int)\n",
    "f1_dict = defaultdict(int)\n",
    "for label in labels:\n",
    "    if tp[label] == 0:\n",
    "        print(label)\n",
    "        continue\n",
    "    precision_dict[label] = tp[label] / (fp[label]+tp[label])\n",
    "    recall_dict[label] = tp[label] / (fn[label]+tp[label])\n",
    "    f1_dict[label] = 2 * (precision_dict[label] * recall_dict[label]) / (precision_dict[label] + recall_dict[label])\n",
    "\n",
    "macro_precision = sum(precision_dict.values()) / 5\n",
    "macro_recall = sum(recall_dict.values()) / 5\n",
    "macro_f1 = sum(f1_dict.values()) / 5\n",
    "micro_precision = sum(tp.values()) / (sum(tp.values()) + sum(fp.values()))\n",
    "micro_recall = sum(tp.values()) / (sum(tp.values()) + sum(fn.values()))\n",
    "micro_f1 = 2 * (micro_precision * micro_recall) / (micro_recall + micro_precision)\n",
    "\n",
    "print(\"### PER-CLASS METRICS ###\")\n",
    "print(\"PRECIS  RECALL  F1    \")\n",
    "for label in labels:\n",
    "    print(f\"{precision_dict[label]:6.4f}  {recall_dict[label]:6.4f}  {f1_dict[label]:6.4f}  {label.upper()}\")\n",
    "\n",
    "print()\n",
    "print(\"### AVERAGED METRICS ###\")\n",
    "print()\n",
    "print(\"MICRO AVERAGED\")\n",
    "print(\"PRECIS  RECALL  F1    \")\n",
    "print(f\"{micro_precision:6.4f}  {micro_recall:6.4f}  {micro_f1:6.4f}\")\n",
    "print()\n",
    "print(\"MACRO AVERAGED\")\n",
    "print(\"PRECIS  RECALL  F1    \")\n",
    "print(f\"{macro_precision:6.4f}  {macro_recall:6.4f}  {macro_f1:6.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_bayes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_results(question):\n",
    "    print('hi')\n",
    "    try:\n",
    "        with open(\"topic_models.pkl\", \"rb\") as f:\n",
    "            models, dictionary = pickle.load(f)\n",
    "    except:\n",
    "        print('heyo!')\n",
    "        build_model()\n",
    "        with open(\"topic_models.pkl\", \"rb\") as f:\n",
    "            models, dictionary = pickle.load(f)\n",
    "    try:\n",
    "        with open(\"classifier.pkl\", \"rb\") as f:\n",
    "            p_class, p_label = pickle.load(f)\n",
    "    except:\n",
    "        bayes_EM(models, dictionary)\n",
    "        with open(\"classifier.pkl\", \"rb\") as f:\n",
    "            p_class, p_label = pickle.load(f)\n",
    "    results = []\n",
    "    #print(question)\n",
    "    #txt1 = process([question.decode('utf-8')])\n",
    "    results = predict(str(question, 'utf-8'), models, dictionary, p_class, p_label)\n",
    "    return sorted(results, key=results.get, reverse=True)[:2]\n",
    "    # for file in os.listdir(\"topics/\"):\n",
    "    #     with open(\"topics/\" + file) as doc2:\n",
    "    #         txt = doc2.read()\n",
    "    #         # print(\"hey\")\n",
    "    #         txt = process([txt])\n",
    "    #         # print(txt)\n",
    "    #         # print(\"ho\")\n",
    "    #         kl = 0\n",
    "    #         for lda in models:\n",
    "    #             p = lda[dictionary.doc2bow(txt1[0])]\n",
    "    #             # print(p)\n",
    "    #             q = lda[dictionary.doc2bow(txt[0])]\n",
    "    #             # print(q)\n",
    "    #             for y, w1 in p:\n",
    "    #                 for x, w0 in q:\n",
    "    #                     if x == y:\n",
    "    #                         kl += w0 * w1\n",
    "    #         results.append((file, kl))\n",
    "    #return sorted(results, key=lambda x: -x[1])[:2]\n",
    "    # if not found:\n",
    "    #     kl += 1\n",
    "    # min_kl = math.inf\n",
    "    # for x, w0 in p:\n",
    "    #     found = False\n",
    "    #     for y, w1 in q:\n",
    "    #         if x == y:\n",
    "    #             found = True\n",
    "    #             kl += w0 * math.log(w0 / w1)\n",
    "    #     if not found:\n",
    "    #         kl += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
