8 . Structured Output Prediction Many problems in NLP involve structured outputs : cases where the desired output is not a class label or distribution over class labels , but a structured object such as a sequence , a tree or a graph . Canonical examples are sequence tagging ( e.g . part-of-speech tagging ) sequence segmentation ( chunking , NER ) , and syntactic parsing . In this section , we discuss how feed-forward neural network models can be used for structured tasks . In later sections we discuss specialized neural network models for dealing with sequences ( Section 10 ) and trees ( Section 12 ) . 8.1 Greedy Structured Prediction The greedy approach to structured prediction is to decompose the structure prediction problem into a sequence of local prediction problems and training a classifier to perform each local decision . At test time , the trained classifier is used in a greedy manner . Examples of this approach are left-to-right tagging models ( Giménez & Màrquez , 2004 ) and greedy transition-based parsing ( Nivre , 2008 ) . Such approaches are easily adapted to use neural networks by simply replacing the local classifier from a linear classifier such as an SVM or a logistic regression model to a neural network , as demonstrated in ( Chen & Manning , 2014 ; Lewis & Steedman , 2014 ) . The greedy approaches suffer from error propagation , where mistakes in early decisions carry over and influence later decisions . The overall higher accuracy achievable with non - linear neural network classifiers helps in offsetting this problem to some extent . In addition , training techniques were proposed for mitigating the error propagation problem by either attempting to take easier predictions before harder ones ( the easy-first approach ( Goldberg & Elhadad , 2010 ) ) or making training conditions more similar to testing conditions by exposing the training procedure to inputs that result from likely mistakes ( Hal Daumé III , Langford , & Marcu , 2009 ; Goldberg & Nivre , 2013 ) . These are effective also for training greedy neural network models , as demonstrated by Ma et al ( Ma , Zhang , & Zhu , 2014 ) ( easy-first tagger ) and ( ? ) ( dynamic oracle training for greedy dependency parsing ) . 8.2 Search Based Structured Prediction The common approach to predicting natural language structures is search based . For in - depth discussion of search-based structure prediction in NLP , see the book by Smith ( Smith , 2011 ) . The techniques can easily be adapted to use a neural-network . In the neural-networks literature , such models were discussed under the framework of energy based learning ( LeCun et al . , 2006 , Section 7 ) . They are presented here using setup and terminology familiar to the NLP community . Search-based structured prediction is formulated as a search problem over possible struc - tures : predict ( x ) = arg max y ∈ Y ( x ) score ( x , y ) where x is an input structure , y is an output over x ( in a typical example x is a sentence and y is a tag-assignment or a parse-tree over the sentence ) , Y ( x ) is the set of all valid 38 structures over x , and we are looking for an output y that will maximize the score of the x , y pair . The scoring function is defined as a linear model : score ( x , y ) = Φ ( x , y ) · w where Φ is a feature extraction function and w is a weight vector . In order to make the search for the optimal y tractable , the structure y is decomposed into parts , and the feature function is defined in terms of the parts , where φ ( p ) is a part-local feature extraction function : Φ ( x , y ) = ∑ p ∈ parts ( x , y ) φ ( p ) Each part is scored separately , and the structure score is the sum of the component parts scores : score ( x , y ) = w · Φ ( x , y ) = w · ∑ p ∈ y φ ( p ) = ∑ p ∈ y w · φ ( p ) = ∑ p ∈ y score ( p ) where p ∈ y is a shorthand for p ∈ parts ( x , y ) . The decomposition of y into parts is such that there exists an inference algorithm that allows for efficient search for the best scoring structure given the scores of the individual parts . One can now trivially replace the linear scoring function over parts with a neural - network : score ( x , y ) = ∑ p ∈ y score ( p ) = ∑ p ∈ y NN ( c ( p ) ) where c ( p ) maps the part p into a din dimensional vector . In case of a one hidden-layer feed-forward network : score ( x , y ) = ∑ p ∈ y NNMLP1 ( c ( p ) ) = ∑ p ∈ y ( g ( c ( p ) W1 + b1 ) ) w c ( p ) ∈ Rdin , W1 ∈ Rdin × d1 , b1 ∈ Rd1 , w ∈ Rd1 . A common objective in structured prediction is making the gold structure y score higher than any other structure y ′ , leading to the following ( generalized perceptron ) loss : max y ′ score ( x , y ′ ) − score ( x , y ) In terms of implementation , this means : create a computation graph CGp for each of the possible parts , and calculate its score . Then , run inference over the scored parts to find the best scoring structure y ′ . Connect the output nodes of the computation graphs corresponding to parts in the gold ( predicted ) structure y ( y ′ ) into a summing node CGy ( CG ′ y ) . Connect CGy and CG ′ y using a “ minus ” node , CGl , and compute the gradients . As argued in ( LeCun et al . , 2006 , Section 5 ) , the generalized perceptron loss may not be a good loss function when training structured prediction neural networks as it does not have a margin , and a margin-based hinge loss is preferred : 39 max ( 0 , m + score ( x , y ) − max y ′ 6 = y score ( x , y ′ ) ) It is trivial to modify the implementation above to work with the hinge loss . Note that in both cases we lose the nice properties of the linear model . In particular , the model is no longer convex . This is to be expected , as even the simplest non-linear neural network is already non-convex . Nonetheless , we could still use standard neural-network optimization techniques to train the structured model . Training and inference is slower , as we have to evaluate the neural network ( and take gradients ) | parts ( x , y ) | times . Structured prediction is a vast field and is beyond the scope of this tutorial , but loss func - tions , regularizers and methods described in , e.g . , ( Smith , 2011 ) , such as cost-augmented decoding , can be easily applied or adapted to the neural-network framework . 23 Probabilistic objective ( CRF ) In a probabilistic framework ( “ CRF ” ) , we treat each of the parts scores as a clique potential ( see ( Smith , 2011 ) ) and define the score of each structure y to be : scoreCRF ( x , y ) = P ( y | x ) = ∑ p ∈ y e score ( p ) ∑ y ′ ∈ Y ( x ) ∑ p ∈ y ′ e score ( p ) = ∑ p ∈ y e NN ( c ( p ) ) ∑ y ′ ∈ Y ( x ) ∑ p ∈ y ′ e NN ( c ( p ) ) The scoring function defines a conditional distribution P ( y | x ) , and we wish to set the pa - rameters of the network such that corpus conditional log likelihood ∑ ( xi , yi ) ∈ training logP ( yi | xi ) is maximized . The loss for a given training example ( x , y ) is then : − log scoreCRF ( x , y ) . Taking the gradient with respect to the loss is as involved as building the associated computation graph . The tricky part is the denominator ( the partition function ) which requires summing over the potentially exponentially many structures in Y . However , for some problems , a dynamic programming algorithm exists for efficiently solving the summation in polynomial time . When such an algorithm exists , it can be adapted to also create a polynomial-size computation graph . When an efficient enough algorithm for computing the partition function is not available , approximate methods can be used . For example , one may use beam search for inference , and for the partition function sum over the structures remaining in the beam instead of over the exponentially large Y ( x ) . A hinge based approached was used by Pei et al ( 2015 ) for arc-factored dependency parsing , and the probabilistic approach by Durrett and Klein ( Durrett & Klein , 2015 ) for a CRF constituency parser . The approximate beam-based partition function was effectively used by Zhou et al ( 2015 ) in a transition based parser . Reranking When searching over all possible structures is intractable , inefficient or hard to integrate into a model , reranking methods are often used . In the reranking framework ( Charniak & Johnson , 2005 ; Collins & Koo , 2005 ) a base model is used to produce a 23 . One should keep in mind that the resulting objectives are no longer convex , and so lack the formal guar - antees and bounds associated with convex optimization problems . Similarly , the theory , learning bounds and guarantees associated with the algorithms do not automatically transfer to the neural versions . 40 list of the k-best scoring structures . A more complex model is then trained to score the candidates in the k-best list such that the best structure with respect to the gold one is scored highest . As the search is now performed over k items rather than over an exponential space , the complex model can condition on ( extract features from ) arbitrary aspects of the scored structure . Reranking methods are natural candidates for structured prediction using neural-network models , as they allow the modeler to focus on the feature extraction and network structure , while removing the need to integrate the neural network scoring into a decoder . Indeed , reranking methods are often used for experimenting with neural models that are not straightforward to integrate into a decoder , such as convolutional , recurrent and recursive networks , which will be discussed in later sections . Works using the reranking approach include ( Socher et al . , 2013 ; Auli et al . , 2013 ; Le & Zuidema , 2014 ; Zhu et al . , 2015a ) MEMM and hybrid approaches Other formulations are , of course , also possible . For example , an MEMM ( McCallum , Freitag , & Pereira , 2000 ) can be trivially adapted to the neural network world by replacing the logistic regression ( “ Maximum Entropy ” ) component with an MLP . Hybrid approaches between neural networks and linear models are also explored . In particular , Weiss et al ( Weiss et al . , 2015 ) report strong results for transition-based depen - dency parsing in a two-stage model . In the first stage , a static feed-forward neural network ( MLP2 ) is trained to perform well on each of the individual decisions of the structured problem in isolation . In the second stage , the neural network model is held fixed , and the different layers ( output as well as hidden layer vectors ) for each input are then concatenated and used as the input features of a linear structured perceptron model ( Collins , 2002 ) that is trained to perform beam-search for the best resulting structure . While it is not clear that such training regime is more effective than training a single structured-prediction neu - ral network , the use of two simpler , isolated models allowed the researchers to perform a much more extensive hyper-parameter search ( e.g . tuning layer sizes , activation functions , learning rates and so on ) for each model than is feasible with more complicated networks . 41