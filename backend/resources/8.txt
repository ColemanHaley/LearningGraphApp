Speech Language Processing . Daniel Jurafsky & James H . Martin . Copyright c © 2019 . rights reserved . Draft October 2 , 2019 . CHAPTER 8 Part-of-Speech Tagging Dionysius Thrax Alexandria ( c . 100 B.C . ) , perhaps someone else ( long time ago ) , wrote grammatical sketch Greek ( “ technē ” ) summarized linguistic knowledge day . work source astonishing proportion modern linguistic vocabulary , including words like syntax , diphthong , clitic , analogy . included description eight parts speech : noun , verb , parts speech pronoun , preposition , adverb , conjunction , participle , article . Although earlier scholars ( including Aristotle well Stoics ) own lists parts speech , Thrax’s set eight became basis practically subsequent part-of-speech descriptions European languages next 2000 years . Schoolhouse Rock series popular animated educational television clips 1970s . Grammar Rock sequence included songs exactly 8 parts speech , including late great Bob Dorough’s Conjunction Junction : Conjunction Junction , function ? Hooking up words phrases clauses . . . Although list 8 slightly modified Thrax’s original , astonishing durability parts speech two millennia indicator importance transparency role human language . 1 Parts speech ( known POS , word classes , syntactic categories ) arePOS useful reveal lot word neighbors . Knowing word noun verb tells likely neighboring words ( nouns pre - ceded determiners adjectives , verbs nouns ) syntactic structure ( nouns generally part noun phrases ) , making part-of-speech tagging key aspect parsing ( Chapter 13 ) . Parts speech useful features labeling named entities like people organizations information extraction ( Chapter 18 ) , corefer - ence resolution ( Chapter 22 ) . word’s part speech even play role speech recognition synthesis , e.g . , word content pronounced CONtent noun conTENT adjective . chapter introduces parts speech , introduces two algorithms part-of-speech tagging , task assigning parts speech words . generative — Hidden Markov Model ( HMM ) — discriminative — Max - imum Entropy Markov Model ( MEMM ) . Chapter 9 introduces third algorithm based recurrent neural network ( RNN ) . three roughly equal perfor - mance , , different tradeoffs . 8.1 ( Mostly ) English Word Classes part-of-speech terms like noun verb rather freely . section give complete definition classes . word classes semantic tendencies — adjectives , example , often describe 1 Nonetheless , eight many , , recent tagsets . 2 CHAPTER 8 • PART-OF-SPEECH TAGGING properties nouns people — parts speech traditionally defined based syntactic morphological function , grouping words similar neighbor - ing words ( distributional properties ) take similar affixes ( morpholog - ical properties ) . Parts speech divided two broad supercategories : closed class typesclosed class open class types . Closed classes relatively fixed membership , open class prepositions — new prepositions rarely coined . contrast , nouns verbs open classes — new nouns verbs like iPhone fax continually created borrowed . speaker corpus different open class words , speakers language , sufficiently large corpora , likely share set closed class words . Closed class words generally function wordsfunction word like , , , , tend short , occur frequently , often structuring grammar . Four major open classes occur languages world : nouns , verbs , adjectives , adverbs . English four , although every language . syntactic class noun includes words people , places , things , butnoun others well . Nouns include concrete terms like ship chair , abstractions like bandwidth relationship , verb-like terms like pacing pacing fro became quite annoying . defines noun English , , things like ability occur determiners ( goat , bandwidth , Plato’s Republic ) , take possessives ( IBM’s annual revenue ) , nouns occur plural form ( goats , abaci ) . Open class nouns fall two classes . Proper nouns , like Regina , Colorado , proper noun IBM , names specific persons entities . English , generally preceded articles ( e.g . , book upstairs , Regina upstairs ) . written English , proper nouns usually capitalized . class , common nouns , arecommon noun divided many languages , including English , count nouns mass nouns . count noun mass noun Count nouns allow grammatical enumeration , occurring singular plu - ral ( goat / goats , relationship / relationships ) counted ( goat , two goats ) . Mass nouns something conceptualized homogeneous group . words like snow , salt , communism counted ( i.e . , * two snows * two communisms ) . Mass nouns appear articles singular count nouns ( Snow white * Goat white ) . Verbs refer actions processes , including main verbs like draw , provide , verb go . English verbs inflections ( non-third-person-sg ( eat ) , third-person-sg ( eats ) , progressive ( eating ) , past participle ( eaten ) ) . many researchers believe human languages categories noun verb , others argued languages , Riau Indonesian Tongan , even make distinction ( Broschart 1997 ; Evans 2000 ; Gil 2000 ) . third open class English form adjectives , class includes many termsadjective properties qualities . languages adjectives concepts color ( white , black ) , age ( old , young ) , value ( good , bad ) , languages adjectives . Korean , example , words corresponding English adjectives act subclass verbs , English adjective “ beautiful ” acts Korean like verb meaning “ beautiful ” . final open class form , adverbs , rather hodge-podge form andadverb meaning . following italicized words adverbs : Actually , ran home extremely quickly yesterday coherence class semantically solely words viewed modifying something ( often verbs , hence name “ ad - 8.1 • ( MOSTLY ) ENGLISH WORD CLASSES 3 verb ” , adverbs entire verb phrases ) . Directional adverbs loca - tive adverbs ( home , , downhill ) specify direction location action ; locative degree adverbs ( extremely , , somewhat ) specify extent action , pro-degree cess , property ; manner adverbs ( slowly , slinkily , delicately ) describe mannermanner action process ; temporal adverbs describe time ac-temporal tion event took place ( yesterday , Monday ) . heterogeneous nature class , adverbs ( e.g . , temporal adverbs like Monday ) tagged tagging schemes nouns . closed classes differ language language open classes . important closed classes English include : prepositions : , , , near , , , , , particles : up , down , , off , , , , determiners : , , conjunctions : , , , , , pronouns : , , , others auxiliary verbs : , , , numerals : , two , three , first , second , third Prepositions occur noun phrases . Semantically often indicate spatialpreposition temporal relations , literal ( , , house ) metaphor - ical ( time , gusto , beside herself ) , often indicate relations well , like marking agent Hamlet written Shakespeare . particle resemblesparticle preposition adverb combination verb . Particles often extended meanings quite same prepositions resemble , particle turned paper . verb particle act single syntactic / semantic unit called phrasal verb . meaning phrasal verbs often problematically non-phrasal verb compositional — predictable distinct meanings verb par - ticle . Thus , turn down means something like ‘ reject ’ , rule ‘ eliminate ’ , find ‘ discover ’ , go ‘ continue ’ . closed class occurs nouns , often marking beginning noun phrase , determiner . small subtype determiners article : Englishdeterminer article three articles : , , . determiners include ( chap - ter , page ) . mark noun phrase indefinite , mark definite ; definiteness discourse property ( Chapter 23 ) . Articles quite fre - quent English ; indeed , frequently occurring word corpora written English , generally right behind . Conjunctions join two phrases , clauses , sentences . Coordinating conjunc-conjunctions tions like , , join two elements equal status . Subordinating conjunc - tions elements embedded status . example , “ thought might like milk ” subordinating conjunction links main clause thought subordinate clause might like milk . clause called subordinate entire clause “ content ” main verb thought . Subordinating conjunctions like link verb argument way called complementizers . complementizer Pronouns forms often act kind shorthand referring somepronoun noun phrase entity event . Personal pronouns refer persons entities ( , personal , , , , etc . ) . Possessive pronouns forms personal pronouns in-possessive dicate actual possession often just abstract relation person object ( , , , , , one’s , , ) . Wh-pronounswh ( , , whom , whoever ) certain question forms , act 4 CHAPTER 8 • PART-OF-SPEECH TAGGING complementizers ( Frida , married Diego . . . ) . closed class subtype English verbs auxiliary verbs . Cross-linguist-auxiliary ically , auxiliaries mark semantic features main verb : action takes place present , past , future ( tense ) , completed ( aspect ) , negated ( polarity ) , action necessary , possible , suggested , desired ( mood ) . English auxiliaries include copula verb , two verbs andcopula , inflected forms , well class modal verbs . calledmodal copula connects subjects certain kinds predicate nominals adjectives ( duck ) . verb mark perfect tenses ( gone , gone ) , part passive ( robbed ) progressive ( leaving ) constructions . Modals mark mood associated event depicted main verb : indicates ability possibility , permission possibility , necessity . modal ( e.g . , go ) . English many words less unique function , including inter - jections ( oh , hey , alas , uh , um ) , negatives ( , ) , politeness markers ( please , interjection negative thank ) , greetings ( hello , goodbye ) , existential ( two table ) among others . classes distinguished lumped together interjections adverbs depending purpose labeling . 8.2 Penn Treebank Part-of-Speech Tagset important tagset English 45-tag Penn Treebank tagset ( Marcus et al . , 1993 ) , shown Fig . 8.1 , label many corpora . labelings , parts speech generally represented placing tag word , delimited slash : Tag Description Example Tag Description Example Tag Description Example CC coordinating conjunction , , PDT predeterminer , VBP verb non-3sg present eat CD cardinal number , two POS possessive ending ’ s VBZ verb 3sg pres eats DT determiner , PRP personal pronoun , , WDT wh-determ . , EX existential ‘ ’ PRP $ possess . pronoun , one’s WP wh-pronoun , FW foreign word mea culpa RB adverb quickly WP $ wh-possess . whose preposition / subordin-conj , , RBR comparative adverb faster WRB wh-adverb , JJ adjective yellow RBS superlatv . adverb fastest $ dollar sign $ JJR comparative adj bigger RP particle up , off # pound sign # JJS superlative adj wildest SYM symbol + , % , & “ left quote ‘ “ LS list item marker 1 , 2 , “ ” ” right quote ’ ” MD modal , UH interjection ah , oops ( left paren [ , ( , { , < NN sing mass noun llama VB verb base form eat ) right paren ] , ) , } , > NNS noun , plural llamas VBD verb past tense ate , comma , NNP proper noun , sing . IBM VBG verb gerund eating . sent-end punc . ! ? NNPS proper noun , plu . Carolinas VBN verb past part . eaten : sent-mid punc : ; . . . – - Figure 8.1 Penn Treebank part-of-speech tags ( including punctuation ) . ( 8.1 ) / DT grand / JJ jury / NN commented / VBD / / DT number / NN / / JJ topics / NNS . / . ( 8.2 ) / EX / VBP 70 / CD children / NNS / RB 8.2 • PENN TREEBANK PART-OF-SPEECH TAGSET 5 ( 8.3 ) Preliminary / JJ findings / NNS / VBD reported / VBN / today / NN ’ s / POS New / NNP England / NNP Journal / NNP / Medicine / NNP . / . Example ( 8.1 ) shows determiners , adjectives grand , common nouns jury , number , topics , past tense verb commented . Example ( 8.2 ) shows EX tag mark existential construction English , , comparison , another tagged adverb ( RB ) . Example ( 8.3 ) shows segmentation possessive morpheme ’ s , passive construction , ‘ reported ’ , reported tagged past participle ( VBN ) . Note New England Journal Medicine proper noun , Treebank tagging chooses mark noun separately NNP , including journal medicine , might otherwise labeled common nouns ( NN ) . Corpora labeled parts speech crucial training ( testing ) sets statistical tagging algorithms . Three main tagged corpora consistently training testing part-of-speech taggers English . Brown corpus mil-Brown lion words samples 500 written texts different genres published United States 1961 . WSJ corpus contains million words published theWSJ Wall Street Journal 1989 . Switchboard corpus consists 2 million wordsSwitchboard telephone conversations collected 1990-1991 . corpora created running automatic part-of-speech tagger texts human annotators hand-corrected tag . minor differences tagsets corpora . example WSJ Brown corpora , single Penn tag infinitive ( like race ) preposition ( go store ) , Switchboard tag reserved infinitive preposition tagged : Well / UH , / , / PRP , / , / PRP / VBP / go / VB / / DT restaurant / NN Finally , idiosyncracies inherent tagset . example , - cause Penn 45 tags collapsed larger 87-tag tagset , original Brown tagset , potentially useful distinctions lost . Penn tagset designed treebank sentences parsed , leaves off syntactic information recoverable parse tree . Thus example Penn tag subordinating conjunctions like , , unless , : / spending / VBG / DT day / NN / / DT beach / NN prepositions like , , : / sunrise / NN Words generally tokenized tagging . Penn Treebank British National Corpus split contractions ’ s-genitive stems : 2 / MD n’t / RB children / NNS ’ s / POS Treebank tagset assumes tokenization multipart words like New York whitespace , thus tagging . New York City firm / DT New / NNP York / NNP City / NNP firm / NN . Another commonly tagset , Universal POS tag set Universal De - pendencies project ( Nivre et al . , 2016 ) , building systems tag many languages . Section 8.7 . 2 Indeed , Treebank tag POS ’ s , segmented tokenization . 6 CHAPTER 8 • PART-OF-SPEECH TAGGING 8.3 Part-of-Speech Tagging Part-of-speech tagging process assigning part-of-speech marker eachpart-of-speechtagging word input text . 3 input tagging algorithm sequence ( tokenized ) words tagset , output sequence tags , per token . Tagging disambiguation task ; words ambiguous — oneambiguous possible part-of-speech — goal find correct tag situation . example , book verb ( book flight ) noun ( hand book ) . determiner ( flight serve dinner ) complementizer ( thought flight earlier ) . goal POS-tagging resolve theseambiguityresolution ambiguities , choosing proper tag context . common tag ambiguity ? Fig . 8.2 shows word types ( 85-86 % ) unambiguous ( Janet always NNP , funniest JJS , hesitantly RB ) . ambiguous words , though accounting 14-15 % vocabulary , common words , hence 55-67 % word tokens running text ambiguous . 4 Types : WSJ Brown Unambiguous ( 1 tag ) 44,432 ( 86 % ) 45,799 ( 85 % ) Ambiguous ( 2 + tags ) 7,025 ( 14 % ) 8,050 ( 15 % ) Tokens : Unambiguous ( 1 tag ) 577,421 ( 45 % ) 384,349 ( 33 % ) Ambiguous ( 2 + tags ) 711,780 ( 55 % ) 786,646 ( 67 % ) Figure 8.2 Tag ambiguity word types Brown WSJ , Treebank-3 ( 45-tag ) tagging . Punctuation treated words , words kept original case . ambiguous frequent words , back , down , put set ; examples 6 different parts speech word back : earnings growth took back / JJ seat small building back / NN clear majority senators back / VBP bill Dave began back / VB toward door enable country buy back / RP debt twenty-one back / RB Nonetheless , many words easy disambiguate , different tags equally likely . example , determiner letter , determiner sense likely . idea suggests simplistic baseline algo - rithm part-of-speech tagging : ambiguous word , choose tag frequent training corpus . key concept : Frequent Class Baseline : Always compare classifier against baseline least good frequent class baseline ( assigning token class occurred often training set ) . good baseline ? standard way measure performance part - of-speech taggers accuracy : percentage tags correctly labeled ( matchingaccuracy 3 Tags applied punctuation , tagging assumes tokenizing commas , quotation marks , etc . , disambiguating end-of-sentence periods periods inside words ( e.g . , etc . ) . 4 Note large differences two genres , especially token frequency . Tags WSJ corpus less ambiguous ; focus financial news leads limited distribution word usages diverse genres Brown corpus . 8.4 • HMM PART-OF-SPEECH TAGGING 7 human labels test set ) . train WSJ training corpus test sec - tions 22-24 same corpus most-frequent-tag baseline achieves accuracy 92.34 % . contrast , state art part-of-speech tagging dataset around 97 % tag accuracy , performance achievable algorithms ( HMMs , MEMMs , neural networks , rule-based algorithms ) . Section 8.7 languages genres . 8.4 HMM Part-of-Speech Tagging section introduce Hidden Markov Model part-of-speech tagging . HMM sequence model . sequence model sequence classi-sequence model fier model whose job assign label class unit sequence , thus mapping sequence observations sequence labels . HMM probabilistic sequence model : sequence units ( words , letters , morphemes , sentences , whatever ) , computes probability distribution possible sequences labels chooses best label sequence . 8.4.1 Markov Chains HMM based augmenting Markov chain . Markov chain modelMarkov chain tells something probabilities sequences random variables , states , take values set . sets words , tags , symbols representing anything , example weather . Markov chain makes strong assumption predict future sequence , matters current state . states current state - pact future except via current state . predict tomorrow’s weather examine today’s weather weren’t allowed look yesterday’s weather . WARM3HOT1 COLD2 . 8 . 6 . 1 . 1 . 3 . 6 . 1 . 1 . 3 charminguniformly . 1 . 4 . 5 . 5 . 5 . 2 . 6 . 2 ( ) ( b ) Figure 8.3 Markov chain weather ( ) words ( b ) , showing states transitions . start distribution π required ; setting π = [ 0.1 , 0.7 , 0.2 ] ( ) mean probability 0.7 starting state 2 ( cold ) , probability 0.1 starting state 1 ( hot ) , etc . formally , consider sequence state variables q1 , q2 , . . . , qi . Markov model embodies Markov assumption probabilities sequence : thatMarkovassumption predicting future , past matter , present . Markov Assumption : P ( qi = | q1 . . . qi − 1 ) = P ( qi = | qi − 1 ) ( 8.4 ) Figure 8.3a shows Markov chain assigning probability sequence weather events , vocabulary consists HOT , COLD , WARM . 8 CHAPTER 8 • PART-OF-SPEECH TAGGING states represented nodes graph , transitions , probabil - ities , edges . transitions probabilities : values arcs leaving state sum 1 . Figure 8.3b shows Markov chain assigning probability sequence words w1 . . . wn . Markov chain familiar ; fact , repre - sents bigram language model , edge expressing probability p ( wi | w j ) ! two models Fig . 8.3 , assign probability sequence vocabulary . Formally , Markov chain specified following components : Q = q1q2 . . . qN set N states = a11a12 . . . an1 . . . ann transition probability matrix , ai j represent - ing probability moving state state j , s.t . ∑ n j = 1 ai j = 1 ∀ π = π1 , π2 , . . . , πN initial probability distribution states . πi probability Markov chain start state . states j π j = 0 , meaning initial states . , ∑ n = 1 πi = 1 go , sample probabilities Fig . 8.3a ( π = [ 0.1,0.7,0.2 ] ) compute probability following sequences : ( 8.5 ) hot hot hot hot ( 8.6 ) cold hot cold hot difference probabilities tell real-world weather fact encoded Fig . 8.3a ? 8.4.2 Hidden Markov Model Markov chain useful need compute probability sequence observable events . many cases , , events interested hidden : observe directly . example normally observehidden part-of-speech tags text . Rather , words , infer tags word sequence . call tags hidden observed . hidden Markov model ( HMM ) allows talk observed eventsHiddenMarkov model ( like words input ) hidden events ( like part-of-speech tags ) think causal factors probabilistic model . HMM specified following components : Q = q1q2 . . . qN set N states = a11 . . . ai j . . . aNN transition probability matrix , ai j representing probability moving state state j , s.t . ∑ N j = 1 ai j = 1 ∀ O = o1o2 . . . oT sequence T observations , drawn vocabulary V = v1 , v2 , . . . , vV B = bi ( ot ) sequence observation likelihoods , called emission probabili - ties , expressing probability observation ot generated state qi π = π1 , π2 , . . . , πN initial probability distribution states . πi probability Markov chain start state . states j π j = 0 , meaning initial states . , ∑ n = 1 πi = 1 8.4 • HMM PART-OF-SPEECH TAGGING 9 first-order hidden Markov model instantiates two simplifying assumptions . First , first-order Markov chain , probability particular state depends previous state : Markov Assumption : P ( qi | q1 . . . qi − 1 ) = P ( qi | qi − 1 ) ( 8.7 ) Second , probability output observation oi depends state produced observation qi states observations : Output Independence : P ( oi | q1 . . . qi , . . . , qT , o1 , . . . , oi , . . . , oT ) = P ( oi | qi ) ( 8.8 ) 8.4.3 components HMM tagger start looking pieces HMM tagger , tag . HMM two components , B probabilities . matrix contains tag transition probabilities P ( ti | ti − 1 ) represent probability tag occurring previous tag . example , modal verbs like likely followed verb base form , VB , like race , expect probability high . compute maximum likelihood estimate transition probability counting , times first tag labeled corpus , often first tag followed second : P ( ti | ti − 1 ) = C ( ti − 1 , ti ) C ( ti − 1 ) ( 8.9 ) WSJ corpus , example , MD occurs 13124 times followed VB 10471 , MLE estimate P ( V B | MD ) = C ( MD , V B ) C ( MD ) = 10471 13124 = . 80 ( 8.10 ) walk example , seeing probabilities estimated sample tagging task , return algorithm decoding . HMM tagging , probabilities estimated counting tagged training corpus . example tagged WSJ corpus . B emission probabilities , P ( wi | ti ) , represent probability , tag ( say MD ) , associated word ( say ) . MLE emis - sion probability P ( wi | ti ) = C ( ti , wi ) C ( ti ) ( 8.11 ) 13124 occurrences MD WSJ corpus , associated 4046 times : P ( | MD ) = C ( MD , ) C ( MD ) = 4046 13124 = . 31 ( 8.12 ) saw kind Bayesian modeling Chapter 4 ; recall likelihood term asking “ likely tag word ? ” posterior P ( MD | ) . , P ( | MD ) answers slightly counterintuitive question “ going generate MD , likely modal ? ” transition probabilities , B observation likelihoods HMM illustrated Fig . 8.4 three states HMM part-of-speech tagger ; full tagger state tag . 10 CHAPTER 8 • PART-OF-SPEECH TAGGING NN3VB1 MD2 a22 a11 a12 a21 a13 a33 a32 a23 a31 P ( " aardvark " | NN ) . . . P ( “ ” | NN ) . . . P ( " " | NN ) . . . P ( “ back ” | NN ) . . . P ( " zebra " | NN ) B3 P ( " aardvark " | VB ) . . . P ( “ ” | VB ) . . . P ( " " | VB ) . . . P ( “ back ” | VB ) . . . P ( " zebra " | VB ) B1 P ( " aardvark " | MD ) . . . P ( “ ” | MD ) . . . P ( " " | MD ) . . . P ( “ back ” | MD ) . . . P ( " zebra " | MD ) B2 Figure 8.4 illustration two parts HMM representation : transition probabilities compute prior probability , B observation likelihoods associated state , likelihood possible observation word . 8.4.4 HMM tagging decoding model , HMM , contains hidden variables , task deter - mining hidden variables sequence corresponding sequence observations called decoding . formally , decoding Decoding : input HMM λ = ( , B ) sequence ob - servations O = o1 , o2 , . . . , oT , find probable sequence states Q = q1q2q3 . . . qT . part-of-speech tagging , goal HMM decoding choose tag se - quence tn1 probable observation sequence n words w n 1 : t̂n1 = argmax tn1 P ( tn1 | wn1 ) ( 8.13 ) way HMM Bayes ’ rule compute : t̂n1 = argmax tn1 P ( wn1 | tn1 ) P ( tn1 ) P ( wn1 ) ( 8.14 ) Furthermore , simplify Eq . 8.14 dropping denominator P ( wn1 ) : t̂n1 = argmax tn1 P ( wn1 | tn1 ) P ( tn1 ) ( 8.15 ) HMM taggers make two further simplifying assumptions . first probability word appearing depends own tag independent neighboring words tags : P ( wn1 | tn1 ) ≈ n ∏ = 1 P ( wi | ti ) ( 8.16 ) second assumption , bigram assumption , probability tag dependent previous tag , rather entire tag sequence ; P ( tn1 ) ≈ n ∏ = 1 P ( ti | ti − 1 ) ( 8.17 ) 8.4 • HMM PART-OF-SPEECH TAGGING 11 Plugging simplifying assumptions Eq . 8.16 Eq . 8.17 Eq . 8.15 results following equation probable tag sequence bigram tagger : t̂n1 = argmax tn1 P ( tn1 | wn1 ) ≈ argmax tn1 n ∏ = 1 emission ︷ ︸ ︸ ︷ P ( wi | ti ) transition ︷ ︸ ︸ ︷ P ( ti | ti − 1 ) ( 8.18 ) two parts Eq . 8.18 correspond neatly B emission probability transition probability just defined ! 8.4.5 Viterbi Algorithm decoding algorithm HMMs Viterbi algorithm shown Fig . 8.5 . AsViterbialgorithm instance dynamic programming , Viterbi resembles dynamic program - ming minimum edit distance algorithm Chapter 2 . function VITERBI ( observations len T , state-graph len N ) returns best-path , path-prob create path probability matrix viterbi [ N , T ] state s 1 N ; initialization step viterbi [ s , 1 ] ← πs ∗ bs ( o1 ) backpointer [ s , 1 ] ← 0 time step t 2 T ; recursion step state s 1 N viterbi [ s , t ] ← Nmax s ′ = 1 viterbi [ s ′ , t − 1 ] ∗ ′ , s ∗ bs ( ot ) backpointer [ s , t ] ← Nargmax s ′ = 1 viterbi [ s ′ , t − 1 ] ∗ ′ , s ∗ bs ( ot ) bestpathprob ← Nmax s = 1 viterbi [ s , T ] ; termination step bestpathpointer ← Nargmax s = 1 viterbi [ s , T ] ; termination step bestpath ← path starting state bestpathpointer , follows backpointer [ ] states back time return bestpath , bestpathprob Figure 8.5 Viterbi algorithm finding optimal sequence tags . observation sequence HMM λ = ( , B ) , algorithm returns state path HMM assigns maximum likelihood observation sequence . Viterbi algorithm first sets up probability matrix lattice , col - umn observation ot row state state graph . col - umn thus cell state qi single combined automaton . Figure 8.6 shows intuition lattice sentence Janet back bill . cell lattice , vt ( j ) , represents probability HMM state j seeing first t observations passing probable state sequence q1 , . . . , qt − 1 , HMM λ . value cell vt ( j ) computed recursively taking probable path lead cell . Formally , cell expresses probability vt ( j ) = max q1 , . . . , qt − 1 P ( q1 . . . qt − 1 , o1 , o2 . . . ot , qt = j | λ ) ( 8.19 ) represent probable path taking maximum possible previous state sequences max q1 , . . . , qt − 1 . Like dynamic programming algorithms , 12 CHAPTER 8 • PART-OF-SPEECH TAGGING JJ NNP NNP NNP MD MD MD MD VB VB JJ JJ JJ NN NN RB RBRBRB DT DT DT DT NNP Janet back bill NN VB MD NN VB JJ RB NNP DT NN VB Figure 8.6 sketch lattice Janet back bill , showing possible tags ( qi ) word highlighting path corresponding correct tag sequence hidden states . States ( parts speech ) zero probability generating particular word according B matrix ( probability determiner DT realized Janet ) greyed . Viterbi fills cell recursively . already computed probabil - ity every state time t − 1 , compute Viterbi probability taking probable extensions paths lead current cell . state q j time t , value vt ( j ) computed vt ( j ) = N max = 1 vt − 1 ( ) ai j b j ( ot ) ( 8.20 ) three factors multiplied Eq . 8.20 extending previous paths compute Viterbi probability time t vt − 1 ( ) previous Viterbi path probability previous time step ai j transition probability previous state qi current state q j b j ( ot ) state observation likelihood observation symbol ot current state j 8.4.6 Working example tag sentence Janet back bill ; goal correct series tags ( Fig . 8.6 ) : ( 8.21 ) Janet / NNP / MD back / VB / DT bill / NN Let HMM defined two tables Fig . 8.7 Fig . 8.8 . Figure 8.7 lists ai j probabilities transitioning hidden states ( part-of-speech tags ) . Figure 8.8 expresses bi ( ot ) probabilities , observation likelihoods words tags . table ( slightly simplified ) counts WSJ corpus . word Janet appears NNP , back 4 possible parts speech , word appear determiner NNP ( titles like “ Somewhere Rainbow ” words tagged NNP ) . Figure 8.9 shows fleshed-out version sketch saw Fig . 8.6 , Viterbi lattice computing best hidden state sequence observation se - quence Janet back bill . 8.4 • HMM PART-OF-SPEECH TAGGING 13 NNP MD VB JJ NN RB DT < s > 0.2767 0.0006 0.0031 0.0453 0.0449 0.0510 0.2026 NNP 0.3777 0.0110 0.0009 0.0084 0.0584 0.0090 0.0025 MD 0.0008 0.0002 0.7968 0.0005 0.0008 0.1698 0.0041 VB 0.0322 0.0005 0.0050 0.0837 0.0615 0.0514 0.2231 JJ 0.0366 0.0004 0.0001 0.0733 0.4509 0.0036 0.0036 NN 0.0096 0.0176 0.0014 0.0086 0.1216 0.0177 0.0068 RB 0.0068 0.0102 0.1011 0.1012 0.0120 0.0728 0.0479 DT 0.1147 0.0021 0.0002 0.2157 0.4744 0.0102 0.0017 Figure 8.7 transition probabilities P ( ti | ti − 1 ) computed WSJ corpus smoothing . Rows labeled conditioning event ; thus P ( V B | MD ) 0.7968 . Janet back bill NNP 0.000032 0 0 0.000048 0 MD 0 0.308431 0 0 0 VB 0 0.000028 0.000672 0 0.000028 JJ 0 0 0.000340 0 0 NN 0 0.000200 0.000223 0 0.002337 RB 0 0 0.010446 0 0 DT 0 0 0 0.506099 0 Figure 8.8 Observation likelihoods B computed WSJ corpus smoothing , simplified slightly . N = 5 state columns . begin column 1 ( word Janet ) setting Viterbi value cell product π transition probability ( start probability state , get < s > entry Fig . 8.7 ) , observation likelihood word Janet tag cell . cells column zero word Janet tags . reader find Fig . 8.9 . Next , cell column gets updated . state , compute value viterbi [ s , t ] taking maximum extensions paths previous column lead current cell according Eq . 8.20 . shown values MD , VB , NN cells . cell gets max 7 values previous column , multiplied appropriate transition probabil - ity ; happens case , zero previous column . remaining value multiplied relevant observation probability , ( triv - ial ) max taken . case final value , 2.772e-8 , comes NNP state previous column . reader fill rest lattice Fig . 8.9 backtrace Viterbi algorithm returns gold state sequence NNP MD VB DT NN . 8.4.7 Extending HMM Algorithm Trigrams Practical HMM taggers number extensions simple model . important missing feature wider tag context . tagger described probability tag depends previous tag : P ( tn1 ) ≈ n ∏ = 1 P ( ti | ti − 1 ) ( 8.22 ) 14 CHAPTER 8 • PART-OF-SPEECH TAGGING π P ( NNP | sta rt ) = . 28 * P ( MD | MD ) = 0 * P ( MD | N NP ) . 00 00 09 * . 0 1 = . 9e - 8 v1 ( 2 ) = . 0006 x 0 = 0 v1 ( 1 ) = . 28 * . 000032 = . 000009 t MDq2 q1 o1 Janet billwill o2 o3 back VB JJ v1 ( 3 ) = . 0031 x 0 = 0 v1 ( 4 ) = . 045 * 0 = 0 o4 * P ( MD | VB ) = 0 * P ( MD | JJ ) = 0 P ( VB | start ) = . 00 31 P ( JJ | star t ) = . 045 backtrace q3 q4 NNq5 RBq6 DTq7 v2 ( 2 ) = max * . 308 = 2.772e-8 v2 ( 5 ) = max * . 0002 = . 0000000001 v2 ( 3 ) = max * . 000028 = 2.5e-13 v3 ( 6 ) = max * . 0104 v3 ( 5 ) = max * . 000223 v3 ( 4 ) = max * . 00034 v3 ( 3 ) = max * . 00067 v1 ( 5 ) v1 ( 6 ) v1 ( 7 ) v2 ( 1 ) v2 ( 4 ) v2 ( 6 ) v2 ( 7 ) backtrace * P ( R B | N N ) * P ( NN | NN ) start start start start start o5 NNP P ( MD | start ) = . 00 06 Figure 8.9 first few entries individual state columns Viterbi algorithm . cell keeps probability best path far pointer previous cell path . filled columns 1 2 ; avoid clutter cells value 0 left empty . rest left exercise reader . cells filled , backtracing end state , able reconstruct correct state sequence NNP MD VB DT NN . practice history , letting probability tag depend two previous tags : P ( tn1 ) ≈ n ∏ = 1 P ( ti | ti − 1 , ti − 2 ) ( 8.23 ) Extending algorithm bigram trigram taggers gives small ( perhaps half point ) increase performance , conditioning two previous tags requires significant change Viterbi algorithm . cell , taking max transitions cell previous column , take max paths cells previous two columns , thus considering N2 rather N hidden states every observation . addition increasing context window , HMM taggers number advanced features . let tagger know location end sentence adding dependence end-of-sequence marker tn + 1 . gives following equation part-of-speech tagging : t̂n1 = argmax tn1 P ( tn1 | wn1 ) ≈ argmax tn1 [ n ∏ = 1 P ( wi | ti ) P ( ti | ti − 1 , ti − 2 ) ] P ( tn + 1 | tn ) ( 8.24 ) 8.4 • HMM PART-OF-SPEECH TAGGING 15 tagging sentence Eq . 8.24 , three tags context fall off edge sentence , hence match regular words . tags , t − 1 , t0 , tn + 1 , set single special ‘ sentence boundary ’ tag added tagset , assumes sentences boundaries already marked . problem trigram taggers instantiated Eq . 8.24 data sparsity . particular sequence tags ti − 2 , ti − 1 , ti occurs test set simply never occurred training set . means compute tag trigram probability just maximum likelihood estimate counts , following Eq . 8.25 : P ( ti | ti − 1 , ti − 2 ) = C ( ti − 2 , ti − 1 , ti ) C ( ti − 2 , ti − 1 ) ( 8.25 ) Just saw language modeling , many counts zero training set , incorrectly predict tag sequence never occur ! need way estimate P ( ti | ti − 1 , ti − 2 ) even sequence ti − 2 , ti − 1 , ti never occurs training data . standard approach solving problem same interpolation idea saw language modeling : estimate probability combining robust , weaker estimators . example , never seen tag sequence PRP VB , compute P ( | PRP , VB ) frequency , still rely bigram probability P ( | VB ) , even unigram probability P ( ) . maximum likelihood estimation probabilities computed corpus following counts : Trigrams P̂ ( ti | ti − 1 , ti − 2 ) = C ( ti − 2 , ti − 1 , ti ) C ( ti − 2 , ti − 1 ) ( 8.26 ) Bigrams P̂ ( ti | ti − 1 ) = C ( ti − 1 , ti ) C ( ti − 1 ) ( 8.27 ) Unigrams P̂ ( ti ) = C ( ti ) N ( 8.28 ) standard way combine three estimators estimate trigram probabil - ity P ( ti | ti − 1 , ti − 2 ) via linear interpolation . estimate probability P ( ti | ti − 1ti − 2 ) weighted sum unigram , bigram , trigram probabilities : P ( ti | ti − 1ti − 2 ) = λ3P̂ ( ti | ti − 1ti − 2 ) + λ2P̂ ( ti | ti − 1 ) + λ1P̂ ( ti ) ( 8.29 ) require λ1 + λ2 + λ3 = 1 , ensuring resulting P probability distri - bution . λ s set deleted interpolation ( Jelinek Mercer , 1980 ) : wedeletedinterpolation successively delete trigram training corpus choose λ s maximize likelihood rest corpus . deletion helps set λ s way generalize unseen data overfit . Figure 8.10 gives deleted interpolation algorithm tag trigrams . 8.4.8 Beam Search number states grows large , vanilla Viterbi algorithm slow . complexity algorithm O ( N2T ) ; N ( number states ) large trigram taggers , consider every previous pair 45 tags , re - sulting 453 = 91,125 computations per column . N even larger applications Viterbi , example decoding neural networks , future chapters . 16 CHAPTER 8 • PART-OF-SPEECH TAGGING function DELETED-INTERPOLATION ( corpus ) returns λ1 , λ2 , λ3 λ1 , λ2 , λ3 ← 0 foreach trigram t1 , t2 , t3 C ( t1 , t2 , t3 ) > 0 depending maximum following three values case C ( t1 , t2 , t3 ) − 1C ( t1 , t2 ) − 1 : increment λ3 C ( t1 , t2 , t3 ) case C ( t2 , t3 ) − 1C ( t2 ) − 1 : increment λ2 C ( t1 , t2 , t3 ) case C ( t3 ) − 1N − 1 : increment λ1 C ( t1 , t2 , t3 ) end end normalize λ1 , λ2 , λ3 return λ1 , λ2 , λ3 Figure 8.10 deleted interpolation algorithm setting weights combining uni - gram , bigram , trigram tag probabilities . denominator 0 case , define result case 0 . N number tokens corpus . Brants ( 2000 ) . common solution complexity problem beam searchbeam search decoding . beam search , keeping entire column states time point t , just keep best few hypothesis point . time t requires computing Viterbi score N cells , sorting scores , keeping best-scoring states . rest pruned continued forward time t + 1 . way implement beam search keep fixed number states N current states . beam width β fixed number states . Alternativelybeam width β modeled fixed percentage N states , probability threshold . Figure 8.11 shows search lattice beam width 2 states . JJ NNP NNP NNP MD MD MD MD VB VB JJ JJ JJ NN NN RB RBRBRB DT DT DT DT NNP Janet back bill NN VB MD NN VB JJ RB NNP DT NN VB Figure 8.11 beam search version Fig . 8.6 , showing beam width 2 . time t , ( non-zero ) states computed , sorted best 2 states propagated forward rest pruned , shown orange . 8.5 • MAXIMUM ENTROPY MARKOV MODELS 17 8.4.9 Unknown Words words people never — know Ishikawa Takuboku 1885 – 1912 achieve high accuracy part-of-speech taggers , important good model dealing unknown words . Proper names acronyms areunknownwords created often , even new common nouns verbs enter language surprising rate . useful feature distinguishing parts speech word shape : words starting capital letters likely proper nouns ( NNP ) . strongest source information guessing part-of-speech un - known words morphology . Words end - s likely plural nouns ( NNS ) , words ending - ed tend past participles ( VBN ) , words ending - able adjectives ( JJ ) , . store final letter sequence ( sim - plicity referred word suffixes ) up 10 letters statistics tag associated training . thus computing suffix length probability tag ti suffix letters ( Samuelsson 1993 , Brants 2000 ) : P ( ti | ln − + 1 . . . ln ) ( 8.30 ) Back-off smooth probabilities successively shorter suffixes . unknown words unlikely closed-class words like prepositions , suffix probabilities computed words whose training set frequency ≤ 10 , open-class words . Separate suffix tries kept capitalized uncapitalized words . Finally , Eq . 8.30 gives posterior estimate p ( ti | wi ) , compute likelihood p ( wi | ti ) HMMs require Bayesian inversion ( i.e . , Bayes ’ rule computation two priors P ( ti ) P ( ti | ln − + 1 . . . ln ) ) . addition capitalization information unknown words , Brants ( 2000 ) capitalization known words adding capitalization feature tag . Thus , computing P ( ti | ti − 1 , ti − 2 ) Eq . 8.26 , algorithm com - putes probability P ( ti , ci | ti − 1 , ci − 1 , ti − 2 , ci − 2 ) . equivalent cap - italized uncapitalized version tag , doubling size tagset . Combining features , trigram HMM like Brants ( 2000 ) tagging accuracy 96.7 % Penn Treebank , perhaps just slightly below performance best MEMM neural taggers . 8.5 Maximum Entropy Markov Models HMM achieve high accuracy , saw requires number architectural innovations deal unknown words , backoff , suffixes , . easier add arbitrary features directly model clean way , that’s hard generative models like HMMs . Luckily , already seen model : logistic regression model Chapter 5 ! logistic regression sequence model ; assigns class single observation . , turn logistic regression discriminative sequence model simply running successive words , class assigned prior word 18 CHAPTER 8 • PART-OF-SPEECH TAGGING feature classification next word . apply logistic regression way , called maximum entropy Markov model MEMM . 5MEMM Let sequence words W = wn1 sequence tags T = t n 1 . HMM compute best tag sequence maximizes P ( T | W ) rely Bayes ’ rule likelihood P ( W | T ) : T̂ = argmax T P ( T | W ) = argmax T P ( W | T ) P ( T ) = argmax T ∏ P ( wordi | tagi ) ∏ P ( tagi | tagi − 1 ) ( 8.31 ) MEMM , contrast , compute posterior P ( T | W ) directly , training discriminate among possible tag sequences : T̂ = argmax T P ( T | W ) = argmax T ∏ P ( ti | wi , ti − 1 ) ( 8.32 ) Consider tagging just word . multinomial logistic regression classifier compute single probability P ( ti | wi , ti − 1 ) different way HMM . Fig . 8.12 shows intuition difference via direction arrows ; HMMs compute likelihood ( observation word conditioned tags ) MEMMs compute posterior ( tags conditioned observation words ) . MD VB DT NN Janet back bill NNP MD VB DT NN Janet back bill NNP Figure 8.12 schematic view HMM ( top ) MEMM ( bottom ) representation probability computation correct sequence tags back sentence . HMM computes likelihood observation hidden state , MEMM computes posterior state , conditioned previous state current observation . 8.5.1 Features MEMM course build MEMMs condition just wi ti − 1 . reason discriminative sequence model easier incorporate lot fea - tures . 6 Figure 8.13 shows graphical intuition additional features . 5 ‘ Maximum entropy model ’ outdated name logistic regression ; history section . 6 HMMs computation based two probabilities P ( tag | tag ) P ( word | tag ) , include source knowledge tagging process , find way encode knowledge two probabilities . time add feature lot complicated conditioning gets harder harder features . 8.5 • MAXIMUM ENTROPY MARKOV MODELS 19 MD VB Janet back bill NNP < s > wi wi + 1wi-1 ti-1ti-2 wi-2 Figure 8.13 MEMM part-of-speech tagging showing ability condition features . basic MEMM part-of-speech tagger conditions observation word - self , neighboring words , previous tags , various combinations , feature templates like following : templates 〈 ti , wi − 2 〉 , 〈 ti , wi − 1 〉 , 〈 ti , wi 〉 , 〈 ti , wi + 1 〉 , 〈 ti , wi + 2 〉 〈 ti , ti − 1 〉 , 〈 ti , ti − 2 , ti − 1 〉 , 〈 ti , ti − 1 , wi 〉 , 〈 ti , wi − 1 , wi 〉 〈 ti , wi , wi + 1 〉 , ( 8.33 ) Recall Chapter 5 feature templates automatically populate set features every instance training test set . Thus example Janet / NNP / MD back / VB / DT bill / NN , wi word back , gen - erate following features : ti = VB wi − 2 = Janet ti = VB wi − 1 = ti = VB wi = back ti = VB wi + 1 = ti = VB wi + 2 = bill ti = VB ti − 1 = MD ti = VB ti − 1 = MD ti − 2 = NNP ti = VB wi = back wi + 1 = necessary features deal unknown words , expressing properties word’s spelling shape : wi contains particular prefix ( prefixes length ≤ 4 ) wi contains particular suffix ( suffixes length ≤ 4 ) wi contains number wi contains upper-case letter wi contains hyphen wi upper case wi’s word shape wi’s short word shape wi upper case digit dash ( like CFC-12 ) wi upper case followed 3 words Co . , Inc . , etc . Word shape features represent abstract letter pattern wordword shape mapping lower-case letters ‘ x ’ , upper-case ‘ X ’ , numbers ’ d ’ , retaining punctuation . Thus example I.M.F map X.X.X . DC10-30 map XXdd-dd . second class shorter word shape features . features consecutive character types removed , DC10-30 mapped Xd-d I.M.F still map X.X.X . example word well-dressed generate following non-zero valued feature values : 20 CHAPTER 8 • PART-OF-SPEECH TAGGING prefix ( wi ) = w prefix ( wi ) = prefix ( wi ) = wel prefix ( wi ) = well suffix ( wi ) = ssed suffix ( wi ) = sed suffix ( wi ) = ed suffix ( wi ) = d has-hyphen ( wi ) word-shape ( wi ) = xxxx-xxxxxxx short-word-shape ( wi ) = x-x Features known words , like templates Eq . 8.33 , computed every word seen training set . unknown word features computed words training , training words whose frequency below threshold . result known-word templates word-signature features large set features . Generally feature cutoff features thrown count < 5 training set . 8.5.2 Decoding Training MEMMs likely sequence tags computed combining features input word wi , neighbors l words wi + li − l , previous k tags t − 1 − k follows ( θ refer feature weights w avoid confusion w meaning words ) : T̂ = argmax T P ( T | W ) = argmax T ∏ P ( ti | wi + li − l , t − 1 − k ) = argmax T ∏ exp   ∑ j θ j f j ( ti , wi + li − l , t − 1 − k )   ∑ t ′ ∈ tagset exp   ∑ j θ j f j ( t ′ , wi + li − l , t − 1 − k )   ( 8.34 ) decode find optimal tag sequence T̂ ? simplest way turn logistic regression sequence model build local classifier classifies word left right , making hard classification first word sentence , hard decision second word , . called greedy decoding algorithm , greedily choose best tag word , greedy shown Fig . 8.14 . function GREEDY SEQUENCE DECODING ( words W , model P ) returns tag sequence T = 1 length ( W ) t̂i = argmax t ′ ∈ T P ( t ′ | wi + li − l , t − 1 − k ) Figure 8.14 greedy decoding simply run classifier token , left right , time making hard decision best tag . 8.6 • BIDIRECTIONALITY 21 problem greedy algorithm making hard decision word moving next word , classifier evidence future decisions . Although greedy algorithm fast , occasionally sufficient accuracy useful , general hard decision causes great drop performance , . decode MEMM Viterbi algorithm just HMM , Viterbi finding sequence part-of-speech tags optimal whole sentence . example , assume MEMM conditioning previous tag ti − 1 observed word wi . Concretely , involves filling N × T array appropriate values P ( ti | ti − 1 , wi ) , maintaining backpointers proceed . HMM Viterbi , table filled , simply follow pointers back maximum value final column retrieve desired set labels . requisite changes HMM-style application Viterbi fill cell . Recall Eq . 8.20 recursive step Viterbi equation computes Viterbi value time t state j vt ( j ) = N max = 1 vt − 1 ( ) ai j b j ( ot ) ; 1 ≤ j ≤ N , 1 < t ≤ T ( 8.35 ) HMM implementation vt ( j ) = N max = 1 vt − 1 ( ) P ( s j | si ) P ( ot | s j ) 1 ≤ j ≤ N , 1 < t ≤ T ( 8.36 ) MEMM requires slight change latter formula , replacing b prior likelihood probabilities direct posterior : vt ( j ) = N max = 1 vt − 1 ( ) P ( s j | si , ot ) 1 ≤ j ≤ N , 1 < t ≤ T ( 8.37 ) Learning MEMMs relies same supervised learning algorithms presented logistic regression . sequence observations , feature functions , cor - responding hidden states , gradient descent train weights maximize log-likelihood training corpus . 8.6 Bidirectionality problem MEMM HMM models presented exclusively run left-to-right . Viterbi algorithm still allows present deci - sions influenced indirectly future decisions , help even decision word wi directly information future tags ti + 1 ti + 2 . Adding bidirectionality another useful advantage . MEMMs theoret - ical weakness , referred alternatively label bias observation bias prob-label bias observation bias lem ( Lafferty et al . 2001 , Toutanova et al . 2003 ) . names situations source information ignored explained away another source . Consider example Toutanova et al . ( 2003 ) , sequence / NN / fight / VB . tag often preceded NN rarely modals ( MD ) , tendency help predict correct NN tag . previ - ous transition P ( twill | 〈 s 〉 ) prefers modal , P ( | , twill ) close 1 regardless twill model make transition probability incorrectly chooses MD . strong information tag ex - plained away presence model learn importance 22 CHAPTER 8 • PART-OF-SPEECH TAGGING previous NN tag predicting . Bidirectionality helps model making link available tagging NN . way implement bidirectionality switch powerful model called conditional random field CRF . CRF undirected graphicalCRF model , means computing probability tag time step . , time step CRF computes log-linear functions clique , set relevant features . Unlike MEMM , might include output features words future time steps . probability best sequence similarly computed Viterbi algorithm . CRF normalizes probabilities tag sequences , rather tags individual time t , training requires computing sum possible labelings , makes CRF training quite slow . Simpler methods ; Stanford tagger bidirectionalStanford tagger version MEMM called cyclic dependency network ( Toutanova et al . , 2003 ) . Alternatively , sequence model turned bidirectional model multiple passes . example , first pass part-of-speech features already-disambiguated words left . second pass , tags words , including right , . Alternately , tagger run twice , once left-to-right once right-to-left . greedy decoding , word classifier chooses highest-scoring tags assigned left-to-right right-to-left classifier . Viterbi decoding , classifier chooses higher scoring two sequences ( left-to-right right-to-left ) . bidirectional models lead directly bi-LSTM models introduce Chapter 9 standard neural sequence model . 8.7 Part-of-Speech Tagging Morphological Rich Lan - guages Augmentations tagging algorithms become necessary dealing lan - guages rich morphology like Czech , Hungarian Turkish . productive word-formation processes result large vocabulary languages : 250,000 word token corpus Hungarian twice many word types similarly sized corpus English ( Oravecz Dienes , 2002 ) , 10 million word token corpus Turkish contains four times many word types similarly sized English corpus ( Hakkani-Tür et al . , 2002 ) . Large vocabular - ies mean many unknown words , unknown words cause significant per - formance degradations wide variety languages ( including Czech , Slovene , Estonian , Romanian ) ( Hajič , 2000 ) . Highly inflectional languages information English coded word morphology , like case ( nominative , accusative , genitive ) gender ( masculine , feminine ) . information important tasks like pars - ing coreference resolution , part-of-speech taggers morphologically rich lan - guages need label words case gender information . Tagsets morpho - logically rich languages sequences morphological tags rather single primitive tag . Here’s Turkish example , word izin three pos - sible morphological / part-of-speech tags meanings ( Hakkani-Tür et al . , 2002 ) : 1 . Yerdeki izin temizlenmesi gerek . iz + Noun + A3sg + Pnon + Gen trace floor cleaned . 2 . Üzerinde parmak izin kalmiş iz + Noun + A3sg + P2sg + Nom 8.8 • SUMMARY 23 finger print left ( ) . 3 . Içeri girmek için izin alman gerekiyor . izin + Noun + A3sg + Pnon + Nom need permission enter . morphological parse sequence like Noun + A3sg + Pnon + Gen part - of-speech tag greatly increases number parts speech , tagsets 4 10 times larger 50 – 100 tags seen English . large tagsets , word needs morphologically analyzed generate list possible morphological tag sequences ( part-of-speech tags ) word . role tagger disambiguate among tags . method helps unknown words morphological parsers accept unknown stems still segment affixes properly . non-word-space languages like Chinese , word segmentation ( Chapter 2 ) applied tagging jointly . Although Chinese words aver - age short ( around 2.4 characters per unknown word compared 7.7 En - glish ) problem unknown words still large . English unknown words tend proper nouns Chinese majority unknown words common nouns verbs extensive compounding . Tagging models Chinese similar unknown word features English , including character prefix suf - fix features , well novel features like radicals character word . ( Tseng et al . , 2005 ) . standard multilingual tagging Universal POS tag set Universal Dependencies project , contains 16 tags plus wide variety features added create large tagset language ( Nivre et al . , 2016 ) . 8.8 Summary chapter introduced parts speech part-of-speech tagging : • Languages generally small set closed class words highly frequent , ambiguous , act function words , open-class words like nouns , verbs , adjectives . Various part-of-speech tagsets exist , 40 200 tags . • Part-of-speech tagging process assigning part-of-speech label sequence words . • Two common approaches sequence modeling generative approach , HMM tagging , discriminative approach , MEMM tagging . third , discriminative neural approach Chapter 9 . • probabilities HMM taggers estimated maximum likelihood es - timation tag-labeled training corpora . Viterbi algorithm decoding , finding likely tag sequence • Beam search variant Viterbi decoding maintains fraction high scoring states rather states decoding . • Maximum entropy Markov model MEMM taggers train logistic regres - sion models pick best tag observation word context previous tags , Viterbi choose best sequence tags . • Modern taggers generally run bidirectionally . 24 CHAPTER 8 • PART-OF-SPEECH TAGGING Bibliographical Historical Notes probably earliest part-of-speech tagger part parser Zellig Harris’s Transformations Discourse Analysis Project ( TDAP ) , implemented - tween June 1958 July 1959 University Pennsylvania ( Harris , 1962 ) , although earlier systems part-of-speech dictionaries . TDAP 14 hand - written rules part-of-speech disambiguation ; part-of-speech tag se - quences relative frequency tags word prefigures modern algo - rithms . parser implemented essentially cascade finite-state trans - ducers ; Joshi Hopely ( 1999 ) Karttunen ( 1999 ) reimplementation . Computational Grammar Coder ( CGC ) Klein Simmons ( 1963 ) three components : lexicon , morphological analyzer , context disambigua - tor . small 1500-word lexicon listed function words irregular words . morphological analyzer inflectional derivational suffixes - sign part-of-speech classes . run words produce candidate parts speech disambiguated set 500 context rules relying surrounding islands unambiguous words . example , rule ARTICLE VERB , allowable sequences ADJ-NOUN , NOUN - ADVERB , NOUN-NOUN . TAGGIT tagger ( Greene Rubin , 1971 ) same architecture Klein Simmons ( 1963 ) , bigger dictionary tags ( 87 ) . TAGGIT applied Brown corpus , according Francis Kučera ( 1982 , p . 9 ) , accurately tagged 77 % corpus ; remainder Brown corpus tagged hand . early algorithms based two-stage architecture dictionary first assign word set potential parts speech , lists handwritten disambiguation rules winnowed set down single part speech per word . Soon afterwards probabilistic architectures began developed . Probabili - ties tagging Stolz et al . ( 1965 ) complete probabilistic tagger Viterbi decoding sketched Bahl Mercer ( 1976 ) . Lancaster - Oslo / Bergen ( LOB ) corpus , British English equivalent Brown corpus , tagged early 1980 ’ s CLAWS tagger ( Marshall 1983 ; Marshall 1987 ; Garside 1987 ) , probabilistic algorithm approximated simplified HMM tag - ger . algorithm tag bigram probabilities , storing word likelihood tag , algorithm marked tags rare ( P ( tag | word ) < . 01 ) infrequent ( P ( tag | word ) < . 10 ) normally frequent ( P ( tag | word ) > . 10 ) . DeRose ( 1988 ) developed quasi-HMM algorithm , including dy - namic programming , although computing P ( t | w ) P ( w ) P ( w | t ) P ( w ) . same year , probabilistic PARTS tagger Church ( 1988 ) , ( 1989 ) probably first implemented HMM tagger , described correctly Church ( 1989 ) , although Church ( 1988 ) described computation incorrectly P ( t | w ) P ( w ) P ( w | t ) P ( w ) . Church ( p.c . ) explained simplified pedagogical pur - poses probability P ( t | w ) made idea seem understandable “ storing lexicon almost standard form ” . Later taggers explicitly introduced hidden Markov model ( Ku - piec 1992 ; Weischedel et al . 1993 ; Schütze Singer 1994 ) . Merialdo ( 1994 ) showed fully unsupervised EM work well tagging task reliance hand-labeled data important . Charniak et al . ( 1993 ) showed - portance frequent tag baseline ; 92.3 % number give Abney et al . ( 1999 ) . Brants ( 2000 ) many implementation details HMM tagger whose performance still roughly close state art taggers . EXERCISES 25 Ratnaparkhi ( 1996 ) introduced MEMM tagger , called MXPOST , modern formulation based work . idea letter suffixes unknown words quite old ; early Klein Simmons ( 1963 ) system checked final letter suffixes lengths 1-5 . probabilistic formulation described HMMs comes Samuelsson ( 1993 ) . unknown word features described page 19 come mainly ( Ratnaparkhi , 1996 ) , augmentations Toutanova et al . ( 2003 ) Manning ( 2011 ) . State art taggers neural algorithms like sequence models Chap - ter 9 ( bidirectional ) log-linear models Toutanova et al . ( 2003 ) . HMM ( Brants 2000 ; Thede Harper 1999 ) MEMM tagger accuracies likely just tad lower . alternative modern formalism , English Constraint Grammar systems ( Karls - son et al . 1995 ; Voutilainen 1995 ; Voutilainen 1999 ) , two-stage formalism like early taggers 1950s 1960s . morphological analyzer tens thousands English word stem entries returns parts speech word , large feature-based tagset . word occurred tagged op - tions 〈 V PCP2 SV 〉 〈 V PAST VFIN SV 〉 , meaning participle ( PCP2 ) intransitive ( SV ) verb , past ( PAST ) finite ( VFIN ) form intransitive ( SV ) verb . set 3,744 constraints applied input sentence rule parts speech inconsistent context . example here’s rule ambiguous word eliminates tags except ADV ( adverbial intensifier ) sense ( sense sentence odd ) : ADVERBIAL-THAT RULE input : “ ” ( + 1 / ADV / QUANT ) ; / * next word adj , adverb , quantifier * / ( + 2 SENT-LIM ) ; / * following sentence boundary , * / ( - 1 SVOC / ) ; / * previous word verb like * / / * ‘ consider ’ allows adjs object complements * / eliminate non-ADV tags else eliminate ADV tag Manning ( 2011 ) investigates remaining 2.7 % errors high-performing tagger , bidirectional MEMM-style model described ( Toutanova et al . , 2003 ) . suggests third half remaining errors due errors inconsistencies training data , third might solvable richer linguistic models , remainder task underspecified unclear . Supervised tagging relies heavily in-domain training data hand-labeled experts . Ways relax assumption include unsupervised algorithms cluster - ing words part-of-speech-like classes , summarized Christodoulopoulos et al . ( 2010 ) , ways combine labeled unlabeled data , example co-training ( Clark et al . 2003 ; Søgaard 2010 ) . Householder ( 1995 ) historical notes parts speech , Sampson ( 1987 ) Garside et al . ( 1997 ) provenance Brown tagsets . Exercises 8.1 Find tagging error following sentences tagged Penn Treebank tagset : 1 . / PRP need / VBP / DT flight / NN / Atlanta / NN 2 . / VBZ / DT flight / NN serve / VB dinner / NNS 3 . / PRP / VB / DT friend / NN living / VBG / Denver / NNP 4 . / VBP / PRP list / VB / DT nonstop / JJ afternoon / NN flights / NNS 26 CHAPTER 8 • PART-OF-SPEECH TAGGING 8.2 Penn Treebank tagset tag word following sentences Damon Runyon’s short stories . ignore punctuation . quite difficult ; best . 1 . nice night . 2 . crap game garage Fifty-second Street . . . 3 . . . . Nobody ever takes newspapers sells . . . 4 . tall , skinny guy long , sad , mean-looking kisser , mournful voice . 5 . . . . sitting Mindy’s restaurant putting gefillte fish , dish fond , . . . 6 . guy doll get taking peeks back forth , why indeed . 8.3 compare tags previous exercise two friend’s answers . words disagree ? Why ? 8.4 Implement “ likely tag ” baseline . Find POS-tagged training set , compute word tag maximizes p ( t | w ) . need implement simple tokenizer deal sentence boundaries . Start assuming unknown words NN compute error rate known unknown words . write least five rules better job tagging unknown words , show difference error rates . 8.5 Build bigram HMM tagger . need part-of-speech-tagged corpus . First split corpus training set test set . labeled training set , train transition observation probabilities HMM tagger di - rectly hand-tagged data . implement Viterbi algorithm label arbitrary test sentence . run algorithm test set . Report error rate compare performance frequent tag baseline . 8.6 error analysis tagger . Build confusion matrix investigate frequent errors . Propose features improving perfor - mance tagger errors . Exercises 27 Abney , S . P . , Schapire , R . E . , Singer , Y . ( 1999 ) . Boosting applied tagging PP attachment . EMNLP / VLC-99 , 38 – 45 . Bahl , L . R . Mercer , R . L . ( 1976 ) . Part speech - signment statistical decision algorithm . Proceed - ings IEEE International Symposium Information - ory , 88 – 89 . Brants , T . ( 2000 ) . TnT : statistical part-of-speech tagger . ANLP 2000 , 224 – 231 . Broschart , J . ( 1997 ) . Why Tongan differently . Lin - guistic Typology , 1 , 123 – 165 . Charniak , E . , Hendrickson , C . , Jacobson , N . , Perkowitz , M . ( 1993 ) . Equations part-of-speech tagging . AAAI - 93 , 784 – 789 . AAAI Press . Christodoulopoulos , C . , Goldwater , S . , Steedman , M . ( 2010 ) . Two decades unsupervised POS induction : far come ? . EMNLP-10 . Church , K . W . ( 1988 ) . stochastic parts program noun phrase parser unrestricted text . ANLP 1988 , 136 – 143 . Church , K . W . ( 1989 ) . stochastic parts program noun phrase parser unrestricted text . ICASSP-89 , 695 – 698 . Clark , S . , Curran , J . R . , Osborne , M . ( 2003 ) . Bootstrap - ping pos taggers unlabelled data . CoNLL-03 , 49 – 55 . DeRose , S . J . ( 1988 ) . Grammatical category disambiguation statistical optimization . Computational Linguistics , 14 , 31 – 39 . Evans , N . ( 2000 ) . Word classes world’s languages . Booij , G . , Lehmann , C . , Mugdan , J . ( Eds . ) , Mor - phology : Handbook Inflection Word Formation , 708 – 732 . Mouton . Francis , W . N . Kučera , H . ( 1982 ) . Frequency Analysis English Usage . Houghton Mifflin , Boston . Garside , R . ( 1987 ) . CLAWS word-tagging system . Garside , R . , Leech , G . , Sampson , G . ( Eds . ) , Com - putational Analysis English , 30 – 41 . Longman . Garside , R . , Leech , G . , McEnery , . ( 1997 ) . Corpus Annotation . Longman . Gil , D . ( 2000 ) . Syntactic categories , cross-linguistic varia - tion universal grammar . Vogel , P . M . Comrie , B . ( Eds . ) , Approaches Typology Word Classes , 173 – 216 . Mouton . Greene , B . B . Rubin , G . M . ( 1971 ) . Automatic grammat - ical tagging English . Department Linguistics , Brown University , Providence , Rhode Island . Hajič , J . ( 2000 ) . Morphological tagging : Data vs . dictionar - ies . NAACL 2000 . Seattle . Hakkani-Tür , D . , Oflazer , K . , Tür , G . ( 2002 ) . Statistical morphological disambiguation agglutinative languages . Journal Computers Humanities , 36 ( 4 ) , 381 – 410 . Harris , Z . S . ( 1962 ) . String Analysis Sentence Structure . Mouton , Hague . Householder , F . W . ( 1995 ) . Dionysius Thrax , technai , Sextus Empiricus . Koerner , E . F . K . Asher , R . E . ( Eds . ) , Concise History Language Sciences , 99 – 103 . Elsevier Science . Jelinek , F . Mercer , R . L . ( 1980 ) . Interpolated estimation Markov source parameters sparse data . Gelsema , E . S . Kanal , L . N . ( Eds . ) , Proceedings , Workshop Pattern Recognition Practice , 381 – 397 . North Holland . Joshi , . K . Hopely , P . ( 1999 ) . parser antiq - uity . Kornai , . ( Ed . ) , Extended Finite State Models Language , 6 – 15 . Cambridge University Press . Karlsson , F . , Voutilainen , . , Heikkilä , J . , Anttila , . ( Eds . ) . ( 1995 ) . Constraint Grammar : Language - Independent System Parsing Unrestricted Text . Mouton de Gruyter . Karttunen , L . ( 1999 ) . Comments Joshi . Kornai , . ( Ed . ) , Extended Finite State Models Language , 16 – 18 . Cambridge University Press . Klein , S . Simmons , R . F . ( 1963 ) . computational ap - proach grammatical coding English words . Journal Association Computing Machinery , 10 ( 3 ) , 334 – 347 . Kupiec , J . ( 1992 ) . Robust part-of-speech tagging hidden Markov model . Computer Speech Language , 6 , 225 – 242 . Lafferty , J . D . , McCallum , . , Pereira , F . C . N . ( 2001 ) . Conditional random fields : Probabilistic models seg - menting labeling sequence data . ICML 2001 . Manning , C . D . ( 2011 ) . Part-of-speech tagging 97 % 100 % : time linguistics ? . CICLing 2011 , 171 – 189 . Marcus , M . P . , Santorini , B . , Marcinkiewicz , M . . ( 1993 ) . Building large annotated corpus English : Penn treebank . Computational Linguistics , 19 ( 2 ) , 313 – 330 . Marshall , . ( 1983 ) . Choice grammatical word-class - GLobal syntactic analysis : Tagging words LOB corpus . Computers Humanities , 17 , 139 – 150 . Marshall , . ( 1987 ) . Tag selection probabilistic meth - ods . Garside , R . , Leech , G . , Sampson , G . ( Eds . ) , Computational Analysis English , 42 – 56 . Longman . Merialdo , B . ( 1994 ) . Tagging English text probabilis - tic model . Computational Linguistics , 20 ( 2 ) , 155 – 172 . Nivre , J . , de Marneffe , M . - C . , Ginter , F . , Goldberg , Y . , Hajič , J . , Manning , C . D . , McDonald , R . , Petrov , S . , Pyysalo , S . , Silveira , N . , Tsarfaty , R . , Zeman , D . ( 2016 ) . Universal Dependencies v1 : multilingual treebank collection . LREC . Oravecz , C . Dienes , P . ( 2002 ) . Efficient stochastic part - of-speech tagging Hungarian . LREC-02 , 710 – 717 . Ratnaparkhi , . ( 1996 ) . maximum entropy part-of-speech tagger . EMNLP 1996 , 133 – 142 . Sampson , G . ( 1987 ) . Alternative grammatical coding sys - tems . Garside , R . , Leech , G . , Sampson , G . ( Eds . ) , Computational Analysis English , 165 – 183 . Long - man . Samuelsson , C . ( 1993 ) . Morphological tagging based en - tirely Bayesian inference . 9th Nordic Conference Computational Linguistics NODALIDA-93 . Stockholm . Schütze , H . Singer , Y . ( 1994 ) . Part-of-speech tagging variable memory Markov model . ACL-94 , 181 – 187 . Søgaard , . ( 2010 ) . Simple semi-supervised training part - of-speech taggers . ACL 2010 , 205 – 208 . 28 Chapter 8 • Part-of-Speech Tagging Stolz , W . S . , Tannenbaum , P . H . , Carstensen , F . V . ( 1965 ) . stochastic approach grammatical coding English . CACM , 8 ( 6 ) , 399 – 405 . Thede , S . M . Harper , M . P . ( 1999 ) . second-order hid - den Markov model part-of-speech tagging . ACL-99 , 175 – 182 . Toutanova , K . , Klein , D . , Manning , C . D . , Singer , Y . ( 2003 ) . Feature-rich part-of-speech tagging cyclic dependency network . HLT-NAACL-03 . Tseng , H . , Jurafsky , D . , Manning , C . D . ( 2005 ) . Mor - phological features help POS tagging unknown words language varieties . Proceedings 4th SIGHAN Workshop Chinese Language Processing . Voutilainen , . ( 1995 ) . Morphological disambiguation . Karlsson , F . , Voutilainen , . , Heikkilä , J . , Anttila , . ( Eds . ) , Constraint Grammar : Language-Independent System Parsing Unrestricted Text , 165 – 284 . Mouton de Gruyter . Voutilainen , . ( 1999 ) . Handcrafted rules . van Halteren , H . ( Ed . ) , Syntactic Wordclass Tagging , 217 – 246 . Kluwer . Weischedel , R . , Meteer , M . , Schwartz , R . , Ramshaw , L . . , Palmucci , J . ( 1993 ) . Coping ambiguity un - known words probabilistic models . Computational Linguistics , 19 ( 2 ) , 359 – 382 .