Speech Language Processing . Daniel Jurafsky & James H . Martin . Copyright c © 2019 . rights reserved . Draft October 2 , 2019 . CHAPTER 20 Semantic Role Labeling Sometime 7th 4th centuries BCE , Indian grammarian Pān . ini1 wrote famous treatise Sanskrit grammar , . t . ādhyāyı̄ ( ‘ 8 books ’ ) , treatise called “ greatest monuments human intelligence ” ( Bloomfield , 1933 , 11 ) . work describes linguistics Sanskrit language form 3959 sutras , efficiently ( memorized ! ) expressing part formal rule system brilliantly prefigured modern mechanisms formal language theory ( Penn Kiparsky , 2012 ) . set rules , relevant discussion chapter , describes kārakas , semantic relationships verb noun arguments , roles like agent , instrument , destina - tion . Pān . ini’s work earliest know tried understand linguistic realization events participants . task understanding participants relate events — able answer ques - tion “ whom ” ( perhaps “ ” ) — central question natural language understanding . move forward 2.5 millennia present consider mundane goal understanding text purchase stock XYZ Corporation . purchasing event participants described wide variety surface forms . event described verb ( sold , bought ) noun ( purchase ) , XYZ Corp syntactic subject ( bought ) , indirect object ( sold ) , genitive noun compound relation ( noun purchase ) despite notionally same role : • XYZ corporation bought stock . • sold stock XYZ corporation . • stock bought XYZ corporation . • purchase stock XYZ corporation . . . • stock purchase XYZ corporation . . . chapter introduce level representation captures common - ality sentences : purchase event , participants XYZ Corp stock , XYZ Corp buyer . shallow semantic representations , semantic roles , express role arguments predicate take event , codified databases like PropBank FrameNet . introduce semantic role labeling , task assigning roles spans sentences , selec - tional restrictions , preferences predicates express arguments , fact theme eat generally something edible . 1 Figure shows birch bark manuscript Kashmir Rupavatra , grammatical textbook based Sanskrit grammar Panini . Image Wellcome Collection . 2 CHAPTER 20 • SEMANTIC ROLE LABELING 20.1 Semantic Roles Consider Chapter 16 represented meaning arguments sentences like : ( 20.1 ) Sasha broke window . ( 20.2 ) Pat opened door . neo-Davidsonian event representation two sentences ∃ e , x , y Breaking ( e ) ∧ Breaker ( e , Sasha ) ∧ BrokenT hing ( e , y ) ∧ Window ( y ) ∃ e , x , y Opening ( e ) ∧ Opener ( e , Pat ) ∧ OpenedT hing ( e , y ) ∧ Door ( y ) representation , roles subjects verbs break open Breaker Opener respectively . deep roles specific event ; Break-deep roles ing events Breakers , Opening events Openers , . going able answer questions , perform inferences , further kinds natural language understanding events , need know little semantics arguments . Breakers Openers something common . volitional actors , often animate , direct causal responsibility events . Thematic roles way capture semantic commonality Break-thematic roles ers Eaters . say subjects verbs agents . Thus , AGENTagents thematic role represents abstract idea volitional causation . Sim - ilarly , direct objects verbs , BrokenThing OpenedThing , prototypically inanimate objects affected way action . semantic role participants theme . theme Thematic Role Definition AGENT volitional causer event EXPERIENCER experiencer event FORCE non-volitional causer event THEME participant directly affected event RESULT end product event CONTENT proposition content propositional event INSTRUMENT instrument event BENEFICIARY beneficiary event SOURCE origin object transfer event GOAL destination object transfer event Figure 20.1 commonly thematic roles definitions . Although thematic roles oldest linguistic models , saw , modern formulation due Fillmore ( 1968 ) Gruber ( 1965 ) . Although universally agreed-upon set roles , Figs . 20.1 20.2 list - matic roles various computational papers , together rough definitions examples . thematic role sets dozen roles , sets smaller numbers roles even abstract meanings , sets large numbers roles specific situations . general term semantic roles sets roles , small large . semantic roles 20.2 • DIATHESIS ALTERNATIONS 3 Thematic Role Example AGENT waiter spilled soup . EXPERIENCER John headache . FORCE wind blows debris mall yards . THEME Benjamin Franklin broke ice . . . RESULT city built regulation-size baseball diamond . . . CONTENT Mona asked “ met Mary Ann supermarket ? ” INSTRUMENT poached catfish , stunning shocking device . . . BENEFICIARY Whenever Ann Callahan makes hotel reservations boss . . . SOURCE flew Boston . GOAL drove Portland . Figure 20.2 prototypical examples various thematic roles . 20.2 Diathesis Alternations main reason computational systems semantic roles act shallow meaning representation let make simple inferences possible pure surface string words , even parse tree . extend earlier examples , document Company acquired Company B , like know answers query Company B acquired ? despite fact two sentences different surface syntax . Similarly , shallow semantics might act useful intermediate language machine translation . Semantic roles thus help generalize different surface realizations pred - icate arguments . example , AGENT often realized subject sentence , cases THEME subject . Consider possible realizations thematic arguments verb break : ( 20.3 ) John AGENT broke window . THEME ( 20.4 ) John AGENT broke window THEME rock . INSTRUMENT ( 20.5 ) rock INSTRUMENT broke window . THEME ( 20.6 ) window THEME broke . ( 20.7 ) window THEME broken John . AGENT examples suggest break ( least ) possible arguments AGENT , THEME , INSTRUMENT . set thematic role arguments taken verb often called thematic grid , θ - grid , case frame . arethematic grid case frame ( among others ) following possibilities realization arguments break : AGENT / Subject , THEME / Object AGENT / Subject , THEME / Object , INSTRUMENT / PPwith INSTRUMENT / Subject , THEME / Object THEME / Subject turns many verbs allow thematic roles realized various syntactic positions . example , verbs like give realize THEME GOAL arguments two different ways : 4 CHAPTER 20 • SEMANTIC ROLE LABELING ( 20.8 ) . Doris AGENT gave book THEME Cary . GOAL b . Doris AGENT gave Cary GOAL book . THEME multiple argument structure realizations ( fact break take AGENT , INSTRUMENT , THEME subject , give realize THEME GOAL order ) called verb alternations diathesis alternations . alternationverbalternation showed give , dative alternation , seems occur particular se-dativealternation mantic classes verbs , including “ verbs future ” ( advance , allocate , offer , owe ) , “ send verbs ” ( forward , hand , mail ) , “ verbs throwing ” ( kick , pass , throw ) , . Levin ( 1993 ) lists 3100 English verbs semantic classes belong ( 47 high-level classes , divided 193 specific classes ) various alternations participate . lists verb classes incorporated online resource VerbNet ( Kipper et al . , 2000 ) , links verb WordNet FrameNet entries . 20.3 Semantic Roles : Problems Thematic Roles Representing meaning thematic role level seems like useful dealing complications like diathesis alternations . Yet proved quite diffi - cult come up standard set roles , equally difficult produce formal definition roles like AGENT , THEME , INSTRUMENT . example , researchers attempting define role sets often find need fragment role like AGENT THEME many specific roles . Levin Rappa - port Hovav ( 2005 ) summarize number cases , fact seem least two kinds INSTRUMENTS , intermediary instruments appear subjects enabling instruments : ( 20.9 ) . cook opened jar new gadget . b . new gadget opened jar . ( 20.10 ) . Shelly ate sliced banana fork . b . * fork ate sliced banana . addition fragmentation problem , cases like reason generalize semantic roles , finite discrete lists roles let . Finally , proved difficult formally define thematic roles . Consider AGENT role ; cases AGENTS animate , volitional , sentient , causal , individual noun phrase might exhibit properties . problems led alternative semantic role models eithersemantic role many fewer many roles . first options define generalized semantic roles abstract specific thematic roles . example , PROTO-AGENT PROTO-PATIENTproto-agent proto-patient generalized roles express roughly agent-like roughly patient-like mean - ings . roles defined , necessary sufficient conditions , rather set heuristic features accompany agent-like patient-like meanings . Thus , argument displays agent-like properties ( voli - tionally involved event , causing event change state another par - ticipant , sentient intentionally involved , moving ) greater likelihood 20.4 • PROPOSITION BANK 5 argument labeled PROTO-AGENT . patient-like proper - ties ( undergoing change state , causally affected another participant , stationary relative participants , etc . ) , greater likelihood argument labeled PROTO-PATIENT . second direction define semantic roles specific particular verb particular group semantically related verbs nouns . next two sections describe two commonly lexical resources make alternative versions semantic roles . PropBank proto - roles verb-specific semantic roles . FrameNet semantic roles spe - cific general semantic idea called frame . 20.4 Proposition Bank Proposition Bank , generally referred PropBank , resource sen-PropBank tences annotated semantic roles . English PropBank labels sentences Penn TreeBank ; Chinese PropBank labels sentences Penn Chinese TreeBank . difficulty defining universal set thematic roles , semantic roles PropBank defined respect individual verb sense . sense verb thus specific set roles , numbers rather names : Arg0 , Arg1 , Arg2 , . general , Arg0 represents PROTO-AGENT , Arg1 , PROTO-PATIENT . semantics roles less consistent , often defined specifically verb . Nonetheless generalization ; Arg2 often benefactive , instrument , attribute , end state , Arg3 start point , benefactive , instrument , attribute , Arg4 end point . slightly simplified PropBank entries sense verbs agree fall . PropBank entries called frame files ; note definitions frame file role ( “ entity agreeing ” , “ Extent , amount fallen ” ) informal glosses intended read humans , rather formal definitions . ( 20.11 ) agree . 01 Arg0 : Agreer Arg1 : Proposition Arg2 : entity agreeing Ex1 : [ Arg0 group ] agreed [ Arg1 make offer ] . Ex2 : [ ArgM-TMP Usually ] [ Arg0 John ] agrees [ Arg2 Mary ] [ Arg1 everything ] . ( 20.12 ) fall . 01 Arg1 : Logical subject , patient , thing falling Arg2 : Extent , amount fallen Arg3 : start point Arg4 : end point , end state arg1 Ex1 : [ Arg1 Sales ] fell [ Arg4 $ 25 million ] [ Arg3 $ 27 million ] . Ex2 : [ Arg1 average junk bond ] fell [ Arg2 4.2 % ] . Note Arg0 role fall , normal subject fall PROTO-PATIENT . 6 CHAPTER 20 • SEMANTIC ROLE LABELING PropBank semantic roles useful recovering shallow semantic - formation verbal arguments . Consider verb increase : ( 20.13 ) increase . 01 “ go up incrementally ” Arg0 : causer increase Arg1 : thing increasing Arg2 : amount increased , EXT , MNR Arg3 : start point Arg4 : end point PropBank semantic role labeling allow infer commonality event structures following three examples , , case Big Fruit Co . AGENT price bananas THEME , despite differing surface forms . ( 20.14 ) [ Arg0 Big Fruit Co . ] increased [ Arg1 price bananas ] . ( 20.15 ) [ Arg1 price bananas ] increased again [ Arg0 Big Fruit Co . ] ( 20.16 ) [ Arg1 price bananas ] increased [ Arg2 5 % ] . PropBank number non-numbered arguments called ArgMs , ( ArgM - TMP , ArgM-LOC , etc . ) represent modification adjunct meanings . relatively stable predicates , listed frame file . Data labeled modifiers helpful training systems detect temporal , location , directional modification predicates . ArgM’s include : TMP ? yesterday evening , LOC ? museum , San Francisco DIR / ? down , Bangkok MNR ? clearly , enthusiasm PRP / CAU why ? . . . , response ruling REC themselves , ADV miscellaneous PRD secondary predication . . . ate meat raw PropBank focuses verbs , related project , NomBank ( Meyers et al . , NomBank 2004 ) adds annotations noun predicates . example noun agreement Apple’s agreement IBM labeled Apple Arg0 IBM Arg2 . allows semantic role labelers assign labels arguments verbal nominal predicates . 20.5 FrameNet making inferences semantic commonalities different sen - tences increase useful , even useful make inferences many situations , different verbs , verbs nouns . example , like extract similarity among three sen - tences : ( 20.17 ) [ Arg1 price bananas ] increased [ Arg2 5 % ] . ( 20.18 ) [ Arg1 price bananas ] rose [ Arg2 5 % ] . ( 20.19 ) [ Arg2 5 % ] rise [ Arg1 price bananas ] . Note second example different verb rise , third example noun rather verb rise . like system recognize 20.5 • FRAMENET 7 price bananas went up , 5 % amount went up , matter 5 % appears object verb increased nominal modifier noun rise . FrameNet project another semantic-role-labeling project attemptsFrameNet address just kinds problems ( Baker et al . 1998 , Fillmore et al . 2003 , Fillmore Baker 2009 , Ruppenhofer et al . 2016 ) . Whereas roles PropBank project specific individual verb , roles FrameNet project specific frame . frame ? Consider following set words : reservation , flight , travel , buy , price , cost , fare , rates , meal , plane many individual lexical relations hyponymy , synonymy , many words list . resulting set relations , , add up complete account words related . clearly defined respect coherent chunk common-sense background information concerning air travel . call holistic background knowledge unites words frame ( Fill-frame , 1985 ) . idea groups words defined respect back - ground information widespread artificial intelligence cognitive science , besides frame related works like model ( Johnson-Laird , 1983 ) , ormodel even script ( Schank Abelson , 1977 ) . script frame FrameNet background knowledge structure defines set frame-specific semantic roles , called frame elements , includes set predi-frame elements cates roles . word evokes frame profiles aspect frame elements . FrameNet dataset includes set frames frame elements , lexical units associated frame , set labeled exam - ple sentences . example , change position scale frame defined follows : frame consists words indicate change Item’s posi - tion scale ( Attribute ) starting point ( Initial value ) end point ( Final value ) . semantic roles ( frame elements ) frame defined Fig . 20.3 . Note separated core roles , frame specific , andcore roles non-core roles , like Arg-M arguments PropBank , expressingnon-core roles general properties time , location , . example sentences : ( 20.20 ) [ ITEM Oil ] rose [ ATTRIBUTE price ] [ DIFFERENCE 2 % ] . ( 20.21 ) [ ITEM ] increased [ FINAL STATE 1 day month ] . ( 20.22 ) [ ITEM Microsoft shares ] fell [ FINAL VALUE 7 5/8 ] . ( 20.23 ) [ ITEM Colon cancer incidence ] fell [ DIFFERENCE 50 % ] [ GROUP among men ] . ( 20.24 ) steady increase [ INITIAL VALUE 9.5 ] [ FINAL VALUE 14.3 ] [ ITEM dividends ] ( 20.25 ) [ DIFFERENCE 5 % ] [ ITEM dividend ] increase . . . Note example sentences frame includes target words like rise , fall , increase . fact , complete frame consists following words : 8 CHAPTER 20 • SEMANTIC ROLE LABELING Core Roles ATTRIBUTE ATTRIBUTE scalar property ITEM possesses . DIFFERENCE distance ITEM changes position scale . FINAL STATE description presents ITEM’s state change ATTRIBUTE’s value independent predication . FINAL VALUE position scale ITEM ends up . INITIAL STATE description presents ITEM’s state change - TRIBUTE’s value independent predication . INITIAL VALUE initial position scale ITEM moves away . ITEM entity position scale . VALUE RANGE portion scale , typically identified end points , values ATTRIBUTE fluctuate . Non-Core Roles DURATION length time change takes place . SPEED rate change VALUE . GROUP GROUP ITEM changes value ATTRIBUTE specified way . Figure 20.3 frame elements change position scale frame FrameNet Labelers Guide ( Ruppenhofer et al . , 2016 ) . VERBS : dwindle move soar escalation shift advance edge mushroom swell explosion tumble climb explode plummet swing fall decline fall reach triple fluctuation ADVERBS : decrease fluctuate rise tumble gain increasingly diminish gain rocket growth dip grow shift NOUNS : hike double increase skyrocket decline increase drop jump slide decrease rise FrameNet codes relationships frames , allowing frames inherit , representing relations frames like causation ( gen - eralizations among frame elements different frames representing inher - itance well ) . Thus , Cause change position scale frame linked Change position scale frame cause relation , adds AGENT role causative examples following : ( 20.26 ) [ AGENT ] raised [ ITEM price soda ] [ DIFFERENCE 2 % ] . Together , two frames allow understanding system extract common event semantics verbal nominal causative non-causative usages . FrameNets developed many languages including Span - ish , German , Japanese , Portuguese , Italian , Chinese . 20.6 Semantic Role Labeling Semantic role labeling ( sometimes shortened SRL ) task automaticallysemantic rolelabeling finding semantic roles argument predicate sentence . Cur - rent approaches semantic role labeling based supervised machine learning , often FrameNet PropBank resources specify counts pred - icate , define set roles task , provide training test sets . 20.6 • SEMANTIC ROLE LABELING 9 Recall difference two models semantic roles FrameNet ( 20.27 ) employs many frame-specific frame elements roles , Prop - Bank ( 20.28 ) smaller number numbered argument labels inter - preted verb-specific labels , general ARGM labels . examples : ( 20.27 ) [ ] [ blame ] [ program ] [ unable identify ] COGNIZER TARGET EVALUEE REASON ( 20.28 ) [ San Francisco Examiner ] issued [ special edition ] [ yesterday ] ARG0 TARGET ARG1 ARGM-TMP 20.6.1 Feature-based Algorithm Semantic Role Labeling simplified feature-based semantic role labeling algorithm sketched Fig . 20.4 . Feature-based algorithms — earliest systems like ( Simmons , 1973 ) — begin parsing , broad-coverage parsers assign parse input string . Figure 20.5 shows parse ( 20.28 ) . parse traversed find words predicates . predicates , algorithm examines node parse tree supervised classification decide semantic role ( ) plays predicate . labeled training set PropBank FrameNet , feature vector extracted node , feature templates described next subsection . 1-of-N classifier trained predict semantic role constituent features , N number potential semantic roles plus extra NONE role non-role constituents . standard classification algorithms . Finally , test sentence labeled , classifier run relevant constituent . function SEMANTICROLELABEL ( words ) returns labeled tree parse ← PARSE ( words ) predicate parse node parse featurevector ← EXTRACTFEATURES ( node , predicate , parse ) CLASSIFYNODE ( node , featurevector , parse ) Figure 20.4 generic semantic-role-labeling algorithm . CLASSIFYNODE 1-of-N clas - sifier assigns semantic role ( NONE non-role constituents ) , trained labeled data FrameNet PropBank . training single-stage classifier Fig . 20.5 , node-level classi - fication task broken down multiple steps : 1 . Pruning : small number constituents sentence arguments predicate , many systems simple heuristics prune unlikely constituents . 2 . Identification : binary classification node argument la - beled NONE . 3 . Classification : 1-of-N classification constituents labeled arguments previous stage separation identification classification lead better fea - tures ( different features useful two tasks ) computational effi - ciency . 10 CHAPTER 20 • SEMANTIC ROLE LABELING S NP-SBJ = ARG0 VP DT NNP NNP NNP San Francisco Examiner VBD = TARGET NP = ARG1 PP-TMP = ARGM-TMP issued DT JJ NN NP special edition around NN NP-TMP noon yesterday Figure 20.5 Parse tree PropBank sentence , showing PropBank argument labels . dotted line shows path feature NP ↑ S ↓ VP ↓ VBD ARG0 , NP-SBJ constituent San Francisco Examiner . Global Optimization classification algorithm Fig . 20.5 classifies argument separately ( ‘ lo - cally ’ ) , making simplifying assumption argument predicate labeled independently . assumption false ; interactions argu - ments require ‘ global ’ assignment labels constituents . example , constituents FrameNet PropBank required non-overlapping . significantly , semantic roles constituents independent . example PropBank allow multiple identical arguments ; two constituents same verb labeled ARG0 . Role labeling systems thus often add fourth step deal global consistency labels sentence . example , local classifiers return list possible labels associated probabilities constituent , second-pass Viterbi decoding re-ranking approach choose best consensus label . Integer linear programming ( ILP ) another common way choose solution conforms best multiple constraints . Features Semantic Role Labeling systems generalization core set features introduced Gildea Jurafsky ( 2000 ) . Common basic features templates ( demonstrated NP-SBJ constituent San Francisco Examiner Fig . 20.5 ) include : • governing predicate , case verb issued . predicate cru - cial feature labels defined respect particular predicate . • phrase type constituent , case , NP ( NP-SBJ ) . se - mantic roles tend appear NPs , others S PP , . • headword constituent , Examiner . headword constituent computed standard head rules , Chapter 12 Fig . ? ? . Certain headwords ( e.g . , pronouns ) place strong constraints possible semantic roles likely fill . • headword part speech constituent , NNP . • path parse tree constituent predicate . path marked dotted line Fig . 20.5 . Following Gildea Jurafsky ( 2000 ) , simple linear representation path , NP ↑ S ↓ VP ↓ VBD . ↑ ↓ represent upward downward movement tree , respectively . 20.6 • SEMANTIC ROLE LABELING 11 path useful compact representation many kinds grammatical function relationships constituent predicate . • voice clause constituent appears , case , active ( contrasted passive ) . Passive sentences tend strongly different linkings semantic roles surface form active ones . • binary linear position constituent respect predicate , . • subcategorization predicate , set expected arguments appear verb phrase . extract information phrase - structure rule expands immediate parent predicate ; VP → VBD NP PP predicate Fig . 20.5 . • named entity type constituent . • first words last word constituent . following feature vector thus represents first NP example ( recall observations value NONE rather , example , ARG0 , constituents parse tree bear semantic role ) : ARG0 : [ issued , NP , Examiner , NNP , NP ↑ S ↓ VP ↓ VBD , active , , VP → NP PP , ORG , , Examiner ] features often addition , sets n-grams inside constituent , complex versions path features ( upward downward halves , particular nodes occur path ) . possible dependency parses constituency parses basis features , example dependency parse paths constituency paths . 20.6.2 Neural Algorithm Semantic Role Labeling standard neural algorithm semantic role labeling based bi-LSTM IOB tagger introduced Chapter 9 , seen applied part-of-speech tagging named entity tagging , among tasks . Recall IOB tagging , begin end tag possible role ( B-ARG0 , I-ARG0 ; B-ARG1 , I-ARG1 , ) , plus outside tag O . taggers , goal compute highest probability tag se - quence ŷ , input sequence words w : ŷ = argmax y ∈ T P ( y | w ) algorithms like et al . ( 2017 ) , input word mapped pre-trained em - beddings , associated embedding flag ( 0/1 ) variable indicating input word predicate . concatenated embeddings passed multiple layers bi-directional LSTM . State-of-the-art algorithms tend deeper POS NER tagging , 3 4 layers ( 6 8 total LSTMs ) . Highway layers connect layers well . Output last bi-LSTM turned IOB sequence POS NER tagging . Tags locally optimized taking bi-LSTM output , passing single layer softmax word creates proba - bility distribution SRL tags likely tag word xi chosen ti , computing word essentially : ŷi = argmax t ∈ tags P ( t | wi ) 12 CHAPTER 20 • SEMANTIC ROLE LABELING cats love hats Embeddings LSTM1 LSTM1 LSTM1 LSTM1 LSTM2 LSTM2 LSTM2 LSTM2 Concatenation Right-to-left LSTM Left-to-right LSTM Softmax P ( B-ARG0 ) P ( I-ARG0 ) P ( B-PRED ) P ( B-ARG1 ) 0 0 1 0word + is-predicate Figure 20.6 bi-LSTM approach semantic role labeling . actual networks deeper shown figure ; 3 4 bi-LSTM layers ( 6 8 total LSTMs ) common . input concatenation embedding input word embedding binary variable 1 predicate 0 words . et al . ( 2017 ) . , just feature-based SRL tagging , local approach decoding exploit global constraints tags ; tag I-ARG0 , example , follow another I-ARG0 B-ARG0 . saw POS NER tagging , many ways take advantage global constraints . CRF layer softmax layer top bi-LSTM output , Viterbi decoding algorithm decode CRF . even simpler Viterbi decoding algorithm perform equally well require adding CRF complexity training process start simple softmax . softmax output ( entire probability distribution tags ) word treated lattice Viterbi decoding lattice . hard IOB constraints act transition probabilities Viterbi decoding ( thus transition state I-ARG0 I-ARG1 probabil - ity 0 ) . Alternatively , training data learn bigram trigram tag transition probabilities HMM decoding . Fig . 20.6 shows sketch algorithm . 20.6.3 Evaluation Semantic Role Labeling standard evaluation semantic role labeling require argument label assigned exactly correct word sequence parse constituent , compute precision , recall , F-measure . Identification classification evaluated separately . Two common datasets evaluation CoNLL - 2005 ( Carreras Màrquez , 2005 ) CoNLL-2012 ( Pradhan et al . , 2013 ) . 20.7 Selectional Restrictions turn section another way represent facts relationship - tween predicates arguments . selectional restriction semantic type con-selectionalrestriction straint verb imposes kind concepts allowed fill argument roles . Consider two meanings associated following example : 20.7 • SELECTIONAL RESTRICTIONS 13 ( 20.29 ) eat someplace nearby . two possible parses semantic interpretations sentence . sensible interpretation , eat intransitive phrase someplace nearby adjunct gives location eating event . nonsensical speaker-as - Godzilla interpretation , eat transitive phrase someplace nearby direct object THEME eating , like NP Malaysian food following sentences : ( 20.30 ) eat Malaysian food . know someplace nearby direct object sentence ? useful cue semantic fact THEME EATING events tends something edible . restriction placed verb eat filler THEME argument selectional restriction . Selectional restrictions associated senses , entire lexemes . following examples lexeme serve : ( 20.31 ) restaurant serves green-lipped mussels . ( 20.32 ) airlines serve Denver ? Example ( 20.31 ) illustrates offering-food sense serve , ordinarily re - stricts THEME kind food Example ( 20.32 ) illustrates provides commercial service sense serve , constrains THEME type appropriate location . Selectional restrictions vary widely specificity . verb imagine , example , imposes strict requirements AGENT role ( restricting humans animate entities ) places few semantic requirements THEME role . verb like diagonalize , hand , places specific constraint filler THEME role : matrix , arguments adjectives odorless restricted concepts possess odor : ( 20.33 ) rehearsal , often ask musicians imagine tennis game . ( 20.34 ) Radon odorless gas detected human senses . ( 20.35 ) diagonalize matrix find eigenvalues . examples illustrate set concepts need represent selectional restrictions ( matrix , able possess odor , etc ) quite open ended . distinguishes selectional restrictions features representing lexical knowledge , like parts-of-speech , quite limited number . 20.7.1 Representing Selectional Restrictions way capture semantics selectional restrictions extend event representation Chapter 16 . Recall neo-Davidsonian representation event consists single variable stands event , predicate denoting kind event , variables relations event roles . Ignoring issue λ - structures thematic roles rather deep event roles , semantic contribution verb like eat might look like following : ∃ e , x , y Eating ( e ) ∧ Agent ( e , x ) ∧ T heme ( e , y ) representation , know y , filler THEME role , associated Eating event Theme relation . stipulate 14 CHAPTER 20 • SEMANTIC ROLE LABELING Sense 1 hamburger , beefburger - - ( fried cake minced beef served bun ) = > sandwich = > snack food = > dish = > nutriment , nourishment , nutrition . . . = > food , nutrient = > substance = > matter = > physical entity = > entity Figure 20.7 Evidence WordNet hamburgers edible . selectional restriction y something edible , simply add new term effect : ∃ e , x , y Eating ( e ) ∧ Agent ( e , x ) ∧ T heme ( e , y ) ∧ EdibleT hing ( y ) phrase like ate hamburger encountered , semantic analyzer form following kind representation : ∃ e , x , y Eating ( e ) ∧ Eater ( e , x ) ∧ T heme ( e , y ) ∧ EdibleT hing ( y ) ∧ Hamburger ( y ) representation perfectly reasonable membership y category Hamburger consistent membership category EdibleThing , assuming reasonable set facts knowledge base . Correspondingly , representation phrase ate takeoff ill-formed membership event-like category Takeoff inconsistent membership category EdibleThing . approach adequately captures semantics selectional restrictions , two problems direct . First , FOL perform simple task enforcing selectional restrictions overkill . , far simpler , formalisms job far less computational cost . second problem approach presupposes large , logical knowledge base facts concepts make up selectional restrictions . Unfortunately , although common-sense knowledge bases developed , none currently kind coverage necessary task . practical approach state selectional restrictions terms WordNet synsets rather logical concepts . predicate simply specifies WordNet synset selectional restriction arguments . meaning representa - tion well-formed role filler word hyponym ( subordinate ) synset . ate hamburger example , instance , set selectional restriction THEME role verb eat synset { food , nutrient } , glossed substance metabolized animal give energy build tissue . Luckily , chain hypernyms hamburger shown Fig . 20.7 reveals hamburgers indeed food . Again , filler role need match restriction synset exactly ; just needs synset superordinates . apply approach THEME roles verbs imagine , lift , di - agonalize , discussed earlier . Let restrict imagine’s THEME synset { entity } , lift’s THEME { physical entity } , diagonalize { matrix } . arrangement 20.7 • SELECTIONAL RESTRICTIONS 15 correctly permits imagine hamburger lift hamburger , correctly ruling diagonalize hamburger . 20.7.2 Selectional Preferences earliest implementations , selectional restrictions considered strict con - straints kind arguments predicate take ( Katz Fodor 1963 , Hirst 1987 ) . example , verb eat might require THEME argument [ + FOOD ] . Early word sense disambiguation systems idea rule senses violated selectional restrictions governing predicates . quickly , , became clear selectional restrictions better represented preferences rather strict constraints ( Wilks 1975b , Wilks 1975a ) . example , selectional restriction violations ( like inedible arguments eat ) often occur well-formed sentences , example negated ( 20.36 ) , selectional restrictions overstated ( 20.37 ) : ( 20.36 ) fell apart 1931 , perhaps people realized eat gold lunch hungry . ( 20.37 ) two championship trials , Mr . Kulkarni ate glass empty stomach , accompanied water tea . Modern systems selectional preferences specify relation - tween predicate possible arguments soft constraints kind . Selectional Association influential selectional association model Resnik ( 1993 ) . Resnik defines idea selectional preference strength general selectional preference strength amount information predicate tells semantic class argu - ments . example , verb eat tells lot semantic class direct objects , tend edible . verb , contrast , tells less direct objects . selectional preference strength defined differ - ence information two distributions : distribution expected semantic classes P ( c ) ( likely direct object fall class c ) dis - tribution expected semantic classes particular verb P ( c | v ) ( likely direct object specific verb v fall semantic class c ) . greater difference distributions , information verb giving possible objects . difference two distributions quantified relative entropy , Kullback-Leibler divergence ( Kullbackrelative entropy Leibler , 1951 ) . Kullback-Leibler KL divergence D ( P | | Q ) expresses theKL divergence difference two probability distributions P Q D ( P | | Q ) = ∑ x P ( x ) log P ( x ) Q ( x ) ( 20.38 ) selectional preference SR ( v ) KL divergence express - formation , bits , verb v expresses possible semantic class argu - ment . SR ( v ) = D ( P ( c | v ) | | P ( c ) ) = ∑ c P ( c | v ) log P ( c | v ) P ( c ) ( 20.39 ) 16 CHAPTER 20 • SEMANTIC ROLE LABELING Resnik defines selectional association particular class verb theselectionalassociation relative contribution class general selectional preference verb : AR ( v , c ) = 1 SR ( v ) P ( c | v ) log P ( c | v ) P ( c ) ( 20.40 ) selectional association thus probabilistic measure strength asso - ciation predicate class dominating argument predicate . Resnik estimates probabilities associations parsing corpus , count - ing times predicate occurs argument word , assuming word partial observation WordNet concepts containing word . following table Resnik ( 1996 ) shows sample high low selectional associations verbs WordNet semantic classes direct objects . Direct Object Direct Object Verb Semantic Class Assoc Semantic Class Assoc read WRITING 6.80 ACTIVITY - . 20 write WRITING 7.26 COMMERCE 0 ENTITY 5.79 METHOD - 0.01 Selectional Preference via Conditional Probability alternative selectional association verb WordNet class arguments conditional probability argument word predicate verb , directly modeling strength association verb ( predicate ) noun ( argument ) . conditional probability model computed parsing large cor - pus ( billions words ) , computing co-occurrence counts : often verb occurs noun relation . conditional probability argument noun verb particular relation P ( n | v , r ) selectional preference metric pair words ( Brockmann Lapata 2003 , Keller Lapata 2003 ) : P ( n | v , r ) = { C ( n , v , r ) C ( v , r ) C ( n , v , r ) > 0 0 otherwise inverse probability P ( v | n , r ) found better performance cases ( Brockmann Lapata , 2003 ) : P ( v | n , r ) = { C ( n , v , r ) C ( n , r ) C ( n , v , r ) > 0 0 otherwise even simpler approach simple log co-occurrence frequency predicate argument logcount ( v , n , r ) conditional probability ; seems better extracting preferences syntactic subjects rather objects ( Brockmann Lapata , 2003 ) . Evaluating Selectional Preferences way evaluate models selectional preferences pseudowords ( Galepseudowords et al . 1992 , Schütze 1992 ) . pseudoword artificial word created concate - nating test word context ( say banana ) confounder word ( say door ) 20.8 • PRIMITIVE DECOMPOSITION PREDICATES 17 create banana-door ) . task system identify two words original word . evaluate selectional preference model ( example relationship verb direct object ) take test corpus select verb tokens . verb token ( say drive ) select direct object ( e.g . , car ) , concatenated confounder word nearest neighbor , noun frequency closest original ( say house ) , make car / house ) . selectional preference model choose car house preferred objects drive , compute often model chooses correct original ob - ject ( e.g . , car ) ( Chambers Jurafsky , 2010 ) . Another evaluation metric get human preferences test set verb - argument pairs , rate degree plausibility . usually magnitude estimation , technique psychophysics , subjects rate plausibility argument proportional modulus item . selectional preference model evaluated correlation human prefer - ences ( Keller Lapata , 2003 ) . 20.8 Primitive Decomposition Predicates way thinking semantic roles discussed chapter help define roles arguments play decompositional way , based finite lists thematic roles ( agent , patient , instrument , proto-agent , proto - patient , etc . ) . idea decomposing meaning sets primitive semantics elements features , called primitive decomposition componential analysis , componentialanalysis taken even further , focused particularly predicates . Consider examples verb kill : ( 20.41 ) Jim killed philodendron . ( 20.42 ) Jim something cause philodendron become alive . truth-conditional ( ‘ propositional semantics ’ ) perspective two sentences same meaning . Assuming equivalence , repre - sent meaning kill : ( 20.43 ) KILL ( x , y ) ⇔ CAUSE ( x , BECOME ( ( ALIVE ( y ) ) ) ) thus semantic primitives like , cause , become , alive . Indeed , set potential semantic primitives account verbal alternations discussed Section 20.2 ( Lakoff 1965 , Dowty 1979 ) . Consider following examples . ( 20.44 ) John opened door . ⇒ CAUSE ( John , BECOME ( OPEN ( door ) ) ) ( 20.45 ) door opened . ⇒ BECOME ( OPEN ( door ) ) ( 20.46 ) door open . ⇒ OPEN ( door ) decompositional approach asserts single state-like predicate associ - ated open underlies examples . differences among meanings examples arises combination single predicate prim - itives CAUSE BECOME . approach primitive decomposition explain similarity - tween states actions causative non-causative predicates , still relies large number predicates like open . radical approaches choose 18 CHAPTER 20 • SEMANTIC ROLE LABELING break down predicates well . approach verbal predicate de - composition played role early natural language understanding systems conceptual dependency ( CD ) , set ten primitive predicates , shown Fig . 20.8 . conceptualdependency Primitive Definition ATRANS abstract transfer possession control entity another PTRANS physical transfer object location another MTRANS transfer mental concepts entities entity MBUILD creation new information entity PROPEL application physical force move object MOVE integral movement body part animal INGEST taking substance animal EXPEL expulsion something animal SPEAK action producing sound ATTEND action focusing sense organ Figure 20.8 set conceptual dependency primitives . Below example sentence CD representation . verb brought translated two primitives ATRANS PTRANS indicate waiter physically conveyed check Mary passed control . Note CD associates fixed set thematic roles primitive represent various participants action . ( 20.47 ) waiter brought Mary check . ∃ x , y Atrans ( x ) ∧ Actor ( x , Waiter ) ∧ Ob ject ( x , Check ) ∧ ( x , Mary ) ∧ Ptrans ( y ) ∧ Actor ( y , Waiter ) ∧ Ob ject ( y , Check ) ∧ ( y , Mary ) 20.9 Summary • Semantic roles abstract models role argument plays event described predicate . • Thematic roles model semantic roles based single finite list roles . semantic role models include per-verb semantic role lists proto-agent / proto-patient , implemented PropBank , per-frame role lists , implemented FrameNet . • Semantic role labeling task assigning semantic role labels constituents sentence . task generally treated supervised ma - chine learning task , models trained PropBank FrameNet . Algo - rithms generally start parsing sentence automatically tag parse tree node semantic role . Neural models map straight words end-to-end . • Semantic selectional restrictions allow words ( particularly predicates ) post constraints semantic properties argument words . Selectional BIBLIOGRAPHICAL HISTORICAL NOTES 19 preference models ( like selectional association simple conditional proba - bility ) allow weight probability assigned association predicate argument word class . Bibliographical Historical Notes Although idea semantic roles dates back Pān . ini , re-introduced modern linguistics Gruber ( 1965 ) , Fillmore ( 1966 ) Fillmore ( 1968 ) . Fillmore , interestingly , become interested argument structure studying Lucien Tesnière’s groundbreaking Éléments de Syntaxe Structurale ( Tesnière , 1959 ) term ‘ dependency ’ introduced foundations laid dependency grammar . Following Tesnière’s terminology , Fillmore first referred argument roles actants ( Fillmore , 1966 ) quickly switched term case , ( Fillmore ( 2003 ) ) proposed universal list semantic roles cases ( Agent , Patient , Instrument , etc . ) , taken arguments predicates . Verbs listed lexicon case frame , list obligatory ( optional ) case arguments . idea semantic roles provide intermediate level semantic representation help map syntactic parse structures deeper , fully-specified representations meaning quickly adopted natural language processing , systems extracting case frames created machine trans - lation ( Wilks , 1973 ) , question-answering ( Hendrix et al . , 1973 ) , spoken-language understanding ( Nash-Webber , 1975 ) , dialogue systems ( Bobrow et al . , 1977 ) . General-purpose semantic role labelers developed . earliest ones ( Sim - mons , 1973 ) first parsed sentence means ATN ( Augmented Transition Network ) parser . verb set rules specifying parse mapped semantic roles . rules mainly made reference grammatical functions ( subject , object , complement specific prepositions ) checked constituent internal features animacy head nouns . Later systems - signed roles pre-built parse trees , again dictionaries verb-specific case frames ( Levin 1977 , Marcus 1980 ) . 1977 case representation widely taught AI NLP courses , described standard natural language understanding first edition Winston’s ( 1977 ) textbook Artificial Intelligence . 1980s Fillmore proposed model frame semantics , later describing intuition follows : “ idea behind frame semantics speakers aware possi - bly quite complex situation types , packages connected expectations , go various names — frames , schemas , scenarios , scripts , cultural narratives , memes — words language understood frames presupposed background . ” ( Fillmore , 2012 , p . 712 ) word frame seemed air suite related notions proposed same time Minsky ( 1974 ) , Hymes ( 1974 ) , Goffman ( 1974 ) , well related notions names like scripts ( Schank Abelson , 1975 ) schemata ( Bobrow Norman , 1975 ) ( Tannen ( 1979 ) comparison ) . Fillmore influenced semantic field theorists visit Yale AI lab took notice lists slots fillers early information 20 CHAPTER 20 • SEMANTIC ROLE LABELING extraction systems like DeJong ( 1982 ) Schank Abelson ( 1977 ) . 1990s Fillmore drew insights begin FrameNet corpus annotation project . same time , Beth Levin drew early case frame dictionaries ( Levin , 1977 ) develop book summarized sets verb classes defined shared argument realizations ( Levin , 1993 ) . VerbNet project built work ( Kipper et al . , 2000 ) , leading soon afterwards PropBank semantic-role-labeled corpus created Martha Palmer colleagues ( Palmer et al . , 2005 ) . combination rich linguistic annotation corpus-based approach - stantiated FrameNet PropBank led revival automatic approaches semantic role labeling , first FrameNet ( Gildea Jurafsky , 2000 ) PropBank data ( Gildea Palmer , 2002 , inter alia ) . problem first addressed 1970s handwritten rules thus generally recast supervised machine learning enabled large consistent databases . Many popular features role labeling defined Gildea Jurafsky ( 2002 ) , Surdeanu et al . ( 2003 ) , Xue Palmer ( 2004 ) , Pradhan et al . ( 2005 ) , Che et al . ( 2009 ) , Zhao et al . ( 2009 ) . dependency rather constituency parses introduced CoNLL-2008 shared task ( Surdeanu et al . , 2008 ) . surveys Palmer et al . ( 2010 ) Màrquez et al . ( 2008 ) . neural approaches semantic role labeling pioneered Col - lobert et al . ( 2011 ) , applied CRF top convolutional net . Early work like Foland , Jr . Martin ( 2015 ) focused dependency features . Later work eschewed syntactic features altogether ; ( Zhou Xu , 2015 ) introduced stacked ( 6-8 layer ) bi-LSTM architecture , ( et al . , 2017 ) showed augment bi-LSTM architecture highway networks replace CRF * decoding make possible apply wide variety global constraints SRL decoding . semantic role labeling schemes work single sentence , fo - cusing object verbal ( nominal , case NomBank ) predicate . , many cases , verbal nominal predicate implicit argu - ment : appears contextual sentence , perhaps mustimplicitargument inferred . two sentences house new owner . sale finalized 10 days ago . sale second sentence ARG1 , reasonable reader infer Arg1 house mentioned prior sentence . Find - ing arguments , implicit argument detection ( sometimes shortened iSRL ) iSRL introduced Gerber Chai ( 2010 ) Ruppenhofer et al . ( 2010 ) . et al . ( 2017 ) recent neural models . avoid need huge labeled training sets , unsupervised approaches semantic role labeling attempt induce set semantic roles clustering arguments . task pioneered Riloff Schmelzenbach ( 1998 ) Swier Stevenson ( 2004 ) ; Grenager Manning ( 2006 ) , Titov Klementiev ( 2012 ) , Lang Lapata ( 2014 ) , Woodsend Lapata ( 2015 ) , Titov Khod - dam ( 2014 ) . Recent innovations frame labeling include connotation frames , mark richer information argument predicates . Connotation frames mark sentiment writer reader toward arguments ( example verb survive survived bombing expresses writer’s sympathy toward subject negative sentiment toward bombing . Connotation frames mark effect ( something bad happened x ) , value : ( x valuable ) , mental state : ( x dis - tressed event ) ( Rashkin et al . 2016 , Rashkin et al . 2017 ) . Connotation frames mark power differential arguments ( verb implore EXERCISES 21 means theme argument greater power agent ) , agency argument ( waited low agency ) . Fig . 20.9 shows visualization Sap et al . ( 2017 ) . AGENT THEME power ( AG < TH ) VERB implore implored tribunal show mercy . princess waited prince . AGENT THEME agency ( AG ) = - VERB wait Figure 2 : formal notation connotation frames power agency . first example shows relative power differential implied verb “ implored ” , i.e . , agent ( “ ” ) position less power theme ( “ tri - bunal ” ) . contrast , “ demanded tribunal show mercy ” implies agent authority theme . second example shows low level agency implied verb “ waited ” . interactive demo website findings ( Fig - ure 5 appendix screenshot ) . 2 Further - , seen Section 4.1 , connotation frames offer new insights complement de - viate well-known Bechdel test ( Bechdel , 1986 ) . particular , find high-agency women lens connotation frames rare modern films . , part , movies ( e.g . , Snow White ) accidentally pass Bechdel test even movies strong female characters entirely free deeply ingrained biases social norms . 2 Connotation Frames Power Agency create two new connotation relations , power agency ( examples Figure 3 ) , expan - sion existing connotation frame lexicons . 3 Three AMT crowdworkers annotated verbs placeholders avoid gender bias con - text ( e.g . , X rescued Y ; example task shown appendix Figure 7 ) . define anno - tated constructs follows : Power Differentials Many verbs imply au - thority levels agent theme relative 2http :// homes.cs.washington.edu/ ˜ msap / movie-bias / . 3The lexicons demo available http :// homes.cs.washington.edu/ ˜ msap / movie-bias / . power ( AG < TH ) power ( AG > TH ) agency ( AG ) = � agency ( AG ) = + Figure 3 : Sample verbs connotation frames high annotator agreement . Size indicative verb frequency corpus ( bigger = frequent ) , color differences legibility . another . example , agent “ dom - inates ” theme ( denoted power ( AG > TH ) ) , agent implied level control theme . Alternatively , agent “ hon - ors ” theme ( denoted power ( AG < TH ) ) , writer implies theme important authoritative . AMT crowdsourcing la - bel 1700 transitive verbs power differentials . three annotators per verb , inter-annotator agreement 0.34 ( Krippendorff’s ↵ ) . Agency agency attributed agent verb denotes action described implies agent powerful , decisive , capable pushing forward own storyline . example , person described “ ex - periencing ” things seem active de - cisive someone described “ determin - ing ” things . AMT workers labeled 2000 transi - tive verbs implying high / moderate / low agency ( inter-annotator agreement 0.27 ) . denote high agency agency ( AG ) = + , low agency agency ( AG ) = � . Pairwise agreements hard constraint 56 % 51 % power agency , respec - tively . Despite , agreements reach 96 % 94 % moderate labels counted agree - ing high low labels , showing - notators rarely strongly disagree another . contributing factors lower KA scores include subtlety choosing neutral Figure 20.9 connotation frames Sap et al . ( 2017 ) , showing verb implore implies agent lower power theme ( contrast , say , verb like demanded ) , showing low level agency subject waited . Figure Sap et al . ( 2017 ) . Selectional preference widely studied beyond selectional associa - tion models Resnik ( 1993 ) Resnik ( 1996 ) . Methods included cluster - ing ( Rooth et al . , 1999 ) , discriminative learning ( Bergsma et al . , 2008 ) , topic models ( Séaghdha 2010 , Ritter et al . 2010 ) , constraints expressed level words classes ( Agirre Martinez , 2001 ) . Selectional preferences successfully integrated semantic role labeling ( Erk 2007 , Zapirain et al . 2013 , et al . 2017 ) . Exercises 22 Chapter 20 • Semantic Role Labeling Agirre , E . Martinez , D . ( 2001 ) . Learning class-to-class selectional preferences . CoNLL-01 . Baker , C . F . , Fillmore , C . J . , Lowe , J . B . ( 1998 ) . Berkeley FrameNet project . COLING / ACL-98 , 86 – 90 . Bergsma , S . , Lin , D . , Goebel , R . ( 2008 ) . Discriminative learning selectional preference unlabeled text . EMNLP-08 , 59 – 68 . Bloomfield , L . ( 1933 ) . Language . University Chicago Press . Bobrow , D . G . , Kaplan , R . M . , Kay , M . , Norman , D . . , Thompson , H . , Winograd , T . ( 1977 ) . GUS , frame driven dialog system . Artificial Intelligence , 8 , 155 – 173 . Bobrow , D . G . Norman , D . . ( 1975 ) . princi - ples memory schemata . Bobrow , D . G . Collins , . ( Eds . ) , Representation Understanding . Academic Press . Brockmann , C . Lapata , M . ( 2003 ) . Evaluating com - bining approaches selectional preference acquisition . EACL-03 , 27 – 34 . Carreras , X . Màrquez , L . ( 2005 ) . Introduction CoNLL-2005 shared task : Semantic role labeling . CoNLL-05 , 152 – 164 . Chambers , N . Jurafsky , D . ( 2010 ) . Improving pseudo-words evaluating selectional preferences . ACL 2010 , 445 – 453 . Che , W . , Li , Z . , Li , Y . , Guo , Y . , Qin , B . , Liu , T . ( 2009 ) . Multilingual dependency-based syntactic se - mantic parsing . CoNLL-09 , 49 – 54 . Collobert , R . , Weston , J . , Bottou , L . , Karlen , M . , Kavukcuoglu , K . , Kuksa , P . ( 2011 ) . Natural language processing ( almost ) scratch . JMLR , 12 , 2493 – 2537 . DeJong , G . F . ( 1982 ) . overview FRUMP system . Lehnert , W . G . Ringle , M . H . ( Eds . ) , Strategies Natural Language Processing , 149 – 176 . LEA . , Q . N . T . , Bethard , S . , Moens , M . - F . ( 2017 ) . Improv - ing implicit semantic role labeling predicting semantic frame arguments . IJCNLP-17 . Dowty , D . R . ( 1979 ) . Word Meaning Montague Gram - mar . D . Reidel . Erk , K . ( 2007 ) . simple , similarity-based model selec - tional preferences . ACL-07 , 216 – 223 . Fillmore , C . J . ( 1966 ) . proposal concerning English prepo - sitions . Dinneen , F . P . ( Ed . ) , 17th annual Round Table . , Vol . 17 Monograph Series Language Linguistics , 19 – 34 . Georgetown University Press . Fillmore , C . J . ( 1968 ) . case case . Bach , E . W . Harms , R . T . ( Eds . ) , Universals Linguistic Theory , 1 – 88 . Holt , Rinehart & Winston . Fillmore , C . J . ( 1985 ) . Frames semantics - standing . Quaderni di Semantica , VI ( 2 ) , 222 – 254 . Fillmore , C . J . ( 2003 ) . Valency semantic roles : con - cept deep structure case . Ágel , V . , Eichinger , L . M . , Eroms , H . W . , Hellwig , P . , Heringer , H . J . , Lobin , H . ( Eds . ) , Dependenz und Valenz : Ein internationales Hand - buch der zeitgenössischen Forschung , chap . 36 , 457 – 475 . Walter de Gruyter . Fillmore , C . J . ( 2012 ) . Encounters language . Computa - tional Linguistics , 38 ( 4 ) , 701 – 718 . Fillmore , C . J . Baker , C . F . ( 2009 ) . frames approach semantic analysis . Heine , B . Narrog , H . ( Eds . ) , Oxford Handbook Linguistic Analysis , 313 – 340 . Oxford University Press . Fillmore , C . J . , Johnson , C . R . , Petruck , M . R . L . ( 2003 ) . Background FrameNet . International journal lexicog - raphy , 16 ( 3 ) , 235 – 250 . Foland , Jr . , W . R . Martin , J . H . ( 2015 ) . Dependency - based semantic role labeling convolutional neural networks . * SEM 2015 ) , 279 – 289 . Gale , W . . , Church , K . W . , Yarowsky , D . ( 1992 ) . Work statistical methods word sense disambiguation . Goldman , R . ( Ed . ) , Proceedings 1992 AAAI Fall Symposium Probabilistic Approaches Natural Lan - guage . Gerber , M . Chai , J . Y . ( 2010 ) . Beyond nombank : study implicit arguments nominal predicates . ACL 2010 , 1583 – 1592 . Gildea , D . Jurafsky , D . ( 2000 ) . Automatic labeling semantic roles . ACL-00 , 512 – 520 . Gildea , D . Jurafsky , D . ( 2002 ) . Automatic labeling se - mantic roles . Computational Linguistics , 28 ( 3 ) , 245 – 288 . Gildea , D . Palmer , M . ( 2002 ) . necessity syntactic parsing predicate argument recognition . ACL-02 . Goffman , E . ( 1974 ) . Frame analysis : essay orga - nization experience . Harvard University Press . Grenager , T . Manning , C . D . ( 2006 ) . Unsupervised Dis - covery Statistical Verb Lexicon . EMNLP 2006 . Gruber , J . S . ( 1965 ) . Studies Lexical Relations . Ph . D . thesis , MIT . , L . , Lee , K . , Lewis , M . , Zettlemoyer , L . ( 2017 ) . Deep semantic role labeling : works next . ACL 2017 , 473 – 483 . Hendrix , G . G . , Thompson , C . W . , Slocum , J . ( 1973 ) . Language processing via canonical verbs semantic models . Proceedings IJCAI-73 . Hirst , G . ( 1987 ) . Semantic Interpretation Resolution Ambiguity . Cambridge University Press . Hymes , D . ( 1974 ) . Ways speaking . Bauman , R . Sherzer , J . ( Eds . ) , Explorations ethnography speaking , 433 – 451 . Cambridge University Press . Johnson-Laird , P . N . ( 1983 ) . Mental Models . Harvard Uni - versity Press , Cambridge , MA . Katz , J . J . Fodor , J . . ( 1963 ) . structure seman - tic theory . Language , 39 , 170 – 210 . Keller , F . Lapata , M . ( 2003 ) . web obtain fre - quencies unseen bigrams . Computational Linguistics , 29 , 459 – 484 . Kipper , K . , Dang , H . T . , Palmer , M . ( 2000 ) . Class-based construction verb lexicon . AAAI-00 , 691 – 696 . Kullback , S . Leibler , R . . ( 1951 ) . information sufficiency . Annals Mathematical Statistics , 22 , 79 – 86 . Lakoff , G . ( 1965 ) . Nature Syntactic Irregularity . Ph . D . thesis , Indiana University . Published Irregularity Syntax . Holt , Rinehart , Winston , New York , 1970 . Lang , J . Lapata , M . ( 2014 ) . Similarity-driven semantic role induction via graph partitioning . Computational Lin - guistics , 40 ( 3 ) , 633 – 669 . Levin , B . ( 1977 ) . Mapping sentences case frames . Tech . rep . 167 , MIT AI Laboratory . AI Working Paper 143 . Exercises 23 Levin , B . ( 1993 ) . English Verb Classes Alternations : Preliminary Investigation . University Chicago Press . Levin , B . Rappaport Hovav , M . ( 2005 ) . Argument Real - ization . Cambridge University Press . Marcus , M . P . ( 1980 ) . Theory Syntactic Recognition Natural Language . MIT Press . Màrquez , L . , Carreras , X . , Litkowski , K . C . , Stevenson , S . ( 2008 ) . Semantic role labeling : introduction special issue . Computational linguistics , 34 ( 2 ) , 145 – 159 . Meyers , . , Reeves , R . , Macleod , C . , Szekely , R . , Zielin - ska , V . , Young , B . , Grishman , R . ( 2004 ) . nom - bank project : interim report . Proceedings NAACL / HLT Workshop : Frontiers Corpus Annotation . Minsky , M . ( 1974 ) . framework representing knowl - edge . Tech . rep . 306 , MIT AI Laboratory . Memo 306 . Nash-Webber , B . L . ( 1975 ) . role semantics auto - matic speech understanding . Bobrow , D . G . Collins , . ( Eds . ) , Representation Understanding , 351 – 382 . Academic Press . Palmer , M . , Gildea , D . , Xue , N . ( 2010 ) . Semantic role labeling . Synthesis Lectures Human Language Tech - nologies , 3 ( 1 ) , 1 – 103 . Palmer , M . , Kingsbury , P . , Gildea , D . ( 2005 ) . propo - sition bank : annotated corpus semantic roles . Com - putational Linguistics , 31 ( 1 ) , 71 – 106 . Penn , G . Kiparsky , P . ( 2012 ) . Pān . ini gen - erative capacity contextualized replacement systems . COLING-12 , 943 – 950 . Pradhan , S . , Moschitti , . , Xue , N . , Ng , H . T . , Björkelund , . , Uryupina , O . , Zhang , Y . , Zhong , Z . ( 2013 ) . - wards robust linguistic analysis OntoNotes . CoNLL-13 , 143 – 152 . Pradhan , S . , Ward , W . , Hacioglu , K . , Martin , J . H . , Ju - rafsky , D . ( 2005 ) . Semantic role labeling different syntactic views . ACL-05 . Rashkin , H . , Bell , E . , Choi , Y . , Volkova , S . ( 2017 ) . Mul - tilingual connotation frames : case study social media targeted sentiment analysis forecast . ACL 2017 , 459 – 464 . Rashkin , H . , Singh , S . , Choi , Y . ( 2016 ) . Connotation frames : data-driven investigation . ACL 2016 , 311 – 321 . Resnik , P . ( 1993 ) . Semantic classes syntactic ambigu - ity . Proceedings workshop Human Language Technology , 278 – 283 . Resnik , P . ( 1996 ) . Selectional constraints : information - theoretic model computational realization . Cogni - tion , 61 , 127 – 159 . Riloff , E . Schmelzenbach , M . ( 1998 ) . empirical ap - proach conceptual case frame acquisition . Proceed - ings Sixth Workshop Large Corpora , 49 – 56 . Ritter , . , Etzioni , O . , Mausam ( 2010 ) . latent dirich - let allocation method selectional preferences . ACL 2010 , 424 – 434 . Rooth , M . , Riezler , S . , Prescher , D . , Carroll , G . , Beil , F . ( 1999 ) . Inducing semantically annotated lexicon via EM-based clustering . ACL-99 , 104 – 111 . Ruppenhofer , J . , Ellsworth , M . , Petruck , M . R . L . , Johnson , C . R . , Baker , C . F . , Scheffczyk , J . ( 2016 ) . FrameNet II : Extended theory practice . . Ruppenhofer , J . , Sporleder , C . , Morante , R . , Baker , C . F . , Palmer , M . ( 2010 ) . Semeval-2010 task 10 : Linking events participants discourse . Proceedings 5th International Workshop Semantic Evaluation , 45 – 50 . Sap , M . , Prasettio , M . C . , Holtzman , . , Rashkin , H . , Choi , Y . ( 2017 ) . Connotation frames power agency modern films . EMNLP 2017 , 2329 – 2334 . Schank , R . C . Abelson , R . P . ( 1975 ) . Scripts , plans , knowledge . Proceedings IJCAI-75 , 151 – 157 . Schank , R . C . Abelson , R . P . ( 1977 ) . Scripts , Plans , Goals Understanding . Lawrence Erlbaum . Schütze , H . ( 1992 ) . Context space . Goldman , R . ( Ed . ) , Proceedings 1992 AAAI Fall Symposium Proba - bilistic Approaches Natural Language . Séaghdha , D . O . ( 2010 ) . Latent variable models selec - tional preference . ACL 2010 , 435 – 444 . Simmons , R . F . ( 1973 ) . Semantic networks : com - putation understanding English sentences . Schank , R . C . Colby , K . M . ( Eds . ) , Computer Models Thought Language , 61 – 113 . W.H . Freeman Co . Surdeanu , M . , Harabagiu , S . , Williams , J . , Aarseth , P . ( 2003 ) . predicate-argument structures informa - tion extraction . ACL-03 , 8 – 15 . Surdeanu , M . , Johansson , R . , Meyers , . , Màrquez , L . , Nivre , J . ( 2008 ) . conll-2008 shared task joint pars - ing syntactic semantic dependencies . CoNLL-08 , 159 – 177 . Swier , R . Stevenson , S . ( 2004 ) . Unsupervised semantic role labelling . EMNLP 2004 , 95 – 102 . Tannen , D . ( 1979 ) . frame ? Surface evidence underlying expectations . Freedle , R . ( Ed . ) , New Direc - tions Discourse Processing , 137 – 181 . Ablex . Tesnière , L . ( 1959 ) . Éléments de Syntaxe Structurale . Li - brairie C . Klincksieck , Paris . Titov , . Khoddam , E . ( 2014 ) . Unsupervised induction semantic roles reconstruction-error minimization framework . NAACL HLT 2015 . Titov , . Klementiev , . ( 2012 ) . Bayesian approach unsupervised semantic role induction . EACL-12 , 12 – 22 . Wilks , Y . ( 1973 ) . artificial intelligence approach ma - chine translation . Schank , R . C . Colby , K . M . ( Eds . ) , Computer Models Thought Language , 114 – 151 . W.H . Freeman . Wilks , Y . ( 1975a ) . Preference semantics . Keenan , E . L . ( Ed . ) , Formal Semantics Natural Language , 329 – 350 . Cambridge Univ . Press . Wilks , Y . ( 1975b ) . preferential , pattern-seeking , semantics natural language inference . Artificial Intelligence , 6 ( 1 ) , 53 – 74 . Winston , P . H . ( 1977 ) . Artificial Intelligence . Addison Wes - ley . Woodsend , K . Lapata , M . ( 2015 ) . Distributed represen - tations unsupervised semantic role labeling . EMNLP 2015 , 2482 – 2491 . Xue , N . Palmer , M . ( 2004 ) . Calibrating features se - mantic role labeling . EMNLP 2004 . 24 Chapter 20 • Semantic Role Labeling Zapirain , B . , Agirre , E . , Màrquez , L . , Surdeanu , M . ( 2013 ) . Selectional preferences semantic role classi - fication . Computational Linguistics , 39 ( 3 ) , 631 – 663 . Zhao , H . , Chen , W . , Kit , C . , Zhou , G . ( 2009 ) . Multi - lingual dependency learning : huge feature engineering method semantic dependency parsing . CoNLL-09 , 55 – 60 . Zhou , J . Xu , W . ( 2015 ) . End-to-end learning seman - tic role labeling recurrent neural networks . ACL 2015 , 1127 – 1137 .