Speech Language Processing . Daniel Jurafsky & James H . Martin . Copyright c © 2019 . rights reserved . Draft October 2 , 2019 . CHAPTER 23 Discourse Coherence even wildest wandering reveries , nay dreams , shall find , reflect , imagination ran altogether adven - tures , still connection upheld among different ideas , succeeded . loosest freest conversation transcribed , immediately transcribed , immediately observed something connected transitions . David Hume , enquiry concerning human understanding , 1748 Orson Welles ’ movie Citizen Kane groundbreaking many ways , perhaps notably structure . story life fictional media magnate Charles Foster Kane , movie proceed chronological order Kane’s life . , film begins Kane’s death ( famously murmuring “ Rosebud ” ) structured around flashbacks life inserted among scenes reporter investigating death . novel idea structure movie linearly follow structure real timeline made apparent 20th century cinematography infinite possibilities impact different kinds coherent narrative structures . coherent structure just fact movies works art . Like movies , language normally consist isolated , unrelated sentences , collocated , structured , coherent groups sentences . refer coherent structured group sentences discourse , word co-discourse herence refer relationship sentences makes real discoursescoherence different just random assemblages sentences . chapter read - ing example discourse , news article , conversation , thread social media , Wikipedia page , favorite novel . makes discourse coherent ? created text taking random sentences many different sources pasted together , coherent discourse ? Almost certainly . Real discourses exhibit locallocal coherence global coherence . consider three ways real discoursesglobal locally coherent ; First , sentences clauses real discourses related nearby sentences systematic ways . Consider example Hobbs ( 1979 ) : ( 23.1 ) John took train Paris Istanbul . likes spinach . sequence incoherent unclear reader why second sentence follows first ; liking spinach train trips ? fact , reader might go effort try figure discourse coherent ; perhaps French spinach shortage ? fact hearers try identify connections suggests human discourse comprehension involves need establish kind coherence . contrast , following coherent example : ( 23.2 ) Jane took train Paris Istanbul . attend conference . 2 CHAPTER 23 • DISCOURSE COHERENCE second sentence gives REASON Jane’s action first sentence . Struc - tured relationships like REASON hold text units called coherence relations , coherent discourses structured many coherence relations . coherencerelations Coherence relations introduced Section 23.1 . second way discourse locally coherent virtue “ ” someone something . coherent discourse entities salient , discourse focuses go back forth multiple entities . called entity-based coherence . Consider following incoherent passage , salient entity seems wildly swing John Jenny piano store living room , back Jenny , piano again : ( 23.3 ) John wanted buy piano living room . Jenny wanted buy piano . went piano store . nearby . living room second floor . find anything liked . piano bought hard get up floor . Entity-based coherence models measure kind coherence tracking salient entities discourse . example Centering Theory ( Grosz et al . , 1995 ) , theCenteringTheory influential theory entity-based coherence , keeps track entities discourse model salient point ( salient entities likely pronominalized appear prominent syntactic positions like subject object ) . Centering Theory , transitions sentences maintain same salient entity considered coherent ones repeatedly shift entities . entity grid model coherence ( Barzilay Lapata , 2008 ) commonly-entity grid model realizes intuitions Centering Theory framework . Entity-based coherence introduced Section 23.3 . Finally , discourses locally coherent topically coherent : nearbytopicallycoherent sentences generally same topic same similar vocab - ulary discuss topics . topically coherent discourses draw single semantic field topic , tend exhibit surface property known lexical cohesion ( Halliday Hasan , 1976 ) : sharing identical semanti-lexical cohesion cally related words nearby sentences . example , fact words house , chimney , garret , closet , window — belong same semantic field — appear two sentences ( 23.4 ) , share identical word shingled , cue two tied together discourse : ( 23.4 ) winter built chimney , shingled sides house . . . thus tight shingled plastered house . . . garret closet , large window side . . . . addition local coherence adjacent nearby sentences , dis - courses exhibit global coherence . Many genres text associated particular conventional discourse structures . Academic articles might sections describing Methodology Results . Stories might follow conventional plotlines motifs . Persuasive essays particular claim trying argue , essay might express claim together structured set premises support argument demolish potential counterarguments . introduce versions kinds global coherence . Why care local global coherence discourse ? co - herence property well-written text , coherence detection plays part 23.1 • COHERENCE RELATIONS 3 task requires measuring quality text . example coherence help pedagogical tasks like essay grading essay quality measurement try - ing grade well-written human essay ( Somasundaran et al . , 2014 ; Feng et al . , 2014 ; Lai Tetreault , 2018 ) . Coherence help summarization ; knowing coherence relationship sentences help know select information . Finally , detecting incoherent text even play role mental health tasks like measuring symptoms schizophrenia kinds dis - ordered language ( Ditman Kuperberg , 2010 ; Elvevåg et al . , 2007 ; Bedi et al . , 2015 ) . 23.1 Coherence Relations Recall introduction difference passages ( 23.5 ) ( 23.6 ) . ( 23.5 ) Jane took train Paris Istanbul . likes spinach . ( 23.6 ) Jane took train Paris Istanbul . attend conference . reason ( 23.6 ) coherent reader form connection - tween two sentences , second sentence provides potential REASON first sentences . link harder form ( 23.5 ) . connections text spans discourse specified set coherence relations . coherencerelation next two sections describe two commonly models coherence relations associated corpora : Rhetorical Structure Theory ( RST ) , Penn Discourse TreeBank ( PDTB ) . 23.1.1 Rhetorical Structure Theory commonly model discourse organization Rhetorical Structure Theory ( RST ) ( Mann Thompson , 1987 ) . RST relations defined betweenRST two spans text , generally nucleus satellite . nucleus unit thatnucleus satellite central writer’s purpose interpretable independently ; satellite less central generally interpretable respect nucleus . symmetric relations , , hold two nuclei . Below few examples RST coherence relations , definitions adapted RST Treebank Manual ( Carlson Marcu , 2001 ) . Reason : nucleus action carried animate agent satellite reason nucleus . ( 23.7 ) [ NUC Jane took train Paris Istanbul . ] [ SAT attend conference . ] Elaboration : satellite gives additional information detail situation presented nucleus . ( 23.8 ) [ NUC Dorothy Kansas . ] [ SAT lived midst great Kansas prairies . ] Evidence : satellite gives additional information detail situation presented nucleus . information presented goal convince reader accept information presented nucleus . ( 23.9 ) [ NUC Kevin . ] [ SAT car parked outside . ] 4 CHAPTER 23 • DISCOURSE COHERENCE Attribution : satellite gives source attribution instance reported speech nucleus . ( 23.10 ) [ SAT Analysts estimated ] [ NUC sales U.S . stores declined quarter , ] List : multinuclear relation , series nuclei , contrast explicit comparison : ( 23.11 ) [ NUC Billy Bones mate ; ] [ NUC Long John , quartermaster ] RST relations traditionally represented graphically ; asymmetric Nucleus - Satellite relation represented arrow satellite nucleus : Kevin . car parked outside evidence talk coherence larger text considering hierar - chical structure coherence relations . Figure 23.1 shows rhetorical struc - ture paragraph Marcu ( 2000a ) text ( 23.12 ) Scientific American magazine . ( 23.12 ) distant orbit – 50 percent farther sun Earth – slim atmospheric blanket , Mars experiences frigid weather conditions . Surface temperatures typically average - 60 degrees Celsius ( - 76 degrees Fahrenheit ) equator dip - 123 degrees C near poles . midday sun tropical latitudes warm enough thaw ice occasion , liquid water formed way evaporate almost instantly low atmospheric pressure . Title ( 1 ) Mars 2-9 evidence 2-3 background ( 2 ) distant orbit < p > - - 50 percent farther sun Earth - - < / p > slim atmospheric blanket , ( 3 ) Mars experiences frigid weather conditions . 4-9 elaboration-additional ( 4 ) Surface temperatures typically average - 60 degrees Celsius < p > ( - 76 degrees Fahrenheit ) < / p > equator 4-5 List ( 5 ) dip - 123 degrees C near poles . 6-9 Contrast 6-7 ( 6 ) midday sun tropical latitudes warm enough ( 7 ) thaw ice occasion , purpose 8-9 explanation-argumentative ( 8 ) liquid water formed way evaporate almost instantly ( 9 ) low atmospheric pressure . Figure 23.1 discourse tree Scientific American text ( 23.12 ) , Marcu ( 2000a ) . Note asymmetric relations represented curved arrow satellite nucleus . leaves Fig . 23.1 tree correspond text spans sentence , clause phrase called elementary discourse units EDUs RST ; units canEDU referred discourse segments . units correspond arbitrary spans text , determining boundaries EDU important task 23.1 • COHERENCE RELATIONS 5 extracting coherence relations . Roughly speaking , think discourse segments analogous constituents sentence syntax , indeed Section 23.2 generally draw parsing algorithms infer discourse struc - ture . corpora many discourse coherence models ; RST Discourse TreeBank ( Carlson et al . , 2001 ) largest available discourse corpus . con - sists 385 English language documents selected Penn Treebank , full RST parses , large set 78 distinct relations , grouped 16 classes . RST treebanks exist Spanish , German , Basque , Dutch Brazilian Portuguese ( Braud et al . , 2017 ) . seen examples coherence , clearly coherence relation play role summarization information extraction . example , nuclei text presumably express important information satellites , might dropped summary . 23.1.2 Penn Discourse TreeBank ( PDTB ) Penn Discourse TreeBank ( PDTB ) second commonly dataset thatPDTB embodies another model coherence relations ( Miltsakaki et al . , 2004 ; Prasad et al . , 2008 , 2014 ) . PDTB labeling lexically grounded . asking annotators directly tag coherence relation text spans , list discourse connectives , words signal discourse relations , like , although , discourseconnectives , , result . part text words marked coherence relation two text spans , connective spans annotated , Fig . 23.13 , phrase result signals causal relationship PDTB calls Arg1 ( first two sentences , italics ) Arg2 ( third sentence , bold ) . ( 23.13 ) Jewelry displays department stores often cluttered uninspired . merchandise , well , fake . result , marketers faux gems steadily lost space department stores fashionable rivals — cosmetics makers . ( 23.14 ) July , Environmental Protection Agency imposed gradual ban virtually asbestos . ( implicit = result ) 1997 , almost remaining cancer-causing asbestos outlawed . coherence relations marked explicit discourse connective , PDTB annotates pairs neighboring sentences explicit signal , like ( 23.14 ) . annotator first chooses word phrase signal ( case result ) , labels sense . example ambiguous discourse connective annotators marked CAUSAL TEMPORAL sense . final dataset contains roughly 18,000 explicit relations 16,000 implicit relations . Fig . 23.2 shows examples 4 major semantic classes , Fig . 23.3 shows full tagset . Unlike RST Discourse Treebank , integrates pairwise coherence relations global tree structure spanning entire discourse , PDTB annotate anything span-pair level , making commitment respect higher-level discourse structure . treebanks similar methods languages ; ( 23.15 ) shows example Chinese Discourse TreeBank ( Zhou Xue , 2015 ) . Chinese smaller percentage explicit discourse connectives 6 CHAPTER 23 • DISCOURSE COHERENCE Class Type Example TEMPORAL SYNCHRONOUS parishioners St . Michael Angels stop chat church door , members always . ( Implicit ) tower , five men women pull rhythmically ropes attached same five bells first sounded 1614 . CONTINGENCY REASON unlike Mr . Ruder , Mr . Breeden appears position get somewhere agenda . ( implicit = ) - mer White House aide worked closely Congress , savvy ways Washington . COMPARISON CONTRAST U.S . wants removal perceives barriers investment ; Japan denies real barriers . EXPANSION CONJUNCTION actors stand outside characters make clear odds , often literally stand heads . Figure 23.2 four high-level semantic distinctions PDTB sense hierarchy Temporal Comparison • Asynchronous • Contrast ( Juxtaposition , Opposition ) • Synchronous ( Precedence , Succession ) • Pragmatic Contrast ( Juxtaposition , Opposition ) • Concession ( Expectation , Contra-expectation ) • Pragmatic Concession Contingency Expansion • Cause ( Reason , Result ) • Exception • Pragmatic Cause ( Justification ) • Instantiation • Condition ( Hypothetical , General , Unreal Present / Past , Factual Present / Past ) • Restatement ( Specification , Equivalence , Generalization ) • Pragmatic Condition ( Relevance , Implicit - sertion ) • Alternative ( Conjunction , Disjunction , Chosen Alterna - tive ) • List Figure 23.3 PDTB sense hierarchy . four top-level c ¯ lasses , 16 types , 23 subtypes ( types subtypes ) . 11 16 types commonly implicit argument classification ; 5 types italics rare implicit labeling . English ( 22 % discourse relations marked explicit connectives , compared 47 % English ) , annotators labeled corpus directly mapping pairs sentences 11 sense tags , starting lexical discourse connec - tor . ( 23.15 ) [ Conn 为 ] [ Arg2 推动 图 们 江 地区 开发 ] ， [ Arg1 韩国 捐款 一 百万 美元 设立 了 图 们 江 发展 基金 ] “ [ order ] [ Arg2 promote development Tumen River region ] , [ Arg1 South Korea donated million dollars establish Tumen River Development Fund ] . ” discourse treebanks shared tasks multilingual dis - course parsing ( Xue et al . , 2016 ) . 23.2 Discourse Structure Parsing sequence sentences , automatically determine coherence relations ? task often called discourse parsing ( even thoughdiscourseparsing 23.2 • DISCOURSE STRUCTURE PARSING 7 PDTB assigning labels leaf spans building full parse tree RST ) . 23.2.1 EDU segmentation RST parsing RST parsing generally two stages . first stage , EDU segmentation , extracts start end EDU . output stage labeling like following : ( 23.16 ) [ Mr . Rambo ] e1 [ 3.2-acre property ] e2 [ overlooking San Fernando Valley ] e3 [ priced $ 4 million ] e4 [ late actor Erroll Flynn once lived . ] e5 EDUs roughly correspond clauses , early models EDU segmentation first ran syntactic parser , post-processed output . Modern systems generally neural sequence models supervised gold EDU segmentation RST Discourse Treebank . Fig . 23.4 shows example Wang et al . ( 2018 ) supervised architecture same biLSTM-CRF architecture saw named entity tagging semantic role labeling . input sentence mapping contextual word embeddings , passed biLSTM CRF layer top produce sequence 0s 1 , 1 indicates start EDU ( except start sentence ) . Muller et al . ( 2019 ) find BERT contextual embeddings plus convolutional character embeddings input similar biLSTM architecture produces highly accurate segmentations . Mr . Rambo LSTM1 LSTM1 LSTM1 LSTM1 LSTM2 LSTM2 LSTM2 LSTM2 Concatenation Right-to-left LSTM Left-to-right LSTM 0 0 0 1CRF Layer Contextual Embedding Contextual Embedding Contextual Embedding Contextual Embedding GloVe GloVe GloVe GloVe Word Representations Figure 23.4 biLSTM-CRF EDU segmentation . Word inputs draw contex - tual embeddings like ELMo BERT . Wang et al . ( 2018 ) . 23.2.2 RST parsing Tools building RST coherence structure discourse long based syntactic parsing algorithms like shift-reduce parsing ( Marcu , 1999 ) . Many modern RST parsers Ji Eisenstein ( 2014 ) draw neural syntactic parsers saw Chapter 15 Section ? ? , representation learning build represen - tations span , training parser choose correct shift reduce actions based gold parses training set . describe shift-reduce parser Yu et al . ( 2018 ) . parser state con - sists stack queue , produces structure taking series actions states . Actions include : 8 CHAPTER 23 • DISCOURSE COHERENCE • shift : pushes first EDU queue onto stack creating single-node subtree . • reduce ( l , d ) : merges top two subtrees stack , l coherence relation label , d nuclearity direction , d ∈ { NN , NS , SN } . well pop root operation , remove final tree stack . 560 e1 e2 e3 e4 attr elab elab e1 : American Telephone & Telegraph Co . e2 : lay off 75 85 technicians , effective Nov . 1 . e3 : workers install , maintain repair private branch exchanges , e4 : large intracompany telephone networks . Figure 1 : example RST discourse tree , { e1 , e2 , e3 , e4 } EDUs , attr elab discourse relation labels , arrows indicate nuclearities discourse relations . RST discourse parsing . studies still adopt discrete syntax features proposed statistical models , feeding neural network models ( Braud et al . , 2016 ; Braud et al . , 2017 ) . approaches model syntax trees explicit way , requiring discrete syntax parsing outputs inputs RST parsing . approaches suffer error propagation problem . Syntax trees produced supervised syntax parsing model errors , propagate discourse parsing models . problem extremely serious inputs discourse parsing different distributions training data supervised syntax parser . Recently , Zhang et al . ( 2017 ) suggest alternative method , extracts syntax features Bi-Affine dependency parser ( Dozat Manning , 2016 ) , method gives competitive performances relation extraction . actually represents syntax trees implicitly , thus reduce error propagation problem . work , investigate implicit syntax feature extraction approach RST parsing . ad - dition , propose transition-based neural model task , able incorporate various features flexibly . exploit hierarchical bi-directional LSTMs ( Bi-LSTMs ) encode texts , further enhance transition-based model dynamic oracle . Based proposed model , study effectiveness proposed implicit syntax features . conduct experiments standard RST dis - course TreeBank ( Carlson et al . , 2003 ) . First , evaluate performance proposed transition - based baseline , finding model able achieve strong performances applying dynamic oracle . evaluate effectiveness implicit syntax features extracted Bi-Affine depen - dency parser . Results show implicit syntax features effective , giving better performances explicit Tree-LSTM ( Li et al . , 2015b ) . codes released public Apache License 2.0 https://github.com/yunan4nlp/NNDisParser . summary , mainly make following two contributions work : ( 1 ) propose transition - based neural RST discourse parsing model dynamic oracle , ( 2 ) compare three different syntactic integration approaches proposed . rest paper organized follows . Section 2 describes proposed models including transition-based neural model , dynamic oracle strategy implicit syntax feature extraction approach . Section 3 presents experiments evaluate models . Section 4 shows related work . Finally , section 5 draws conclusions . 2 Transition-based Discourse Parsing follow Ji Eisenstein ( 2014 ) , exploiting transition-based framework RST discourse parsing . framework conceptually simple flexible support arbitrary features , widely number NLP tasks ( Zhu et al . , 2013 ; Dyer et al . , 2015 ; Zhang et al . , 2016 ) . addition , transition-based model formalizes certain task predicting sequence actions , essential similar sequence-to-sequence models proposed recently ( Bahdanau et al . , 2014 ) . following , first describe transition system RST discourse parsing , introduce neural network model encoder decoder parts , respectively . Thirdly , present proposed dynamic oracle strategy aiming enhance transition-based model . introduce integration method implicit syntax features . Finally describe training method neural network models . 2.1 Transition-based System transition-based framework converts structural learning problem sequence action predic - tions , whose key point transition system . transition system consists two parts : states actions . states store partially-parsed results actions control state transitions . Figure 23.5 Example RST discourse tree , showing four EDUs . Figure Yu et al . ( 2018 ) . Fig . 23.6 shows actions parser takes build structure Fig . 23.5 . 561 Step Stack Queue Action Relation 1 ? e1 , e2 , e3 , e4 SH ? 2 e1 e2 , e3 , e4 SH ? 3 e1 , e2 e3 , e4 RD ( attr , SN ) ? 4 e1:2 e3 , e4 SH de1e2 5 e1:2 , e3 e4 SH de1e2 6 e1:2 , e3 , e4 ? RD ( elab , NS ) de1e2 7 e1:2 , e3:4 ? RD ( elab , SN ) de1e2 , de3e4 8 e1:4 ? PR de1e2 , de3e4 , \ e1:2e3:4 Table 1 : example transition-based system RST discourse parsing . initial state empty state , final state represents full result . three kinds actions transition system : • Shift ( SH ) , removes first EDU queue onto stack , forming single-node subtree . • Reduce ( RD ) ( l , d ) , merges top two subtrees stack , l discourse relation label , d 2 { NN , NS , SN } indicates relation nuclearity ( nuclear ( N ) satellite ( S ) ) . • Pop Root ( PR ) , pops top tree stack , marking decoding completed , stack holds subtree queue empty . RST tree shown Figure 1 , generated following action sequence : { SH , SH , RD ( attr , SN ) , SH , SH , RD ( elab , NS ) , RD ( elab , SN ) , PR } . Table 1 shows decoding process detail . way , naturally convert RST discourse parsing predicting sequence transition actions , line includes state next step action referring tree . 2.2 Encoder-Decoder Previous transition-based RST discourse parsing studies exploit statistical models , manually - designed discrete features ( Sagae , 2009 ; Heilman Sagae , 2015 ; Wang et al . , 2017 ) . work , propose transition-based neural model RST discourse parsing , follows encoder-decoder framework . input sequence EDUs { e1 , e2 , . . . , en } , encoder computes input represen - tations { he1 , he2 , . . . , hen } , decoder predicts next step actions conditioned encoder outputs . 2.2.1 Encoder follow Li et al . ( 2016 ) , hierarchical Bi-LSTMs encode source EDU inputs , first-layer represent sequencial words inside EDUs , second layer represent sequencial EDUs . input sentence { w1 , w2 , . . . , wm } , first represent word form ( e.g . , wi ) POS tag ( e.g . ti ) , concatenating neural embeddings . way , input vectors first-layer Bi-LSTM { xw1 , xw2 , . . . , xwm } , xwi = emb ( wi ) � emb ( ti ) , apply Bi-LSTM directly , obtaining : { hw1 , hw2 , . . . , hwm } = Bi-LSTM ( { xw1 , xw2 , . . . , xwm } ) ( 1 ) second-layer Bi-LSTM built sequential EDUs . first obtain suitable representa - tion EDU , composed span words inside certain sentence . Assuming EDU words { ws , ws + 1 , . . . , wt } , applying first-layer Bi-LSTM , obtain representa - tions { hws , hws + 1 . . . , hwt } , calculate EDU representation average pooling : xe = 1 t � s + 1 tX s hwk ( 2 ) EDU representations ready , apply second-layer Bi-LSTM directly , resulting : { he1 , he2 , . . . , hen } = Bi-LSTM ( { xe1 , xe2 , . . . , xen } ) ( 3 ) Figure 23.6 Parsing example Fig . 23.5 shift-reduce parser . Figure Yu et al . ( 2018 ) . Yu et al . ( 2018 ) encoder-decoder architecture , encoder represents input span words EDUs hierarchical biLSTM . first biLSTM layer represents words inside EDU , second represents EDU sequence . input sentence w1 , w2 , . . . , wm , words repre - sented usual ( static embeddings , combinations character embeddings tags , contextual embeddings ) resulting input word representation sequence xw1 , x w 2 , . . . , x w m . result word-level biLSTM sequence hw values : hw1 , h w 2 , . . . , h w m = biLSTM ( x w 1 , x w 2 , . . . , x w m ) ( 23.17 ) EDU span ws , ws + 1 , . . . , wt biLSTM output representation hws , hws + 1 , . . . , h w t , represented average pooling : xe = 1 t − s + 1 t ∑ k = s hwk ( 23.18 ) second layer input compute final representation sequence EDU representations : he1 , h e 2 , . . . , h e n = biLSTM ( x e 1 , x e 2 , . . . , x e n ) ( 23.19 ) decoder feedforward network W outputs action o based concatenation top three subtrees stack ( , s1 , s2 ) plus first EDU 23.2 • DISCOURSE STRUCTURE PARSING 9 queue ( q0 ) : o = W ( hts0 , h t s0 , h t s1 , h t s2 , h e q0 ) ( 23.20 ) representation EDU queue heq0 comes directly encoder , three hidden vectors representing partial trees computed average pooling encoder output EDUs trees : hts = 1 j − + 1 j ∑ k = hek ( 23.21 ) Training first maps RST gold parse tree sequence oracle actions , standard cross-entropy loss ( l2 regularization ) train system take actions . Give state S oracle action , first compute decoder output Eq . 23.20 , apply softmax get probabilities : pa = exp ( oa ) ∑ ′ ∈ exp ( oa ′ ) ( 23.22 ) computing cross-entropy loss : L ( Θ ) = − log ( pa ) + λ 2 | | Θ | | 2 ( 23.23 ) RST discourse parsers evaluated test section RST Discourse Tree - bank , gold EDUs end-to-end , RST-Pareval metrics ( Marcu , 2000b ) . standard first transform gold RST trees right-branching bi - nary trees , report four metrics : trees labels ( S Span ) , labeled nuclei ( N ) , relations ( R ) , ( F Full ) , metric computing micro-averaged F1 spans documents ( Marcu , 2000b ; Morey et al . , 2017 ) . 23.2.3 PDTB discourse parsing PDTB discourse parsing , task detecting PDTB coherence relations spans , sometimes called shallow discourse parsing task just involves shallow discourse parsing flat relationships text spans , rather full trees RST parsing . set four subtasks PDTB discourse parsing laid Lin et al . ( 2014 ) first complete system , separate tasks explicit ( tasks 1-3 ) implicit ( task 4 ) connectives : 1 . Find discourse connectives ( disambiguating non-discourse ) 2 . Find two spans connective 3 . Label relationship spans 4 . Assign relation every adjacent pair sentences Many systems proposed Task 4 : taking pair adjacent sentences input assign coherence relation sense label output . setup often fol - lows Lin et al . ( 2009 ) assuming gold sentence span boundaries assigning adjacent span 11 second-level PDTB tags none ( removing 5 rare tags 16 shown italics Fig . 23.3 ) . simple strong algorithm Task 4 represent two spans BERT contextual embeddings take last layer hidden state corre - sponding position < CLS > token , pass single layer tanh feedforward network softmax sense classification ( Nie et al . , 2019 ) . 10 CHAPTER 23 • DISCOURSE COHERENCE tasks addressed . Task 1 disambiguat - ing discourse connectives non-discourse . example Pitler Nenkova ( 2009 ) point , word discourse connective linking two clauses elaboration / expansion relation ( 23.24 ) non-discourse NP conjunction ( 23.25 ) : ( 23.24 ) Selling picked up previous buyers bailed positions aggressive short sellers — anticipating further declines — moved . ( 23.25 ) favorite colors blue green . Similarly , once discourse connective indicating temporal relation ( 23.26 ) , simply non-discourse adverb meaning ‘ formerly ’ modifying ( 23.27 ) : ( 23.26 ) asbestos fiber , crocidolite , unusually resilient once enters lungs , even brief exposures causing symptoms show up decades later , researchers . ( 23.27 ) form asbestos once make Kent cigarette filters caused high percentage cancer deaths among group workers exposed 30 years ago , researchers reported . Determining word discourse connective thus special case word sense disambiguation . Early work disambiguation showed 4 PDTB high-level sense classes disambiguated high ( 94 % ) accuracy syntactic features gold parse trees ( Pitler Nenkova , 2009 ) . Recent work performs task end end word inputs biLSTM-CRF BIO outputs ( B-CONN , I-CONN , O ) ( Yu et al . , 2019 ) . task 2 , PDTB spans identified same sequence models find RST EDUs : biLSTM sequence model pretrained contextual embedding ( BERT ) inputs ( Muller et al . , 2019 ) . Simple heuristics pretty well base - line finding spans , 93 % relations completely single sentence span two adjacent sentences , argument sentence ( Biran McKeown , 2015 ) . 23.3 Centering Entity-Based Coherence second way discourse coherent virtue “ ” entity . idea point discourse entity salient , discourse coherent continuing discuss same entity , appears early functional lin - guistics psychology discourse ( Chafe , 1976 ; Kintsch Van Dijk , 1978 ) , soon made way computational models . section introduce two models kind entity-based coherence : Centering Theory ( Grosz et al . , entity-based 1995 ) , entity grid model Barzilay Lapata ( 2008 ) . 23.3.1 Centering Centering Theory ( Grosz et al . , 1995 ) theory discourse salience andCenteringTheory discourse coherence . model discourse salience , Centering proposes point discourse entities discourse model salient : “ centered ” . model discourse coherence , Centering proposes discourses adjacent sentences CONTINUE maintain same salient entity coherent SHIFT back forth multiple entities ( CONTINUE SHIFT technical terms theory ) . 23.3 • CENTERING ENTITY-BASED COHERENCE 11 following two texts Grosz et al . ( 1995 ) exactly same propositional content different saliences , help understanding main Centering intuition . ( 23.28 ) . John went favorite music store buy piano . b . frequented store many years . c . excited finally buy piano . d . arrived just store closing day . ( 23.29 ) . John went favorite music store buy piano . b . store John frequented many years . c . excited finally buy piano . d . closing just John arrived . two texts differ two entities ( John store ) realized sentences , discourse ( 23.28 ) intuitively coherent ( 23.29 ) . Grosz et al . ( 1995 ) point , discourse ( 23.28 ) clearly individual , John , describing actions feelings . discourse ( 23.29 ) , contrast , focuses first John , store , back John , store again . lacks “ aboutness ” first discourse . Centering Theory realizes intuition maintaining two representations utterance Un . backward-looking center Un , denoted Cb ( Un ) , rep - backward - looking center resents current salient entity , focused discourse Un interpreted . forward-looking centers Un , denoted C f ( Un ) , setforward-lookingcenter potential future salient entities , discourse entities evoked Un serve Cb ( salient entity ) following utterance , i.e . Cb ( Un + 1 ) . set forward-looking centers C f ( Un ) ranked according factors like discourse salience grammatical role ( example subjects higher ranked objects , higher ranked grammatical roles ) . call highest-ranked forward-looking center Cp ( “ preferred center ” ) . Cp kind prediction entity talked next . Sometimes next utterance indeed talks entity , sometimes another entity becomes salient . algorithm centering presented Brennan et al . ( 1987 ) , defines four intersentential relationships pair utterances Un Un + 1 depend relationship Cb ( Un + 1 ) , Cb ( Un ) , Cp ( Un + 1 ) ; shown Fig . 23.7 . Cb ( Un + 1 ) = Cb ( Un ) Cb ( Un + 1 ) 6 = Cb ( Un ) undefined Cb ( Un ) Cb ( Un + 1 ) = Cp ( Un + 1 ) Continue Smooth-Shift Cb ( Un + 1 ) 6 = Cp ( Un + 1 ) Retain Rough-Shift Figure 23.7 Centering Transitions Rule 2 Brennan et al . ( 1987 ) . following rules algorithm : Rule 1 : element C f ( Un ) realized pronoun utterance Un + 1 , Cb ( Un + 1 ) realized pronoun . Rule 2 : Transition states ordered . Continue preferred Retain preferred Smooth-Shift preferred Rough-Shift . Rule 1 captures intuition pronominalization ( including zero-anaphora ) common way mark discourse salience . multiple pronouns 12 CHAPTER 23 • DISCOURSE COHERENCE utterance realizing entities previous utterance , pronouns realize backward center Cb ; pronoun , Cb . Rule 2 captures intuition discourses continue center same en - tity coherent ones repeatedly shift centers . transition table based two factors : backward-looking center Cb same Un Un + 1 discourse entity preferred ( Cp ) Un . hold , CONTINUE relation , speaker talking same entity going continue talking entity . RETAIN relation , speaker intends SHIFT new entity future utterance mean - places current entity lower rank C f . SHIFT relation , speaker shifting new salient entity . walk though start ( 23.28 ) again , repeated ( 23.30 ) , showing representations utterance processed . ( 23.30 ) John went favorite music store buy piano . ( U1 ) excited finally buy piano . ( U2 ) arrived just store closing day . ( U3 ) closing just John arrived ( U4 ) grammatical role hierarchy order C f , sentence U1 get : C f ( U1 ) : { John , music store , piano } Cp ( U1 ) : John Cb ( U1 ) : undefined sentence U2 : C f ( U2 ) : { John , piano } Cp ( U2 ) : John Cb ( U2 ) : John Result : Continue ( Cp ( U2 ) = Cb ( U2 ) ; Cb ( U1 ) undefined ) transition U1 U2 thus CONTINUE . Completing example left exercise ( 1 ) reader 23.3.2 Entity Grid model Centering embodies particular theory entity mentioning leads coher - ence : salient entities appear subject position pronominalized , discourses salient means continuing mention same entity ways . entity grid model Barzilay Lapata ( 2008 ) alternative way toentity grid capture entity-based coherence : top-down theory , entity-grid model machine learning induce patterns entity mentioning make discourse coherent . model based around entity grid , two-dimensional array repre - sents distribution entity mentions sentences . rows represent sen - tences , columns represent discourse entities ( versions entity grid model focus just nominal mentions ) . cell represents possible appearance entity sentence , values represent entity appears grammatical role . Grammatical roles subject ( S ) , object ( O ) , neither ( X ) , ab - sent ( – ) ; implementation Barzilay Lapata ( 2008 ) , subjects passives represented O , leading representation characteristics thematic roles . 23.3 • CENTERING ENTITY-BASED COHERENCE 13 Computational Linguistics Volume 34 , Number 1 patterns encoded feature vectors appropriate performing coherence - related ranking classification tasks . 3.1 Entity-Grid Discourse Representation text represented entity grid , two-dimensional array captures distribution discourse entities text sentences . follow Miltsakaki Kukich ( 2000 ) assuming unit analysis traditional sentence ( i.e . , main clause accompanying subordinate adjunct clauses ) . rows grid correspond sentences , columns correspond discourse entities . discourse entity mean class coreferent noun phrases ( explain Section 3.3 coreferent entities identified ) . occurrence discourse entity text , corresponding grid cell contains information presence absence sequence sentences . addition , entities present sentence , grid cells contain information syntactic role . information expressed many ways ( e.g . , constituent labels thematic role information ) . grammatical relations figure prominently entity-based theories local coherence ( Section 2 ) , serve logical point departure . grid cell thus corresponds string set categories reflecting entity question subject ( S ) , object ( O ) , neither ( X ) . Entities absent sentence signaled gaps ( – ) . Grammatical role information extracted output broad-coverage dependency parser ( Lin 2001 ; Briscoe Carroll 2002 ) state-of-the art statistical parser ( Collins 1997 ; Charniak 2000 ) . discuss information computed experiments Section 3.3 . Table 1 illustrates fragment entity grid constructed text Table 2 . text contains six sentences , grid columns length six . Consider instance grid column entity trial , [ O – – – – X ] . records trial present sentences 1 6 ( O X , respectively ) absent rest sentences . note grid Table 1 takes coreference resolution account . Even though same entity appears different linguistic forms , example , Microsoft Corp . , Microsoft , company , mapped single entry grid ( column introduced Microsoft Table 1 ) . Table 1 fragment entity grid . Noun phrases represented head nouns . Grid cells correspond grammatical roles : subjects ( S ) , objects ( O ) , neither ( X ) . D ep ar tm en t Tr ia l M ic ro ft Ev id en ce C om pe ti rs M ar ke ts Pr od uc ts Br ds C e N et sc ap e ft w ar e Ta ct ic s G ov er nm en t Su Ea rn gs 1 S O S X O – – – – – – – – – – 1 2 – – O – – X S O – – – – – – – 2 3 – – S O – – – – S O O – – – – 3 4 – – S – – – – – – – – S – – – 4 5 – – – – – – – – – – – – S O – 5 6 – X S – – – – – – – – – – – O 6 6 Figure 23.8 Part entity grid text Fig . 23.9 . Entities listed head noun ; cell represents entity appears subject ( S ) , object ( O ) , neither ( X ) , absent ( – ) . Figure Barzilay Lapata ( 2008 ) . Barzilay Lapata Modeling Local Coherence Table 2 Summary augmented syntactic annotations grid computation . 1 [ Justice Department ] S conducting [ anti-trust trial ] O against [ Microsoft Corp . ] X [ evidence ] X [ company ] S increasingly attempting crush [ competitors ] O . 2 [ Microsoft ] O accused trying forcefully buy [ markets ] X [ own products ] S competitive enough unseat [ established brands ] O . 3 [ case ] S revolves around [ evidence ] O [ Microsoft ] S aggressively pressuring [ Netscape ] O merging [ browser software ] O . 4 [ Microsoft ] S claims [ tactics ] S commonplace good economically . 5 [ government ] S file [ civil suit ] O ruling [ conspiracy ] S curb [ competition ] O [ collusion ] X [ violation Sherman Act ] O . 6 [ Microsoft ] S continues show [ increased earnings ] O despite [ trial ] X . noun attested once different grammatical role same sentence , default role highest grammatical ranking : subjects ranked higher objects , turn ranked higher rest . example , entity Microsoft mentioned twice Sentence 1 grammatical roles x ( Microsoft Corp . ) s ( company ) , represented s grid ( Tables 1 2 ) . 3.2 Entity Grids Feature Vectors fundamental assumption underlying approach distribution entities coherent texts exhibits certain regularities reflected grid topology . regularities formalized Centering Theory constraints transitions local focus adjacent sentences . Grids coherent texts likely dense columns ( i.e . , columns just few gaps , Microsoft Table 1 ) many sparse columns consist mostly gaps ( markets earnings Table 1 ) . further expect entities corresponding dense columns often subjects objects . characteristics less pronounced low-coherence texts . Inspired Centering Theory , analysis revolves around patterns local entity transitions . local entity transition sequence { S , O , X , – } n represents entity occurrences syntactic roles n adjacent sentences . Local transitions easily obtained grid continuous subsequences column . transition certain probability grid . instance , probability transition [ S – ] grid Table 1 0.08 ( computed ratio frequency [ i.e . , six ] divided total number transitions length two [ i.e . , 75 ] ) . text thus viewed distribution defined transition types . go step further represent text fixed set transition sequences standard feature vector notation . grid rendering j document di corresponds feature vector Φ ( x ij ) = ( p1 ( x ij ) , p2 ( x ij ) , . . . , pm ( x ij ) ) , m number predefined entity transitions , pt ( x ij ) probability transition t grid x ij . feature vector representation usefully amenable machine learning algorithms ( experiments Sections 4 – 6 ) . Furthermore , allows consid - eration large numbers transitions potentially uncover novel entity distribution patterns relevant coherence assessment coherence-related tasks . Note considerable latitude available specifying transition types included feature vector . transitions length ( e.g . , two three ) frequent transitions document collection . example 7 Figure 23.9 discourse entities marked annotated grammatical func - tions . Figure Barzilay Lapata ( 2008 ) . Fig . 23.8 Barzilay Lapata ( 2008 ) shows grid text shown Fig . 23.9 . row six sentences . second column , entity ‘ trial ’ , O – – – X , showing trial appears first sentence direct object , last sentence oblique , appear middle sentences . third column , entity Microsoft , shows appears sub - ject sentence 1 ( appears object preposition against , entities appear multiple times recorded highest-ranked grammatical func - tion ) . Computing entity grids requires extracting entities coreference resolution cluster discourse entities ( Chapter 22 ) well parsing sentences get grammatical roles . resulting grid , columns dense ( like column Microsoft ) - dicate entities mentioned often texts ; sparse columns ( like column earnings ) indicate entities mentioned rarely . entity grid model , coherence measured patterns local entity tran - sition . example , Department subject sentence 1 , men - tioned sentence 2 ; transition [ S – ] . transitions thus sequences { S , O X , – } n extracted continuous cells column . transition probability ; probability [ S – ] grid Fig . 23.8 0.08 ( occurs 6 times 75 total transitions length two ) . Fig . 23.10 shows distribution transitions length 2 text Fig . 23.9 ( shown first row d1 ) , 2 documents . transitions probabilities features machine learning model . model text classifier trained produce human-labeled coherence scores ( example humans labeling text coherent inco - herent ) . data expensive gather . Barzilay Lapata ( 2005 ) introduced simplifying innovation : coherence models trained self-supervision : trained distinguish natural original order sentences discourse 14 CHAPTER 23 • DISCOURSE COHERENCE Computational Linguistics Volume 34 , Number 1 feature space transitions length two illustrated Table 3 . second row ( introduced d1 ) feature vector representation grid Table 1 . 3.3 Grid Construction : Linguistic Dimensions central research issues developing entity-based models coherence determining sources linguistic knowledge essential accurate prediction , encode succinctly discourse representation . Previous approaches tend agree features entity distribution related local coherence — disagreement lies way features modeled . study alternative encodings mere duplication previous ef - forts ( Poesio et al . 2004 ) focus linguistic aspects parameterization . interested automatically constructed model , take account com - putational learning issues considering alternative representations . , exploration parameter space guided three considerations : linguistic importance parameter , accuracy automatic computation , size resulting feature space . linguistic side , focus properties entity distri - bution tightly linked local coherence , same time allow multiple interpretations encoding process . Computational considerations prevent considering discourse representations computed reliably exist - ing tools . instance , experiment granularity utterance — sentence versus clause — available clause separators introduce substantial noise grid construction . Finally , exclude representations explode size feature space , thereby increasing amount data required training model . Entity Ex traction . accurate computation entity classes key computing mean - ingful entity grids . previous implementations entity-based models , classes coref - erent nouns extracted manually ( Miltsakaki Kukich 2000 ; Karamanis et al . 2004 ; Poesio et al . 2004 ) , option model . obvious solution identifying entity classes employ automatic coreference resolution tool determines noun phrases refer same entity document . Current approaches recast coreference resolution classification task . pair NPs classified coreferring based constraints learned annotated corpus . separate clustering mechanism coordinates possibly contradictory pairwise classifications constructs partition set NPs . experiments , employ Ng Cardie’s ( 2002 ) coreference resolution system . system decides two NPs coreferent exploiting wealth lexical , grammatical , semantic , positional features . trained MUC ( 6 – 7 ) data sets yields state-of-the-art performance ( 70.4 F-measure MUC-6 63.4 MUC-7 ) . Table 3 Example feature-vector document representation transitions length two syntactic categories S , O , X , – . S S S O S X S – O S O O O X O – X S X O X X X – – S – O – X – – d1 . 01 . 01 0 . 08 . 01 0 0 . 09 0 0 0 . 03 . 05 . 07 . 03 . 59 d2 . 02 . 01 . 01 . 02 0 . 07 0 . 02 . 14 . 14 . 06 . 04 . 03 . 07 0.1 . 36 d3 . 02 0 0 . 03 . 09 0 . 09 . 06 0 0 0 . 05 . 03 . 07 . 17 . 39 8 Figure 23.10 feature vector representing documents transitions length 2 . Document d1 text Fig . 23.9 . Figure Barzilay Lapata ( 2008 ) . modified order ( randomized order ) . turn evaluations next section . 23.3.3 Evaluating Neural Entity-based coherence Entity-based coherence models , well neural models introduce next section , generally evaluated two ways . First , humans rate coherence document train classifier predict human ratings , categorial ( high / low , high / mid / low ) continuous . best evaluation end task mind , like essay grading , human raters correct definition final label . Alternatively , expensive get human labels , might yet end-task mind , natural texts self-supervision . self-supervision pair up natural discourse pseudo-document created changing ordering . naturally-ordered discourses coherent random permutation ( Lin et al . , 2011 ) , successful coherence algorithm pre - fer original ordering . Self-supervision implemented 3 ways . sentence order dis - crimination task ( Barzilay Lapata , 2005 ) , compare document random permutation sentence . model considered correct ( original , per - muted ) test pair ranks original document higher . k documents , compute n permutations , resulting kn pairs original document permutation , training testing . sentence insertion task ( Chen et al . , 2007 ) take document , remove n sentences s , create n − 1 copies document s inserted position . task decide n documents original ordering , distinguishing original position s positions . Insertion harder discrimination comparing documents differ sentence . Finally , sentence order reconstruction task ( Lapata , 2003 ) , take document , randomize sentences , train model put back correct order . Again k documents , compute n permutations , resulting kn pairs original document permutation , training testing . Reordering course harder task simple classification . 23.4 Representation learning models local coherence third kind local coherence topical semantic field coherence . Discourses cohere talking same topics subtopics , drawing same semantic fields . field pioneered series unsupervised models 1990s 23.4 • REPRESENTATION LEARNING MODELS LOCAL COHERENCE 15 kind coherence made lexical cohesion ( Halliday Hasan , 1976 ) : lexical cohesion sharing identical semantically related words nearby sentences . Morris Hirst ( 1991 ) computed lexical chains words ( like pine , bush trees , trunk ) occurred discourse related Roget’s Thesaurus ( same category , linked categories ) . showed number density chain correlated topic structure . TextTiling algorithm HearstTextTiling ( 1997 ) computed cosine neighboring text spans ( normalized dot product vectors raw word counts ) , again showing sentences paragraph subtopic high cosine , sentences neighboring subtopic . third early model , LSA Coherence method Foltz et al . ( 1998 ) first embeddings , modeling coherence two sentences co - sine LSA sentence embedding vectors1 , computing embeddings sentence s summing embeddings words w : sim ( s , t ) = cos ( s , t ) = cos ( ∑ w ∈ s w , ∑ w ∈ t w ) ( 23.31 ) defining overall coherence text average similarity pairs adjacent sentences si si + 1 : coherence ( T ) = 1 n − 1 n − 1 ∑ = 1 cos ( si , si + 1 ) ( 23.32 ) Modern neural representation-learning coherence models , beginning Li et al . ( 2014 ) , draw intuitions early unsupervised models learning sen - tence representations measuring change neighboring sen - tences . new models draw idea pioneered Barzilay Lapata ( 2005 ) self-supervision . , unlike say coherence relation models , train hand-labeled representations RST PDTB , models trained distinguish natural discourses unnatural discourses formed scrambling order sentences , thus representation learning discover features matter least ordering aspect coherence . present model , local coherence discriminator ( LCD ) ( Xu et al . , 2019 ) . Like early models , LCD computes coherence text av - erage coherence scores consecutive pairs sentences . unlike early unsupervised models , LCD self-supervised model trained discriminate consecutive sentence pairs ( si , si + 1 ) training documents ( assumed coher - ent ) ( constructed ) incoherent pairs ( si , s ′ ) . consecutive pairs positive examples , negative ( incoherent ) partner sentence si another sentence uniformly sampled same document si . Fig . 23.11 describes architecture model fθ , takes sentence pair returns score , higher scores coherent pairs . input sentence pair s t , model computes sentence embeddings s t ( sentence embeddings algorithm ) , concatenates four features pair : ( 1 ) concatenation two vectors ( 2 ) difference s − t ; ( 3 ) absolute value difference | s − t | ; ( 4 ) element-wise product s � t . passed one-layer feedforward network output coherence score . 1 Chapter 6 LSA embeddings ; computed applying SVD term - document matrix ( cell weighted log frequency normalized entropy ) , first 300 dimensions embedding . 16 CHAPTER 23 • DISCOURSE COHERENCE 681 Loss function : role loss function encourage f + = f ✓ ( si , si + 1 ) high f � = f ✓ ( si , s0 ) low . Common losses margin log loss . exper - imental validation , found margin loss superior problem . Specifically , L takes form : L ( f + , f � ) = max ( 0 , ⌘ � f + + f � ) ⌘ margin hyperparameter . Negative samples : Technically , free choose sentence s0 form negative pair si . , potential differ - ences genre , topic writing style , neg - atives might cause discriminative model learn cues unrelated coherence . , select sentences same document construct negative pairs . Specifically , suppose si comes document dk length nk , p ( s0 | si ) uniform distribution nk � 1 sentences { sj } j 6 = dk . document n sentences , n � 1 positive pairs , ( n � 1 ) ⇤ ( n � 2 ) / 2 negative pairs . turns quadratic number negatives provides rich enough learning signal , same time , prohibitively large effectively cov - ered sampling procedure . practice , sample new set negatives time document , hence many epochs , ef - fectively cover space even long doc - uments . Section 5.7 discusses further details sampling . 4.1 Model Architecture specific neural architecture f ✓ illustrated Figure 1 . assume pre-trained sentence encoder , dis - cussed next section . input sentence pair , sentence en - coder maps sentences real-valued vectors S T . compute concatenation following features : ( 1 ) concatenation two vectors ( S , T ) ; ( 2 ) element-wise difference S � T ; ( 3 ) element-wise product S ⇤ T ; ( 4 ) absolute value element-wise difference | S � T | . concate - nated feature representation fed - layer MLP output coherence score . practice , make overall coherence model bidirectional , training forward model input ( S , T ) backward model - put ( T , S ) same architecture separate parameters . coherence score aver - age two models . Figure 1 : Generic architecture proposed model . 4.2 Pre-trained Generative Model Sentence Encoder model work pre-trained sen - tence encoder , ranging simplistic average GloVe ( Pennington et al . , 2014 ) embed - dings sophisticated supervised unsu - pervised pre-trained sentence encoders ( Conneau et al . , 2017 ) . mentioned introduction , generative models often turned sentence encoder , generative coherence model leveraged model benefit advantages generative discriminative training , similar ( Kiros et al . , 2015 ; Peters et al . , 2018 ) . initialization , freeze genera - tive model parameters avoid overfitting . Section 5 , experimentally show benefit strong pre-trained en - coders , fact local discriminative model improves previous methods independent choice sentence encoder . 5 Experiments 5.1 Evaluation Tasks Following Nguyen Joty ( 2017 ) pre - vious work , evaluate models dis - crimination insertion tasks . Additionally , evaluate paragraph reconstruction task open-domain settings , similar manner Li Jurafsky ( 2017 ) . discrimination task , document com - pared random permutation sentences , model considered correct scores original document higher permuted . Twenty permutations test set ac - cordance previous work . Figure 23.11 architecture LCD model document coherence , showing computation score pair sentences s t . Figure Xu et al . ( 2019 ) . model trained make coherence score higher real pairs negative pairs . formally , training objective corpus C documents d , consists list sentences si , : Lθ = ∑ d ∈ C ∑ si ∈ d E p ( s ′ | si ) [ L ( fθ ( si , si + 1 ) , fθ ( si , s ′ ) ) ] ( 23.33 ) Ep ( s ′ | si ) expectation respect negative sampling distribution con - ditioned si : sentence si algorithms samples negative sentence s ′ uniformly sentences same document . L loss function takes two scores , positive pair negative pair , goal encouraging f + = fθ ( si , si + 1 ) high f − = fθ ( si , s ′ ) ) low . Fig . 23.11 margin loss l ( f + , f − ) = max ( 0 , η − f + + f − ) η margin hyper - parameter . Xu et al . ( 2019 ) give useful baseline algorithm itself quite high performance measuring perplexity : train RNN language model data , compute log likelihood sentence si two ways , once preceding context ( conditional log likelihood ) once context ( marginal log likeli - hood ) . difference values tells preceding context improved predictability si , predictability measure coherence . architecture roots neural models lie cohesion-based idea coherent discourses share words , semantic fields , topics , qualitative analysis models ( Li Jurafsky , 2017 ) suggest neural models represent coherence due relations ( example neural models find pairs sentences coherent causal temporal relation ) entity coher - ence ( example models correctly assign discourse ( 23.28 ) higher coherence score ( 23.29 ) . 23.5 Global Coherence discourse cohere globally rather just level pairs sen - tences . Consider stories , example . narrative structure stories 23.5 • GLOBAL COHERENCE 17 oldest kinds global coherence studied . influential Morphology Folktale , Propp ( 1968 ) models discourse structure Russian folktales via kind plot grammar . model includes set character categories called dramatis personae , like Hero , Villain , Donor , Helper , set events called functions ( like “ Villain commits kidnapping ” , “ Donor tests Hero ” , “ Hero pursued ” ) occur particular order , components . Propp shows plots fairy tales studies represented sequence functions , different tales choosing different subsets functions , always same order . Indeed Lakoff ( 1972 ) showed Propp’s model amounted discourse grammar stories , recent computational work Fin - layson ( 2016 ) demonstrates Proppian functions induced corpora folktale texts detecting events similar actions stories . Bamman et al . ( 2013 ) showed generalizations dramatis personae induced movie plot summaries Wikipedia . model induced latent personae features like actions character takes ( e.g . , Villains stran - gle ) , actions ( e.g . , Villains foiled arrested ) descriptive words ( Villains evil ) . section introduce two kinds global discourse structure widely studied computationally . first structure arguments : way people attempt convince persuasive essays offering claims supporting premises . second somewhat related : structure scientific papers , way authors present goals , results , relationship prior work papers . 23.5.1 Argumentation Structure first type global discourse structure structure arguments . Analyzing people’s argumentation computationally often called argumentation mining . argumentationmining study arguments dates back Aristotle , Rhetorics described three components good argument : pathos ( appealing emotions thepathos listener ) , ethos ( appealing speaker’s personal character ) , logos ( logicalethos logos structure argument ) . discourse structure studies argumentation focused logos , particularly via building training annotated datasets persuasive essays arguments ( Reed et al . , 2008 ; Stab Gurevych , 2014a ; Peldszus Stede , 2016 ; Habernal Gurevych , 2017 ; Musi et al . , 2018 ) . corpora , exam - ple , often include annotations argumentative components like claims ( centralclaims component argument controversial needs support ) premisespremises ( reasons author persuade reader supporting attacking claim premises ) , well argumentative relations themargumentativerelations like SUPPORT ATTACK . Consider following example persuasive essay Stab Gurevych ( 2014b ) . first sentence ( 1 ) presents claim ( bold ) . ( 2 ) ( 3 ) present two premises supporting claim . ( 4 ) gives premise supporting premise ( 3 ) . “ ( 1 ) Museums art galleries provide better understanding arts Internet . ( 2 ) museums art galleries , de - tailed descriptions terms background , history author provided . ( 3 ) Seeing artwork online same watching own eyes , ( 4 ) picture online show texture three-dimensional structure art , important study . ” 18 CHAPTER 23 • DISCOURSE COHERENCE Thus example three argumentative relations : SUPPORT ( 2,1 ) , SUPPORT ( 3,1 ) SUPPORT ( 4,3 ) . Fig . 23.12 shows structure complex argu - ment . Stab Gurevych Parsing Argumentation Structures cloning . example illustrates knowing argumentative relations important separating several arguments paragraph . example shows argument components frequently exhibit preceding text units relevant argument helpful recognizing argument component type . example , preceding dis - course connectors like “ ” , “ consequently ” , “ thus ” signal subsequent claim . Discourse markers like “ ” , “ ” , “ furthermore ” indicate premise . Formally , preceding tokens argument component starting token ti defined tokens ti � m , . . . , ti � 1 covered another argument component sentence s = t1 , t2 , . . . , tn 1   n � m � 1 . third body paragraph illustrates contra argument argumentative attack relations : Admittedly , [ cloning misused military purposes ] Claim5 . example , [ : : : : : : : : : : : : : : : : : : : : : : : : : : manipulate : : : : : : : human : : : : : : genes : : : : : : : : order : : : : : : : : create : : : : : : : : obedient : : : : : : : soldiers : : : : : : : : : : : : : : : : extraordinary : : : : : : : abilities ] Premise9 . , [ : : : : moral : : : : : : : : : : : ethical : : : : : : values : : : : : : : : : : : : : : : internationally : : : : : : shared ] Premise10 , [ : : : : : : : : : : : : : : : : unlikely : : : : : : : : : : : cloning : : : : : : : : : : : : : : misused : : : : : : : : : militant : : : : : : : : : objectives ] Premise11 . paragraph begins Claim5 , attacks stance author . supported Premise9 second sentence . third sentence includes two premises , defend stance author . Premise11 attack Claim5 , Premise10 supports Premise11 . last paragraph ( conclusion ) restates major claim sum - marizes main aspects essay : sum up , although [ permitting cloning might bear risks like misuse military purposes ] Claim6 , strongly believe [ technology beneficial humanity ] MajorClaim2 . likely [ technology bears important cures significantly improve life conditions ] Claim7 . conclusion essay starts attacking claim followed restatement major claim . last sentence includes another claim summarizes - portant points author’s argumentation . Figure 2 shows entire argumentation structure example essay . Figure 2 Argumentation structure example essay . Arrows indicate argumentative relations . Arrowheads denote argumentative support relations circleheads attack relations . Dashed lines indicate relations encoded stance attributes claims . “ P ” denotes premises . 629 Figure 23.12 Argumentation structure persuasive essay . Arrows indicate argumentation relations , ei - ther SUPPORT ( arrowheads ) ATTACK ( circleheads ) ; P denotes premises . Figure Stab Gurevych ( 2017 ) . argumentation mining clearly related rhetorical structure kinds coherence relations , arguments tend less local ; often persua - sive essay single main claim , premises spread throughout text , local coherence coherence relations . Algorithms detecting argumentation structure often include classifiers distinguishing claims , premises , non-argumentation , together relation clas - sifiers deciding two spans SUPPORT , ATTACK , neither relation ( Peldszus Stede , 2013 ) . main focus computational work , preliminary efforts annotating detecting richer semantic relationships ( Park Cardie , 2014 ; Hidey et al . , 2017 ) detecting argu - mentation schemes , larger-scale structures argument like argument ex-argumentationschemes ample , argument cause effect , argument consequences ( Feng Hirst , 2011 ) . Another important line research studying argument structure ( features ) associated success persuasiveness argument ( Habernal Gurevych , 2016 ; Tan et al . , 2016 ; Hidey et al . , 2017 ) . Indeed , Aristotle’s logos related discourse structure , Aristotle’s ethos pathos techniques particularly relevant detection mechanisms sort persuasion . example scholars investigated linguistic realizationpersuasion features studied social scientists like reciprocity ( people return favors ) , social proof ( people follow others ’ choices ) , authority ( people influenced power ) , scarcity ( people value things scarce ) , brought up persuasive argument ( Cialdini , 1984 ) . Rosenthal McKeown ( 2017 ) showed features combined argumentation structure predict influences whom social media , Althoff et al . ( 2014 ) found linguistic models reciprocity authority predicted success online requests , semisupervised model Yang et al . ( 2019 ) detected mentions scarcity , commitment , social identity predict success peer-to-peer lending plat - 23.6 • SUMMARY 19 forms . Stede Schneider ( 2018 ) comprehensive survey argument mining . 23.5.2 structure scientific discourse Scientific papers specific global structure : somewhere course paper authors indicate scientific goal , develop method solu - tion , provide evidence solution , compare prior work . popular annotation scheme modeling rhetorical goals argumentative zoningargumentativezoning model Teufel et al . ( 1999 ) Teufel et al . ( 2009 ) , informed idea scientific paper tries make knowledge claim new piece knowledge added repository field ( Myers , 1992 ) . Sentences scientific paper assigned 15 tags ; Fig . 23.13 shows 7 ( shortened ) examples labeled sentences . Category Description Example AIM Statement specific research goal , hypothesis current paper “ aim process examine role training plays tagging process ” OWN METHOD New Knowledge claim , own work : methods “ order useful purposes , following extensions made : ” OWN RESULTS Measurable / objective outcome own work “ curves generally upward trend always lie far below backoff ( 51 % error rate ) ” work own work “ framework allocation transfer control Whittaker . . . . ” GAP WEAK Lack solution field , problem solutions “ , produce experimental evidence suggesting simple model leads serious overestimates ” SUPPORT work supports current work supported current work “ Work similar described car - ried Merialdo ( 1994 ) , broadly similar conclusions . ” ANTISUPPORT Clash other’s results theory ; su - periority own work “ result challenges claims . . . ” Figure 23.13 Examples 7 15 labels Argumentative Zoning labelset ( Teufel et al . , 2009 ) . Teufel et al . ( 1999 ) Teufel et al . ( 2009 ) develop labeled corpora scientific articles computational linguistics chemistry , supervi - sion training standard sentence-classification architecture assign 15 labels . 23.6 Summary chapter introduced local global models discourse coherence . • Discourses arbitrary collections sentences ; coherent . Among factors make discourse coherent coherence relations sentences , entity-based coherence , topical coherence . • Various sets coherence relations rhetorical relations pro - posed . relations Rhetorical Structure Theory ( RST ) hold spans text structured tree . , shift-reduce parsing algorithms generally assign structures . Penn Discourse Treebank ( PDTB ) labels relations pairs spans , labels generally assigned sequence models . 20 CHAPTER 23 • DISCOURSE COHERENCE • Entity-based coherence captures intuition discourses entity , continue mentioning entity sentence sentence . Cen - tering Theory family models describing salience modeled discourse entities , hence coherence achieved virtue keeping same discourse entities salient discourse . entity grid model gives bottom-up way compute entity realization transitions lead coherence . • Many different genres different types global coherence . Persuasive essays claims premises extracted field argument mining , scientific articles structure related aims , methods , results , comparisons . Bibliographical Historical Notes Coherence relations arose independent development number schol - ars , including Hobbs ( 1979 ) idea coherence relations play inferential role hearer , investigations Mann Thompson ( 1987 ) discourse structure large texts . approaches coherence relations extrac - tion include Segmented Discourse Representation Theory ( SDRT ) ( Asher Las-SDRT carides 2003 , Baldridge et al . 2007 ) Linguistic Discourse Model ( Polanyi , 1988 ; Scha Polanyi , 1988 ; Polanyi et al . , 2004a , 2004b ) Wolf Gibson ( 2005 ) argue coherence structure includes crossed bracketings , make impossi - ble represent tree , propose graph representation . compendium 350 relations proposed literature found Hovy ( 1990 ) . RST parsing first proposed Marcu ( 1997 ) , early work rule-based , focused discourse markers ( Marcu , 2000a ) . creation RST Discourse TreeBank ( Carlson et al . 2001 , Carlson Marcu 2001 ) enabled wide variety machine learning algorithms , beginning shift-reduce parser Marcu ( 1999 ) decision trees choose actions , continuing wide variety machine learned parsing methods ( Soricut Marcu 2003 , Sagae 2009 , Hernault et al . 2010 , Feng Hirst 2014 , Surdeanu et al . 2015 , Joty et al . 2015 ) chunkers ( Sporleder Lapata , 2005 ) . Subba Di Eugenio ( 2009 ) integrated sophisticated semantic information RST parsing . Ji Eisenstein ( 2014 ) first applied neural models RST parsing neural models , leading modern set neural RST models ( Li et al . 2014 , Li et al . 2016 , Braud et al . 2017 , Yu et al . 2018 , inter alia ) well neural segmenters ( Wang et al . 2018 ) . neural PDTB parsing models ( Ji Eisenstein 2015 , Qin et al . 2016 , Qin et al . 2017 ) . Barzilay Lapata ( 2005 ) pioneered idea self-supervision coher - ence : training coherence model distinguish true orderings sentences random permutations . Li et al . ( 2014 ) first applied paradigm neural sentence - representation , many neural self-supervised models followed ( Li Juraf - sky 2017 , Logeswaran et al . 2018 , Lai Tetreault 2018 , Xu et al . 2019 ) Another aspect global coherence global topic structure text , way topics shift course document . Barzilay Lee ( 2004 ) introduced HMM model capturing topics coherence , later work expanded intuition ( Soricut Marcu 2006 , Elsner et al . 2007 , Louis Nenkova 2012 , Li Jurafsky 2017 ) . BIBLIOGRAPHICAL HISTORICAL NOTES 21 relationship explicit implicit discourse connectives fruitful research . Marcu Echihabi ( 2002 ) first proposed sen - tences explicit relations help provide training data implicit relations , removing explicit relations trying re-predict way improv - ing performance implicit connectives ; idea refined Sporleder Lascarides ( 2005 ) , ( Pitler et al . , 2009 ) , Rutherford Xue ( 2015 ) . rela - tionship way create discourse-aware representations . DisSent algorithm ( Nie et al . , 2019 ) creates task predicting explicit discourse markers two sentences . show representations learned good task function powerful sentence representations discourse tasks . idea entity-based coherence seems arisen multiple fields mid-1970s , functional linguistics ( Chafe , 1976 ) , psychology discourse processing ( Kintsch Van Dijk , 1978 ) , roughly contemporaneous work Grosz , Sidner , Joshi , colleagues . Grosz ( 1977 ) addressed focus attention conversational participants maintain discourse unfolds . de - fined two levels focus ; entities relevant entire discourse global focus , whereas entities locally focus ( i.e . , central partic - ular utterance ) immediate focus . Sidner ( 1979 , 1983 ) described method tracking ( immediate ) discourse foci resolving pronouns demonstrative noun phrases . made distinction current dis - course focus potential foci , predecessors backward - forward-looking centers Centering theory , respectively . name further roots centering approach lie papers Joshi Kuhn ( 1979 ) Joshi Weinstein ( 1981 ) , addressed relationship immediate focus inferences required integrate current utterance discourse model . Grosz et al . ( 1983 ) integrated work prior work Sidner Grosz . led manuscript centering , widely circulated 1986 , remained unpublished Grosz et al . ( 1995 ) . collection centering papers ap - pears Walker et al . ( 1998 ) . Karamanis et al . ( 2004 ) Poesio et al . ( 2004 ) deeper exploration centering parameterizations , History section Chapter 22 centering coreference . grid model entity-based coherence first proposed Barzilay Lapata ( 2005 ) drawing earlier work Lapata ( 2003 ) Barzilay , extended Barzilay Lapata ( 2008 ) others additional features ( Elsner Charniak 2008 , ( 2011 ) , Feng et al . 2014 , Lin et al . 2011 ) model projects entities global graph discourse ( Guinaudeau Strube 2013 , Mesgar Strube 2016 ) , convolutional model capture longer-range entity dependencies ( Nguyen Joty , 2017 ) . Theories discourse coherence algorithms interpret - ing discourse-level linguistic phenomena , including verb phrase ellipsis gapping ( Asher , 1993 ; Kehler , 1993 ) , tense interpretation ( Lascarides Asher 1993 , Kehler 1994 , Kehler 2000 ) . extensive investigation relationship - tween coherence relations discourse connectives found Knott Dale ( 1994 ) . Useful surveys discourse processing structure include Stede ( 2011 ) Webber et al . ( 2012 ) . 22 CHAPTER 23 • DISCOURSE COHERENCE Exercises 23.1 Finish Centering Theory processing last two utterances ( 23.30 ) , show ( 23.29 ) processed . algorithm indeed mark ( 23.29 ) less coherent ? 23.2 Select editorial column favorite newspaper , determine discourse structure 10 – 20 sentence portion . problems encounter ? helped superficial cues speaker included ( e.g . , discourse connectives ) places ? Exercises 23 Althoff , T . , Danescu-Niculescu-Mizil , C . , Jurafsky , D . ( 2014 ) . ask favor : case study suc - cess altruistic requests . ICWSM 2014 . Asher , N . ( 1993 ) . Reference Abstract Objects Dis - course . Studies Linguistics Philosophy ( SLAP ) 50 , Kluwer . Asher , N . Lascarides , . ( 2003 ) . Logics Conversation . Cambridge University Press . Baldridge , J . , Asher , N . , Hunter , J . ( 2007 ) . Annotation robust parsing discourse structure unrestricted texts . Zeitschrift für Sprachwissenschaft , 26 , 213 – 239 . Bamman , D . , O’Connor , B . , Smith , N . . ( 2013 ) . Learn - ing latent personas film characters . ACL 2013 , 352 – 361 . Barzilay , R . Lapata , M . ( 2005 ) . Modeling local coher - ence : entity-based approach . ACL-05 , 141 – 148 . Barzilay , R . Lapata , M . ( 2008 ) . Modeling local coher - ence : entity-based approach . Computational Linguis - tics , 34 ( 1 ) , 1 – 34 . Barzilay , R . Lee , L . ( 2004 ) . Catching drift : Proba - bilistic content models , applications generation summarization . HLT-NAACL-04 , 113 – 120 . Bedi , G . , Carrillo , F . , Cecchi , G . . , Slezak , D . F . , Sigman , M . , Mota , N . B . , Ribeiro , S . , Javitt , D . C . , Copelli , M . , Corcoran , C . M . ( 2015 ) . Automated analysis free speech predicts psychosis onset high-risk youths . npj Schizophrenia , 1 . Biran , O . McKeown , K . ( 2015 ) . PDTB discourse parsing tagging task : two taggers approach . SIGDIAL 15 , 96 – 104 . Braud , C . , Coavoux , M . , Søgaard , . ( 2017 ) . Cross - lingual RST discourse parsing . EACL-17 , 292 – 304 . Brennan , S . E . , Friedman , M . W . , Pollard , C . ( 1987 ) . centering approach pronouns . ACL-87 , 155 – 162 . Carlson , L . Marcu , D . ( 2001 ) . Discourse tagging man - ual . Tech . rep . ISI-TR-545 , ISI . Carlson , L . , Marcu , D . , Okurowski , M . E . ( 2001 ) . Build - ing discourse-tagged corpus framework rhetori - cal structure theory . Proceedings SIGDIAL . Chafe , W . L . ( 1976 ) . Givenness , contrastiveness , definite - ness , subjects , topics , point view . Li , C . N . ( Ed . ) , Subject Topic , 25 – 55 . Academic Press . Chen , E . , Snyder , B . , Barzilay , R . ( 2007 ) . Incremen - tal text structuring online hierarchical ranking . EMNLP / CoNLL 2007 , 83 – 91 . Cialdini , R . B . ( 1984 ) . Influence : psychology persua - sion . Morrow . Ditman , T . Kuperberg , G . R . ( 2010 ) . Building coher - ence : framework exploring breakdown links clause boundaries schizophrenia . Journal neu - rolinguistics , 23 ( 3 ) , 254 – 269 . Elsner , M . , Austerweil , J . , Charniak , E . ( 2007 ) . uni - fied local global model discourse coherence . NAACL-HLT 07 , 436 – 443 . Elsner , M . Charniak , E . ( 2008 ) . Coreference-inspired coherence modeling . ACL-08 , 41 – 44 . Elsner , M . Charniak , E . ( 2011 ) . Extending entity grid entity-specific features . ACL 2011 , 125 – 129 . Elvevåg , B . , Foltz , P . W . , Weinberger , D . R . , Goldberg , T . E . ( 2007 ) . Quantifying incoherence speech : au - tomated methodology novel application schizophre - nia . Schizophrenia research , 93 ( 1-3 ) , 304 – 316 . Feng , V . W . Hirst , G . ( 2011 ) . Classifying arguments scheme . ACL 2011 , 987 – 996 . Feng , V . W . Hirst , G . ( 2014 ) . linear-time bottom-up discourse parser constraints post-editing . ACL 2014 , 511 – 521 . Feng , V . W . , Lin , Z . , Hirst , G . ( 2014 ) . impact deep hierarchical discourse structures evaluation text coherence . COLING-14 , 940 – 949 . Finlayson , M . . ( 2016 ) . Inferring propp’s functions semantically annotated text . Journal American Folk - lore , 129 ( 511 ) , 55 – 77 . Foltz , P . W . , Kintsch , W . , Landauer , T . K . ( 1998 ) . measurement textual coherence latent semantic analysis . Discourse processes , 25 ( 2-3 ) , 285 – 307 . Grosz , B . J . ( 1977 ) . representation focus system understanding dialogs . IJCAI-77 , 67 – 76 . Morgan Kaufmann . Reprinted Grosz et al . ( 1986 ) . Grosz , B . J . , Joshi , . K . , Weinstein , S . ( 1983 ) . Provid - ing unified account definite noun phrases English . ACL-83 , 44 – 50 . Grosz , B . J . , Joshi , . K . , Weinstein , S . ( 1995 ) . Cen - tering : framework modeling local coherence discourse . Computational Linguistics , 21 ( 2 ) , 203 – 225 . Guinaudeau , C . Strube , M . ( 2013 ) . Graph-based local coherence modeling . ACL 2013 , 93 – 103 . Habernal , . Gurevych , . ( 2016 ) . argument convincing ? Analyzing predicting convincing - ness Web arguments bidirectional LSTM . ACL 2016 , 1589 – 1599 . Habernal , . Gurevych , . ( 2017 ) . Argumentation mining user-generated web discourse . Computational Linguis - tics , 43 ( 1 ) , 125 – 179 . Halliday , M . . K . Hasan , R . ( 1976 ) . Cohesion En - glish . Longman . English Language Series , Title . 9 . Hearst , M . . ( 1997 ) . Texttiling : Segmenting text multi - paragraph subtopic passages . Computational Linguistics , 23 , 33 – 64 . Hernault , H . , Prendinger , H . , duVerle , D . . , Ishizuka , M . ( 2010 ) . Hilda : discourse parser support vector machine classification . Dialogue & Discourse , 1 ( 3 ) . Hidey , C . , Musi , E . , Hwang , . , Muresan , S . , McKe - own , K . ( 2017 ) . Analyzing semantic types claims premises online persuasive forum . Proceed - ings 4th Workshop Argument Mining , 11 – 21 . Hobbs , J . R . ( 1979 ) . Coherence coreference . Cognitive Science , 3 , 67 – 90 . Hovy , E . H . ( 1990 ) . Parsimonious profligate approaches question discourse structure relations . Proceed - ings 5th International Workshop Natural Lan - guage Generation , 128 – 136 . Ji , Y . Eisenstein , J . ( 2014 ) . Representation learning text-level discourse parsing . ACL 2014 , 13 – 24 . Ji , Y . Eisenstein , J . ( 2015 ) . vector enough : Entity-augmented distributed semantics discourse rela - tions . TACL , 3 , 329 – 344 . 24 Chapter 23 • Discourse Coherence Joshi , . K . Kuhn , S . ( 1979 ) . Centered logic : role entity centered sentence representation natural language inferencing . IJCAI-79 , 435 – 439 . Joshi , . K . Weinstein , S . ( 1981 ) . Control inference : Role aspects discourse structure – centering . IJCAI-81 , 385 – 387 . Joty , S . , Carenini , G . , Ng , R . T . ( 2015 ) . CODRA : novel discriminative framework rhetorical analysis . Computational Linguistics , 41 ( 3 ) , 385 – 435 . Karamanis , N . , Poesio , M . , Mellish , C . , Oberlander , J . ( 2004 ) . Evaluating centering-based metrics coherence text structuring reliably annotated corpus . ACL-04 . Kehler , . ( 1993 ) . effect establishing coherence ellipsis anaphora resolution . ACL-93 , 62 – 69 . Kehler , . ( 1994 ) . Temporal relations : Reference dis - course coherence ? . ACL-94 , 319 – 321 . Kehler , . ( 2000 ) . Coherence , Reference , Theory Grammar . CSLI Publications . Kintsch , W . Van Dijk , T . . ( 1978 ) . Toward model text comprehension production . Psychological review , 85 ( 5 ) , 363 – 394 . Knott , . Dale , R . ( 1994 ) . linguistic phenomena motivate set coherence relations . Discourse Pro - cesses , 18 ( 1 ) , 35 – 62 . Lai , . Tetreault , J . ( 2018 ) . Discourse coherence wild : dataset , evaluation methods . SIGDIAL 18 , 214 – 223 . Lakoff , G . ( 1972 ) . Structural complexity fairy tales . Study Man , 128 – 50 . School Social Sciences , Univer - sity California , Irvine , CA . Lapata , M . ( 2003 ) . Probabilistic text structuring : Experi - ments sentence ordering . ACL-03 , 545 – 552 . Lascarides , . Asher , N . ( 1993 ) . Temporal interpreta - tion , discourse relations , common sense entailment . Linguistics Philosophy , 16 ( 5 ) , 437 – 493 . Li , J . Jurafsky , D . ( 2017 ) . Neural net models open - domain discourse coherence . EMNLP 2017 , 198 – 209 . Li , J . , Li , R . , Hovy , E . H . ( 2014 ) . Recursive deep models discourse parsing . EMNLP 2014 , 2061 – 2069 . Li , Q . , Li , T . , Chang , B . ( 2016 ) . Discourse parsing attention-based hierarchical neural networks . EMNLP 2016 , 362 – 371 . Lin , Z . , Kan , M . - Y . , Ng , H . T . ( 2009 ) . Recognizing - plicit discourse relations penn discourse treebank . EMNLP-09 , 343 – 351 . Lin , Z . , Ng , H . T . , Kan , M . - Y . ( 2011 ) . Automatically evaluating text coherence discourse relations . ACL 2011 , 997 – 1006 . Lin , Z . , Ng , H . T . , Kan , M . - Y . ( 2014 ) . pdtb-styled end-to-end discourse parser . Natural Language Engineer - ing , 20 ( 2 ) , 151 – 184 . Logeswaran , L . , Lee , H . , Radev , D . ( 2018 ) . Sentence - dering coherence modeling recurrent neural net - works . AAAI-18 . Louis , . Nenkova , . ( 2012 ) . coherence model based syntactic patterns . EMNLP 2012 , 1157 – 1168 . Mann , W . C . Thompson , S . . ( 1987 ) . Rhetorical struc - ture theory : theory text organization . Tech . rep . RS - 87-190 , Information Sciences Institute . Marcu , D . ( 1997 ) . rhetorical parsing natural language texts . ACL / EACL-97 . Marcu , D . ( 1999 ) . decision-based approach rhetorical parsing . ACL-99 , 365 – 372 . Marcu , D . ( 2000a ) . rhetorical parsing unrestricted texts : surface-based approach . Computational Linguis - tics , 26 ( 3 ) , 395 – 448 . Marcu , D . ( Ed . ) . ( 2000b ) . Theory Practice Dis - course Parsing Summarization . MIT Press . Marcu , D . Echihabi , . ( 2002 ) . unsupervised ap - proach recognizing discourse relations . ACL-02 , 368 – 375 . Mesgar , M . Strube , M . ( 2016 ) . Lexical coherence graph modeling word embeddings . ACL 2016 , 1414 – 1423 . Miltsakaki , E . , Prasad , R . , Joshi , . K . , Webber , B . L . ( 2004 ) . Penn Discourse Treebank . LREC-04 . Morey , M . , Muller , P . , Asher , N . ( 2017 ) . progress made RST discourse parsing ? repli - cation study recent results rst-dt . EMNLP 2017 . Morris , J . Hirst , G . ( 1991 ) . Lexical cohesion computed thesaural relations indicator structure text . Computational Linguistics , 17 ( 1 ) , 21 – 48 . Muller , P . , Braud , C . , Morey , M . ( 2019 ) . ToNy : Contex - tual embeddings accurate multilingual discourse seg - mentation full documents . Proceedings Work - shop Discourse Relation Parsing Treebanking 2019 , 115 – 124 . Musi , E . , Stede , M . , Kriese , L . , Muresan , S . , Rocci , . ( 2018 ) . multi-layer annotated corpus argumentative text : argument schemes discourse relations . LREC-18 . Myers , G . ( 1992 ) . “ paper report . . . ” : Speech acts scientific facts . Journal Pragmatics , 17 ( 4 ) , 295 – 313 . Nguyen , D . T . Joty , S . ( 2017 ) . neural local coherence model . ACL 2017 , 1320 – 1330 . Nie , . , Bennett , E . , Goodman , N . ( 2019 ) . Dissent : Learning sentence representations explicit discourse relations . ACL 2019 , 4497 – 4510 . Park , J . Cardie , C . ( 2014 ) . Identifying appropriate sup - port propositions online user comments . Proceed - ings first workshop argumentation mining , 29 – 38 . Peldszus , . Stede , M . ( 2013 ) . argument diagrams argumentation mining texts : survey . International Journal Cognitive Informatics Natural Intelligence ( IJCINI ) , 7 ( 1 ) , 1 – 31 . Peldszus , . Stede , M . ( 2016 ) . annotated corpus argumentative microtexts . Proceedings 1st Euro - pean Conference Argumentation , 801 – 816 . Pitler , E . , Louis , . , Nenkova , . ( 2009 ) . Automatic sense prediction implicit discourse relations text . ACL IJCNLP 2009 , 683 – 691 . Pitler , E . Nenkova , . ( 2009 ) . syntax disam - biguate explicit discourse connectives text . ACL IJC - NLP 2009 , 13 – 16 . Exercises 25 Poesio , M . , Stevenson , R . , Di Eugenio , B . , Hitzeman , J . ( 2004 ) . Centering : parametric theory instantia - tions . Computational Linguistics , 30 ( 3 ) , 309 – 363 . Polanyi , L . ( 1988 ) . formal model structure dis - course . Journal Pragmatics , 12 . Polanyi , L . , Culy , C . , van den Berg , M . , Thione , G . L . , Ahn , D . ( 2004a ) . rule based approach discourse pars - ing . Proceedings SIGDIAL . Polanyi , L . , Culy , C . , van den Berg , M . , Thione , G . L . , Ahn , D . ( 2004b ) . Sentential structure discourse pars - ing . ACL04 Discourse Annotation Workshop . Prasad , R . , Dinesh , N . , Lee , . , Miltsakaki , E . , Robaldo , L . , Joshi , . K . , Webber , B . L . ( 2008 ) . Penn Discourse TreeBank 2.0 . LREC-08 . Prasad , R . , Webber , B . L . , Joshi , . ( 2014 ) . Reflec - tions Penn Discourse Treebank , comparable cor - pora , complementary annotation . Computational Lin - guistics , 40 ( 4 ) , 921 – 950 . Propp , V . ( 1968 ) . Morphology Folktale ( 2nd Ed . ) . Uni - versity Texas Press . Original Russian 1928 . Translated Laurence Scott . Qin , L . , Zhang , Z . , Zhao , H . ( 2016 ) . stacking gated neural architecture implicit discourse relation classifi - cation . EMNLP 2016 , 2263 – 2270 . Qin , L . , Zhang , Z . , Zhao , H . , Hu , Z . , Xing , E . ( 2017 ) . Adversarial connective-exploiting networks implicit discourse relation classification . ACL 2017 , 1006 – 1017 . Reed , C . , Mochales Palau , R . , Rowe , G . , Moens , M . - F . ( 2008 ) . Language resources studying argument . LREC-08 , 91 – 100 . Rosenthal , S . McKeown , K . ( 2017 ) . Detecting influ - encers multiple online genres . ACM Transactions Internet Technology ( TOIT ) , 17 ( 2 ) . Rutherford , . Xue , N . ( 2015 ) . Improving inference implicit discourse relations via classifying explicit dis - course connectives . NAACL HLT 2015 , 799 – 808 . Sagae , K . ( 2009 ) . Analysis discourse structure syn - tactic dependencies data-driven shift-reduce parsing . IWPT-09 , 81 – 84 . Scha , R . Polanyi , L . ( 1988 ) . augmented context free grammar discourse . COLING-88 , 573 – 577 . Sidner , C . L . ( 1979 ) . computational theory def - inite anaphora comprehension English discourse . Tech . rep . 537 , MIT Artificial Intelligence Laboratory , Cam - bridge , MA . Sidner , C . L . ( 1983 ) . Focusing comprehension def - inite anaphora . Brady , M . Berwick , R . C . ( Eds . ) , Computational Models Discourse , 267 – 330 . MIT Press . Somasundaran , S . , Burstein , J . , Chodorow , M . ( 2014 ) . Lexical chaining measuring discourse coherence qual - ity test-taker essays . COLING-14 , 950 – 961 . Soricut , R . Marcu , D . ( 2003 ) . Sentence level discourse parsing syntactic lexical information . HLT - NAACL-03 , 149 – 156 . Soricut , R . Marcu , D . ( 2006 ) . Discourse generation utility-trained coherence models . COLING / ACL 2006 , 803 – 810 . Sporleder , C . Lascarides , . ( 2005 ) . Exploiting linguis - tic cues classify rhetorical relations . RANLP-05 . Sporleder , C . Lapata , M . ( 2005 ) . Discourse chunk - ing application sentence compression . HLT - EMNLP-05 , 257 – 264 . Stab , C . Gurevych , . ( 2014a ) . Annotating argu - ment components relations persuasive essays . COLING-14 , 1501 – 1510 . Stab , C . Gurevych , . ( 2014b ) . Identifying argumenta - tive discourse structures persuasive essays . EMNLP 2014 , 46 – 56 . Stab , C . Gurevych , . ( 2017 ) . Parsing argumentation structures persuasive essays . Computational Linguistics , 43 ( 3 ) , 619 – 659 . Stede , M . ( 2011 ) . Discourse processing . Morgan & Clay - pool . Stede , M . Schneider , J . ( 2018 ) . Argumentation Mining . Morgan & Claypool . Subba , R . Di Eugenio , B . ( 2009 ) . effective discourse parser rich linguistic information . NAACL HLT 2009 , 566 – 574 . Surdeanu , M . , Hicks , T . , Valenzuela-Escarcega , M . . ( 2015 ) . Two practical rhetorical structure theory parsers . NAACL HLT 2015 , 1 – 5 . Tan , C . , Niculae , V . , Danescu-Niculescu-Mizil , C . , Lee , L . ( 2016 ) . Winning arguments : Interaction dynamics persuasion strategies good-faith online discussions . WWW-16 , 613 – 624 . Teufel , S . , Carletta , J . , Moens , M . ( 1999 ) . annota - tion scheme discourse-level argumentation research articles . EACL-99 . Teufel , S . , Siddharthan , . , Batchelor , C . ( 2009 ) . - wards domain-independent argumentative zoning : Evi - dence chemistry computational linguistics . EMNLP-09 , 1493 – 1502 . Walker , M . . , Joshi , . K . , Prince , E . ( Eds . ) . ( 1998 ) . Centering Discourse . Oxford University Press . Wang , Y . , Li , S . , Yang , J . ( 2018 ) . Toward fast accu - rate neural discourse segmentation . EMNLP 2018 . Webber , B . L . , Egg , M . , Kordoni , V . ( 2012 ) . Discourse structure language technology . Natural Language En - gineering , 18 ( 4 ) , 437 – 490 . Wolf , F . Gibson , E . ( 2005 ) . Representing discourse co - herence : corpus-based analysis . Computational Linguis - tics , 31 ( 2 ) , 249 – 287 . Xu , P . , Saghir , H . , Kang , J . S . , Long , T . , Bose , . J . , Cao , Y . , Cheung , J . C . K . ( 2019 ) . cross-domain transferable neural coherence model . ACL 2019 , 678 – 687 . Xue , N . , Ng , H . T . , Pradhan , S . , Rutherford , . , Webber , B . L . , Wang , C . , Wang , H . ( 2016 ) . Conll 2016 shared task multilingual shallow discourse parsing . Proceed - ings CoNLL-16 shared task . Yang , D . , Chen , J . , Yang , Z . , Jurafsky , D . , Hovy , E . H . ( 2019 ) . make request persuasive : Mod - eling persuasive strategies via semi-supervised neural nets crowdfunding platforms . NAACL HLT 2019 , 3620 – 3630 . Yu , N . , Zhang , M . , Fu , G . ( 2018 ) . Transition-based neu - ral RST parsing implicit syntax features . COLING - 18 , 559 – 570 . 26 Chapter 23 • Discourse Coherence Yu , Y . , Zhu , Y . , Liu , Y . , Liu , Y . , Peng , S . , Gong , M . , Zeldes , . ( 2019 ) . GumDrop DISRPT2019 shared task : model stacking approach discourse unit seg - mentation connective detection . Proceedings Workshop Discourse Relation Parsing Treebanking 2019 . Zhou , Y . Xue , N . ( 2015 ) . Chinese Discourse Tree - Bank : Chinese corpus annotated discourse relations . Language Resources Evaluation , 49 ( 2 ) , 397 – 431 .